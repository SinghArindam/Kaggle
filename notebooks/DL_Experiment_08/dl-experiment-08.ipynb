{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1780478,"sourceType":"datasetVersion","datasetId":1058581}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:08:57.892017Z","iopub.execute_input":"2025-04-20T12:08:57.892675Z","iopub.status.idle":"2025-04-20T12:08:59.855642Z","shell.execute_reply.started":"2025-04-20T12:08:57.892649Z","shell.execute_reply":"2025-04-20T12:08:59.854945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_path = '/kaggle/input/monthly-milk-production-pounds/monthlyMilkProduction.csv'\ndf = pd.read_csv(data_path)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:12:22.578867Z","iopub.execute_input":"2025-04-20T12:12:22.579355Z","iopub.status.idle":"2025-04-20T12:12:22.601232Z","shell.execute_reply.started":"2025-04-20T12:12:22.57933Z","shell.execute_reply":"2025-04-20T12:12:22.600438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom torch.utils.data import Dataset, DataLoader\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load the dataset\ndata_path = '/kaggle/input/monthly-milk-production-pounds/monthlyMilkProduction.csv'\ndf = pd.read_csv(data_path)\n\n# Assuming the dataset has a column 'Monthly milk production: pounds per cow' for the time series\ntime_series = df['Monthly milk production: pounds per cow. Jan 62 ? Dec 75'].values.astype(float)\n\n# Normalize the data\nscaler = MinMaxScaler(feature_range=(0, 1))\ntime_series_normalized = scaler.fit_transform(time_series.reshape(-1, 1))\n\n# Create sequences for LSTM\ndef create_sequences(data, seq_length):\n    X, y = [], []\n    for i in range(len(data) - seq_length):\n        X.append(data[i:i + seq_length])\n        y.append(data[i + seq_length])\n    return np.array(X), np.array(y)\n\nseq_length = 12  # Using 12 months (1 year) as the sequence length\nX, y = create_sequences(time_series_normalized, seq_length)\n\n# Split into training and testing sets (80% train, 20% test)\ntrain_size = int(len(X) * 0.8)\nX_train = X[:train_size]\ny_train = y[:train_size]\nX_test = X[train_size:]\ny_test = y[train_size:]\n\n# Convert to PyTorch tensors\nX_train = torch.FloatTensor(X_train).to(device)\ny_train = torch.FloatTensor(y_train).to(device)\nX_test = torch.FloatTensor(X_test).to(device)\ny_test = torch.FloatTensor(y_test).to(device)\n\n# Define the LSTM model\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size=1, hidden_size=50, num_layers=1):\n        super(LSTMModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, 1)\n    \n    def forward(self, x):\n        batch_size = x.size(0)\n        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Instantiate the model\nmodel = LSTMModel(input_size=1, hidden_size=50, num_layers=1).to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# Training the model\nnum_epochs = 250\ntrain_losses = []\n\nfor epoch in range(num_epochs):\n    model.train()\n    outputs = model(X_train)\n    optimizer.zero_grad()\n    loss = criterion(outputs, y_train)\n    loss.backward()\n    optimizer.step()\n    train_losses.append(loss.item())\n    \n    if (epoch + 1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}')\n\n# Evaluate the model\nmodel.eval()\nwith torch.no_grad():\n    train_predictions = model(X_train).cpu().numpy()\n    test_predictions = model(X_test).cpu().numpy()\n\n# Inverse transform the predictions and actual values\ntrain_predictions = scaler.inverse_transform(train_predictions)\ny_train_actual = scaler.inverse_transform(y_train.cpu().numpy())\ntest_predictions = scaler.inverse_transform(test_predictions)\ny_test_actual = scaler.inverse_transform(y_test.cpu().numpy())\n\n# Plot 1: Training Loss\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Training Loss')\nplt.title('Training Loss Over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\nplt.savefig('training_loss.png')\nplt.show()\nplt.close()\n\n# Plot 2: Actual vs Predicted (Training Set)\nplt.figure(figsize=(15, 5))\nplt.plot(y_train_actual, label='Actual Milk Production (Train)', color='blue')\nplt.plot(train_predictions, label='Predicted Milk Production (Train)', color='orange', linestyle='--')\nplt.title('Actual vs Predicted Milk Production (Training Set)')\nplt.xlabel('Time Step')\nplt.ylabel('Milk Production (Pounds)')\nplt.legend()\nplt.grid(True)\nplt.savefig('train_predictions.png')\nplt.show()\nplt.close()\n\n# Plot 3: Actual vs Predicted (Test Set)\nplt.figure(figsize=(15, 5))\nplt.plot(y_test_actual, label='Actual Milk Production (Test)', color='blue')\nplt.plot(test_predictions, label='Predicted Milk Production (Test)', color='orange', linestyle='--')\nplt.title('Actual vs Predicted Milk Production (Test Set)')\nplt.xlabel('Time Step')\nplt.ylabel('Milk Production (Pounds)')\nplt.legend()\nplt.grid(True)\nplt.savefig('test_predictions.png')\nplt.show()\nplt.close()\n\n# Plot 4: Full Time Series with Predictions\nfull_actual = time_series[seq_length:train_size + seq_length]\nfull_pred = np.concatenate([train_predictions, test_predictions])\nplt.figure(figsize=(20, 5))\nplt.plot(time_series, label='Actual Milk Production (Full)', color='blue')\nplt.plot(range(seq_length, seq_length + len(full_pred)), full_pred, label='Predicted Milk Production', color='orange', linestyle='--')\nplt.title('Full Time Series with Predictions')\nplt.xlabel('Time Step')\nplt.ylabel('Milk Production (Pounds)')\nplt.legend()\nplt.grid(True)\nplt.savefig('full_time_series.png')\nplt.show()\nplt.close()\n\nprint(\"Plots saved as 'training_loss.png', 'train_predictions.png', 'test_predictions.png', and 'full_time_series.png'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:12:35.5931Z","iopub.execute_input":"2025-04-20T12:12:35.593683Z","iopub.status.idle":"2025-04-20T12:12:40.201274Z","shell.execute_reply.started":"2025-04-20T12:12:35.593661Z","shell.execute_reply":"2025-04-20T12:12:40.200488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}