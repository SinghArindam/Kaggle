{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V","metadata":{"_uuid":"e892d7cb-b179-42f7-8fd6-1e757053626f","_cell_guid":"fb94bd38-d79e-4595-8de1-9ac99df56ab3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:15.328157Z","iopub.execute_input":"2025-05-20T15:47:15.328458Z","iopub.status.idle":"2025-05-20T15:47:15.469175Z","shell.execute_reply.started":"2025-05-20T15:47:15.328435Z","shell.execute_reply":"2025-05-20T15:47:15.467273Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import lib and Check Input","metadata":{"_uuid":"70804f5e-b23d-49eb-8b88-58a36883c12f","_cell_guid":"b351f33d-1a12-409c-b635-f408a8621abd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport time\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"0d16b8a7-1f10-47c3-b632-e3ab29fc1791","_cell_guid":"afbeed18-74a0-45de-8897-676811eb5a10","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:15.471415Z","iopub.execute_input":"2025-05-20T15:47:15.47176Z","iopub.status.idle":"2025-05-20T15:47:20.145454Z","shell.execute_reply.started":"2025-05-20T15:47:15.471719Z","shell.execute_reply":"2025-05-20T15:47:20.144171Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data","metadata":{"_uuid":"515a5a2b-2e90-4e6d-b532-23ed46897137","_cell_guid":"98a16328-261c-457c-a8b6-1a44e01f845d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_path = \"/kaggle/input/playground-series-s5e5/train.csv\"\ntest_path = \"/kaggle/input/playground-series-s5e5/test.csv\"","metadata":{"_uuid":"70683262-f493-4682-80bc-1fa5f4202cbd","_cell_guid":"6d51bba6-b599-47fa-83db-bb5d12008e8c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:20.148178Z","iopub.execute_input":"2025-05-20T15:47:20.14917Z","iopub.status.idle":"2025-05-20T15:47:20.154194Z","shell.execute_reply.started":"2025-05-20T15:47:20.14914Z","shell.execute_reply":"2025-05-20T15:47:20.152728Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"_uuid":"eb6ca5ab-5b2a-4a75-8be4-31a2b0391fac","_cell_guid":"7fedad59-0595-4aab-af4c-c620129d47c1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:20.155977Z","iopub.execute_input":"2025-05-20T15:47:20.156392Z","iopub.status.idle":"2025-05-20T15:47:21.743669Z","shell.execute_reply.started":"2025-05-20T15:47:20.156357Z","shell.execute_reply":"2025-05-20T15:47:21.742579Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Observe Data","metadata":{"_uuid":"a221c741-e9e6-4cbc-9891-a338ccec37a9","_cell_guid":"a953ba3a-470f-47bb-bee1-e5552be9a316","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(f\"Train data shape: {train_df.shape}\")\nprint(f\"Test data shape:  {test_df.shape}\")","metadata":{"_uuid":"aac7a61d-7b48-41f9-8369-db2ac4356b16","_cell_guid":"75bc575d-467e-4041-a160-c44fa418d0de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:21.745213Z","iopub.execute_input":"2025-05-20T15:47:21.745576Z","iopub.status.idle":"2025-05-20T15:47:21.752223Z","shell.execute_reply.started":"2025-05-20T15:47:21.745552Z","shell.execute_reply":"2025-05-20T15:47:21.751027Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.describe())","metadata":{"_uuid":"6e2beb87-342d-45e6-a7dc-ef4a2f014f2c","_cell_guid":"dc17be01-db4c-4371-8ac8-d4ebc7e6e5c9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:21.754148Z","iopub.execute_input":"2025-05-20T15:47:21.754577Z","iopub.status.idle":"2025-05-20T15:47:22.103864Z","shell.execute_reply.started":"2025-05-20T15:47:21.754541Z","shell.execute_reply":"2025-05-20T15:47:22.10167Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(test_df.describe())","metadata":{"_uuid":"affb0baf-4137-48f9-8cb7-d9146cfd1c3d","_cell_guid":"7d8c26a0-212b-4e84-8cf3-22da31b83fab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.104661Z","iopub.execute_input":"2025-05-20T15:47:22.104955Z","iopub.status.idle":"2025-05-20T15:47:22.208574Z","shell.execute_reply.started":"2025-05-20T15:47:22.104932Z","shell.execute_reply":"2025-05-20T15:47:22.207237Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"61d9b74c-91bc-4313-95ad-c9eaf49c9491","_cell_guid":"0dfeb41d-f5de-479e-8ac0-2179c87c19d7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.209669Z","iopub.execute_input":"2025-05-20T15:47:22.210042Z","iopub.status.idle":"2025-05-20T15:47:22.242054Z","shell.execute_reply.started":"2025-05-20T15:47:22.209997Z","shell.execute_reply":"2025-05-20T15:47:22.239525Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.tail()","metadata":{"_uuid":"468b29d5-3f54-4cd8-87f2-78a2854a1a5a","_cell_guid":"a1699f9f-5c4f-477c-ba27-508a37ffacee","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.246233Z","iopub.execute_input":"2025-05-20T15:47:22.246636Z","iopub.status.idle":"2025-05-20T15:47:22.267164Z","shell.execute_reply.started":"2025-05-20T15:47:22.246605Z","shell.execute_reply":"2025-05-20T15:47:22.266041Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"d9271665-8184-4b21-b5c4-bc9fefe1e26e","_cell_guid":"070cef3a-5239-4ab4-a3da-42c2b31f6523","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.268106Z","iopub.execute_input":"2025-05-20T15:47:22.268473Z","iopub.status.idle":"2025-05-20T15:47:22.298253Z","shell.execute_reply.started":"2025-05-20T15:47:22.268447Z","shell.execute_reply":"2025-05-20T15:47:22.297092Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.tail()","metadata":{"_uuid":"2586ec8c-c124-4760-9dc5-3e45511e6e58","_cell_guid":"e62d1aba-9b9e-4939-9c23-f4eba14df6ad","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.29932Z","iopub.execute_input":"2025-05-20T15:47:22.29962Z","iopub.status.idle":"2025-05-20T15:47:22.326179Z","shell.execute_reply.started":"2025-05-20T15:47:22.299589Z","shell.execute_reply":"2025-05-20T15:47:22.325031Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Store test ids","metadata":{"_uuid":"388eb89b-2709-4543-8ed3-9ad2a8ddadb7","_cell_guid":"320ae4b2-2260-4f41-afb3-d7e03890ed90","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"test_ids = test_df['id']","metadata":{"_uuid":"6f4dac58-3cbf-4371-a25d-22b3df7289ba","_cell_guid":"06bb2244-8b54-40fa-b656-95d4f5023852","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.327491Z","iopub.execute_input":"2025-05-20T15:47:22.328005Z","iopub.status.idle":"2025-05-20T15:47:22.349568Z","shell.execute_reply.started":"2025-05-20T15:47:22.327973Z","shell.execute_reply":"2025-05-20T15:47:22.348424Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ids","metadata":{"_uuid":"664bf52d-7131-4748-8426-602740383dab","_cell_guid":"c1e650cb-7c90-4bfa-b2f8-27248e57d24e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.350985Z","iopub.execute_input":"2025-05-20T15:47:22.351377Z","iopub.status.idle":"2025-05-20T15:47:22.380854Z","shell.execute_reply.started":"2025-05-20T15:47:22.351343Z","shell.execute_reply":"2025-05-20T15:47:22.378969Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Data","metadata":{"_uuid":"ac3e2636-e07d-467c-8cb7-d82b70f9bce8","_cell_guid":"79d73a30-42e2-419d-b8ee-c4b458811510","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='Sex', data=train_df)\nplt.title('Sex Distribution')\nplt.show()","metadata":{"_uuid":"51faabb6-5be4-403f-96ba-8f1da6909242","_cell_guid":"95a86e79-5f0e-4e24-842e-7394c53d0dd9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:22.382122Z","iopub.execute_input":"2025-05-20T15:47:22.382528Z","iopub.status.idle":"2025-05-20T15:47:23.132742Z","shell.execute_reply.started":"2025-05-20T15:47:22.382493Z","shell.execute_reply":"2025-05-20T15:47:23.131475Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.barplot(x='Sex', y='Calories', data=train_df)\nplt.title('Sex Distribution')\nplt.show()","metadata":{"_uuid":"ad85cc49-bf07-44e9-9101-14762bacc14d","_cell_guid":"1e8d8419-335e-4c78-b063-6e4384ef6f4e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:23.133689Z","iopub.execute_input":"2025-05-20T15:47:23.133928Z","iopub.status.idle":"2025-05-20T15:47:34.330106Z","shell.execute_reply.started":"2025-05-20T15:47:23.133909Z","shell.execute_reply":"2025-05-20T15:47:34.328932Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Age'].dropna(), kde=True)\nplt.title('Age Distribution')\nplt.show()","metadata":{"_uuid":"c6ee70bd-e307-4edb-b393-0888f7869e60","_cell_guid":"fcee84dc-df80-414a-90d1-828dd17edc55","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:34.331168Z","iopub.execute_input":"2025-05-20T15:47:34.331634Z","iopub.status.idle":"2025-05-20T15:47:37.934356Z","shell.execute_reply.started":"2025-05-20T15:47:34.331607Z","shell.execute_reply":"2025-05-20T15:47:37.933102Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Height'].dropna(), kde=True)\nplt.title('Height Distribution')\nplt.show()","metadata":{"_uuid":"1052d6a5-f467-4a2b-b625-38c8198049ab","_cell_guid":"38af4921-59b5-4b36-80c8-b604d7ba460a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:37.935322Z","iopub.execute_input":"2025-05-20T15:47:37.936195Z","iopub.status.idle":"2025-05-20T15:47:41.9559Z","shell.execute_reply.started":"2025-05-20T15:47:37.936139Z","shell.execute_reply":"2025-05-20T15:47:41.95505Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Weight'].dropna(), kde=True)\nplt.title('Weight Distribution')\nplt.show()","metadata":{"_uuid":"a8887ffe-9cd8-42f9-ab68-b630b810ee4a","_cell_guid":"aeef6460-f2a9-43f5-8d25-d7aac2486350","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:41.957155Z","iopub.execute_input":"2025-05-20T15:47:41.95751Z","iopub.status.idle":"2025-05-20T15:47:45.857662Z","shell.execute_reply.started":"2025-05-20T15:47:41.957487Z","shell.execute_reply":"2025-05-20T15:47:45.856726Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Duration'].dropna(), kde=True)\nplt.title('Duration Distribution')\nplt.show()","metadata":{"_uuid":"637f2475-5add-4953-80bd-3e1d8e12c8a5","_cell_guid":"2dfb3825-37f6-4b03-8b31-b19a1b06a7ab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:45.858742Z","iopub.execute_input":"2025-05-20T15:47:45.859165Z","iopub.status.idle":"2025-05-20T15:47:49.256456Z","shell.execute_reply.started":"2025-05-20T15:47:45.859135Z","shell.execute_reply":"2025-05-20T15:47:49.255238Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Heart_Rate'].dropna(), kde=True)\nplt.title('Heart_Rate Distribution')\nplt.show()","metadata":{"_uuid":"2f861e7f-e1c1-4c50-859e-837177640758","_cell_guid":"7a5fb2d6-3901-4692-89c5-866d514b9cd4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:49.257442Z","iopub.execute_input":"2025-05-20T15:47:49.257718Z","iopub.status.idle":"2025-05-20T15:47:53.234158Z","shell.execute_reply.started":"2025-05-20T15:47:49.257696Z","shell.execute_reply":"2025-05-20T15:47:53.2325Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Body_Temp'].dropna(), kde=True)\nplt.title('Body_Temp Distribution')\nplt.show()","metadata":{"_uuid":"2054592e-9b83-43ce-9de8-ea50d2cfcbf9","_cell_guid":"2afacaf3-5f7e-4cb8-9e9e-051605af2112","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:53.235968Z","iopub.execute_input":"2025-05-20T15:47:53.236487Z","iopub.status.idle":"2025-05-20T15:47:57.221232Z","shell.execute_reply.started":"2025-05-20T15:47:53.23645Z","shell.execute_reply":"2025-05-20T15:47:57.220245Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{"_uuid":"7b99a93c-2a7e-48ba-96da-3c93e703902d","_cell_guid":"6ee4426f-d021-4f6b-a8a3-2ec7d2a8bb35","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Encoding Categorical Variables","metadata":{"_uuid":"f24d877d-edda-4183-97f3-544f848a98ec","_cell_guid":"98b12efc-2a9a-43de-80f1-a5012f0293eb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})","metadata":{"_uuid":"83cd95d9-03ae-4594-aea5-1a172a2f74a4","_cell_guid":"3109ba27-3a97-44ca-b00f-d970a646c020","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.222509Z","iopub.execute_input":"2025-05-20T15:47:57.222874Z","iopub.status.idle":"2025-05-20T15:47:57.307656Z","shell.execute_reply.started":"2025-05-20T15:47:57.222845Z","shell.execute_reply":"2025-05-20T15:47:57.306666Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Data","metadata":{"_uuid":"6f1a2577-1dfa-4bf3-b9da-6034ff8927fd","_cell_guid":"1b50cf9d-46f7-49bb-a8fe-bfb6331b7e4c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"fa2e14f0-6d1d-4f6c-b8da-734bf05aa92b","_cell_guid":"bc37dc9a-2c02-4679-b120-b5dc034d3287","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.30909Z","iopub.execute_input":"2025-05-20T15:47:57.309452Z","iopub.status.idle":"2025-05-20T15:47:57.325114Z","shell.execute_reply.started":"2025-05-20T15:47:57.30942Z","shell.execute_reply":"2025-05-20T15:47:57.324093Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"32639795-a2d5-487a-9ad1-8fe942b740b3","_cell_guid":"3a9dc1e8-2e0e-4b5b-ab4c-9e02c6c88774","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.325896Z","iopub.execute_input":"2025-05-20T15:47:57.326221Z","iopub.status.idle":"2025-05-20T15:47:57.357578Z","shell.execute_reply.started":"2025-05-20T15:47:57.326192Z","shell.execute_reply":"2025-05-20T15:47:57.356365Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check For Missing Values","metadata":{"_uuid":"374d144f-91bd-449f-a0e5-a385cf4ac8b2","_cell_guid":"25a39552-9710-4fa8-8d67-70e3d4aa401b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"missing_age_values_train = train_df['Age'].isnull().sum()\nmissing_age_values_test = test_df['Age'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Age' column of train.csv: {missing_age_values_train}\")\nprint(f\"Number of missing values in the 'Age' column of test.csv: {missing_age_values_test}\")","metadata":{"_uuid":"6deed246-600a-4bd6-884b-eff2537eb4fc","_cell_guid":"0c15261b-e069-41f7-8b17-479d216c0d07","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.358721Z","iopub.execute_input":"2025-05-20T15:47:57.359259Z","iopub.status.idle":"2025-05-20T15:47:57.388368Z","shell.execute_reply.started":"2025-05-20T15:47:57.359231Z","shell.execute_reply":"2025-05-20T15:47:57.387185Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Height'].isnull().sum()\nmissing_values_test = test_df['Height'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Height' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Height' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"57c9cfa3-3df0-422b-9876-3bfb82139fae","_cell_guid":"6d7e5f07-9867-4eca-881a-37b1cd56f636","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.389369Z","iopub.execute_input":"2025-05-20T15:47:57.389635Z","iopub.status.idle":"2025-05-20T15:47:57.42387Z","shell.execute_reply.started":"2025-05-20T15:47:57.389614Z","shell.execute_reply":"2025-05-20T15:47:57.422741Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Weight'].isnull().sum()\nmissing_values_test = test_df['Weight'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Weight' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Weight' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"a3662cd0-8509-44c9-9269-1489febb4215","_cell_guid":"6b61f48a-a931-489f-bf58-f6ce9fcbca8e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.431398Z","iopub.execute_input":"2025-05-20T15:47:57.432178Z","iopub.status.idle":"2025-05-20T15:47:57.448347Z","shell.execute_reply.started":"2025-05-20T15:47:57.432152Z","shell.execute_reply":"2025-05-20T15:47:57.447212Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Duration'].isnull().sum()\nmissing_values_test = test_df['Duration'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Duration' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Duration' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"4f5d3d9c-d85b-4e15-8bb9-7b19445e7197","_cell_guid":"8bf5b928-67b4-46f5-ab35-e6e3c7354b5d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.449453Z","iopub.execute_input":"2025-05-20T15:47:57.44987Z","iopub.status.idle":"2025-05-20T15:47:57.469925Z","shell.execute_reply.started":"2025-05-20T15:47:57.449836Z","shell.execute_reply":"2025-05-20T15:47:57.468901Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Heart_Rate'].isnull().sum()\nmissing_values_test = test_df['Heart_Rate'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Heart_Rate' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Heart_Rate' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"e7062b57-ef01-4797-9b8f-ba2c91194753","_cell_guid":"4faef343-e9b2-415d-a8c3-f031357984a7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.47106Z","iopub.execute_input":"2025-05-20T15:47:57.47149Z","iopub.status.idle":"2025-05-20T15:47:57.499329Z","shell.execute_reply.started":"2025-05-20T15:47:57.471348Z","shell.execute_reply":"2025-05-20T15:47:57.49805Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Body_Temp'].isnull().sum()\nmissing_values_test = test_df['Body_Temp'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Body_Temp' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Body_Temp' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"3d6609c5-8382-40a6-9edb-b997747b303a","_cell_guid":"52e94ac4-8733-4be9-9c53-1c10927ad966","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.500618Z","iopub.execute_input":"2025-05-20T15:47:57.50096Z","iopub.status.idle":"2025-05-20T15:47:57.521926Z","shell.execute_reply.started":"2025-05-20T15:47:57.500931Z","shell.execute_reply":"2025-05-20T15:47:57.520915Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Calories'].isnull().sum()\nprint(f\"Number of missing values in the 'Calories' column of train.csv: {missing_values_train}\")","metadata":{"_uuid":"5571534d-08bf-4c3b-bb60-b6140e74e786","_cell_guid":"b5df4bae-1283-4963-b699-06a4548c7481","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.523081Z","iopub.execute_input":"2025-05-20T15:47:57.523358Z","iopub.status.idle":"2025-05-20T15:47:57.536685Z","shell.execute_reply.started":"2025-05-20T15:47:57.523331Z","shell.execute_reply":"2025-05-20T15:47:57.535649Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{"_uuid":"bc82cfea-218a-4604-a6b7-27319197abd7","_cell_guid":"5ef17f18-54ca-44b6-b9de-764da5b0355d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['BMI'] = train_df['Weight'] / (train_df['Height']/100)**2\ntest_df['BMI'] = test_df['Weight'] / (test_df['Height']/100)**2","metadata":{"_uuid":"ae496b03-daa6-4ebb-832e-dfe8ade0efcd","_cell_guid":"f5771909-26bd-432e-9d02-68c5e53ab215","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.537832Z","iopub.execute_input":"2025-05-20T15:47:57.538099Z","iopub.status.idle":"2025-05-20T15:47:57.563443Z","shell.execute_reply.started":"2025-05-20T15:47:57.538077Z","shell.execute_reply":"2025-05-20T15:47:57.562658Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Duration_HR'] = train_df['Duration'] * train_df['Heart_Rate']\ntest_df['Duration_HR'] = test_df['Duration'] * test_df['Heart_Rate']","metadata":{"_uuid":"bb1205cf-320c-4972-b565-ec42501310c8","_cell_guid":"12762f49-6a4d-410f-a732-87482ba24c49","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.564538Z","iopub.execute_input":"2025-05-20T15:47:57.564873Z","iopub.status.idle":"2025-05-20T15:47:57.574136Z","shell.execute_reply.started":"2025-05-20T15:47:57.564842Z","shell.execute_reply":"2025-05-20T15:47:57.572994Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A feature like Duration^2 x Heart_Rate to capture potentially accelerating calorie burn with concurrent high values of these strongly correlated features.","metadata":{"_uuid":"02da8ccb-3b36-4282-98e6-23291c82223d","_cell_guid":"a17590fb-79ef-41df-a17b-62f91fb6bfc2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['Duration2_HR'] = (train_df['Duration'])**2 * train_df['Heart_Rate']\ntest_df['Duration2_HR'] = (test_df['Duration'])**2 * test_df['Heart_Rate']","metadata":{"_uuid":"c3db0147-42d4-4dea-9475-072ccfb545cf","_cell_guid":"56ed914a-2b9c-4eba-afd0-b2d0a82a2839","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-20T15:47:57.575147Z","iopub.execute_input":"2025-05-20T15:47:57.575421Z","iopub.status.idle":"2025-05-20T15:47:57.591718Z","shell.execute_reply.started":"2025-05-20T15:47:57.5754Z","shell.execute_reply":"2025-05-20T15:47:57.590733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"8e9e1a45-c43c-4cbc-9e4e-6064c6fb022e","_cell_guid":"ff08f9cb-51b9-42ef-8486-9689f8570baa","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.592751Z","iopub.execute_input":"2025-05-20T15:47:57.593192Z","iopub.status.idle":"2025-05-20T15:47:57.61405Z","shell.execute_reply.started":"2025-05-20T15:47:57.593162Z","shell.execute_reply":"2025-05-20T15:47:57.612736Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"05321894-c83c-423b-9681-ed7452b9e1f8","_cell_guid":"bf5afce0-4aec-4c21-8c95-d082e20d84b1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.615374Z","iopub.execute_input":"2025-05-20T15:47:57.615727Z","iopub.status.idle":"2025-05-20T15:47:57.646192Z","shell.execute_reply.started":"2025-05-20T15:47:57.615697Z","shell.execute_reply":"2025-05-20T15:47:57.645127Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Body_Temp'] = train_df['Body_Temp'] - 37.0\ntest_df['Body_Temp'] = test_df['Body_Temp'] - 37.0","metadata":{"_uuid":"41dd1d01-8d7e-45a9-8c9a-38ac77aa15f2","_cell_guid":"37abdedc-65e2-490a-a2ac-0c6f7d54c890","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.647165Z","iopub.execute_input":"2025-05-20T15:47:57.647435Z","iopub.status.idle":"2025-05-20T15:47:57.671648Z","shell.execute_reply.started":"2025-05-20T15:47:57.647413Z","shell.execute_reply":"2025-05-20T15:47:57.670606Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"ad04c2b1-fa0e-47cd-82df-01e5af83f098","_cell_guid":"fe28d39d-8d30-4080-b1a3-5b81a2b4b9e3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.672842Z","iopub.execute_input":"2025-05-20T15:47:57.67379Z","iopub.status.idle":"2025-05-20T15:47:57.696041Z","shell.execute_reply.started":"2025-05-20T15:47:57.673758Z","shell.execute_reply":"2025-05-20T15:47:57.695018Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"8506dcd2-fb78-4237-b255-c6a719be0c80","_cell_guid":"2da09496-77d5-47f8-b23e-7a5ec47d475a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.69713Z","iopub.execute_input":"2025-05-20T15:47:57.697428Z","iopub.status.idle":"2025-05-20T15:47:57.728219Z","shell.execute_reply.started":"2025-05-20T15:47:57.697407Z","shell.execute_reply":"2025-05-20T15:47:57.727318Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling Numeric Features","metadata":{"_uuid":"1bbb0f62-0b1d-4d4f-8357-5b0c41781d60","_cell_guid":"b124b505-6d4b-417e-b3b8-ca82460fe740","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n# # train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']])\n# # test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n\n# train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n# test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n\n# train_df[['Age', 'BMI', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n# test_df[['Age', 'BMI', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n\n# train_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']] = scaler.fit_transform(train_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']])\n# test_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']] = scaler.transform(test_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']])\n\ntrain_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]])\ntest_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', 'Duration2_HR']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]])","metadata":{"_uuid":"8f51e5c8-81b8-4fd7-b757-c425ec86b0c1","_cell_guid":"706c6d45-0f72-4538-8f1f-ce4ec0ec6bfc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:57.729477Z","iopub.execute_input":"2025-05-20T15:47:57.729823Z","iopub.status.idle":"2025-05-20T15:47:58.081214Z","shell.execute_reply.started":"2025-05-20T15:47:57.729797Z","shell.execute_reply":"2025-05-20T15:47:58.080341Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{"_uuid":"32f6c039-cb8a-4346-bb16-e107b140ae0f","_cell_guid":"574b66aa-692c-40fd-b185-59d52af1afa7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# 1. Linear Regression","metadata":{"_uuid":"1beadc5a-a987-40bc-88db-4bab705250ae","_cell_guid":"82b3d528-d6e2-4361-8af8-e8391b3ffbcb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","metadata":{"_uuid":"3a58d706-87b8-4edc-bac1-35667dfde275","_cell_guid":"f2120d4e-c571-48a8-818a-f83c38ea0d95","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.08247Z","iopub.execute_input":"2025-05-20T15:47:58.082829Z","iopub.status.idle":"2025-05-20T15:47:58.375414Z","shell.execute_reply.started":"2025-05-20T15:47:58.082794Z","shell.execute_reply":"2025-05-20T15:47:58.374376Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Features","metadata":{"_uuid":"6ce12bc7-2f9b-4143-9bd2-a0367f8f6372","_cell_guid":"3094689d-73f1-4504-aa60-b273c25872c9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n# features = ['Age', 'BMI', 'Duration', 'Heart_Rate', 'Body_Temp']\n# features = ['Age', 'BMI', 'Duration_HR', 'Body_Temp']\nfeatures = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]","metadata":{"_uuid":"2e13cc95-2687-4092-b52a-fddc0939812c","_cell_guid":"ef95a2e3-5b03-4787-8dbf-9d780cd6e1ae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.376376Z","iopub.execute_input":"2025-05-20T15:47:58.376702Z","iopub.status.idle":"2025-05-20T15:47:58.38201Z","shell.execute_reply.started":"2025-05-20T15:47:58.376673Z","shell.execute_reply":"2025-05-20T15:47:58.381055Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Preparation","metadata":{"_uuid":"b40ffbbf-8a67-4dba-8532-3db5e523ed5f","_cell_guid":"ec7f1fe7-2902-4448-8df2-a16b60eb1111","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"X_train = train_df[features]\ny_train = train_df['Calories']","metadata":{"_uuid":"b57878fe-d12a-4b2e-8b4a-fd59236fff6c","_cell_guid":"c7ebcecd-076e-4931-b902-bc457243914f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.383898Z","iopub.execute_input":"2025-05-20T15:47:58.38419Z","iopub.status.idle":"2025-05-20T15:47:58.443558Z","shell.execute_reply.started":"2025-05-20T15:47:58.384169Z","shell.execute_reply":"2025-05-20T15:47:58.442347Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = test_df[features]","metadata":{"_uuid":"972298cc-1ce0-4744-a380-615e29489800","_cell_guid":"22402664-4490-4356-ab07-dbe559108812","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.444636Z","iopub.execute_input":"2025-05-20T15:47:58.446239Z","iopub.status.idle":"2025-05-20T15:47:58.47097Z","shell.execute_reply.started":"2025-05-20T15:47:58.446201Z","shell.execute_reply":"2025-05-20T15:47:58.469888Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_train.fillna(0) # Fill NaNs in training features\nX_test = X_test.fillna(0) # Fill NaNs in test features","metadata":{"_uuid":"40254446-8994-4f60-ae7c-9e50bf239f4c","_cell_guid":"25ba0e1b-c3f8-41cc-bb73-5fe3e30193db","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.472355Z","iopub.execute_input":"2025-05-20T15:47:58.472673Z","iopub.status.idle":"2025-05-20T15:47:58.540542Z","shell.execute_reply.started":"2025-05-20T15:47:58.472654Z","shell.execute_reply":"2025-05-20T15:47:58.539523Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## K Fold CV","metadata":{"_uuid":"22d9e58d-d6ab-42d3-9c25-c274a82d3add","_cell_guid":"42584a4d-80b4-4be1-be8f-98740d63cc6e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.model_selection import KFold  # For creating K-Fold cross-validation splits\nfrom sklearn.metrics import mean_squared_log_error # For calculating Mean Squared Logarithmic Error","metadata":{"_uuid":"6bc65f45-9dee-476c-b3ff-876703beeba7","_cell_guid":"151fc775-20e8-4844-acf6-eb3f052db9df","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.541438Z","iopub.execute_input":"2025-05-20T15:47:58.541704Z","iopub.status.idle":"2025-05-20T15:47:58.546753Z","shell.execute_reply.started":"2025-05-20T15:47:58.541675Z","shell.execute_reply":"2025-05-20T15:47:58.545673Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kfold_summary = []","metadata":{"_uuid":"18b3888a-3c07-4842-91f1-75fce92c9834","_cell_guid":"d00496d6-db3a-4f30-b22d-3fbae221b00f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.547668Z","iopub.execute_input":"2025-05-20T15:47:58.547917Z","iopub.status.idle":"2025-05-20T15:47:58.568732Z","shell.execute_reply.started":"2025-05-20T15:47:58.547895Z","shell.execute_reply":"2025-05-20T15:47:58.567692Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5 Fold CV","metadata":{"_uuid":"a43b5703-5e62-42ac-a546-23550c900428","_cell_guid":"fb00c35c-eb23-4da5-92b4-3ad0284b6fd4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# This KFold CV block assumes X_train and y_train are already defined and preprocessed\n# as they are in your script before the final model training:\n# - X_train: pandas DataFrame containing the selected features.\n#            It is assumed to have been derived from a globally scaled train_df\n#            and to have had NaNs filled (e.g., with X_train.fillna(0)).\n# - y_train: pandas Series containing the target variable 'Calories'.\n#            'Calories' must be non-negative for RMSLE. Your data exploration\n#            (train_df.describe()) should confirm this (min value >= 0).\n\n# --- START OF KFold CV CODE BLOCK (using RMSLE) ---","metadata":{"_uuid":"c16f5ce4-8b8d-4e96-986d-6165d2345488","_cell_guid":"5abd3c6c-6945-4973-a296-56c1848b9c48","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.569457Z","iopub.execute_input":"2025-05-20T15:47:58.569691Z","iopub.status.idle":"2025-05-20T15:47:58.59241Z","shell.execute_reply.started":"2025-05-20T15:47:58.569673Z","shell.execute_reply":"2025-05-20T15:47:58.590831Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"--- Preparing for K-Fold Cross-Validation with RMSLE ---\")\n# 1. Configure K-Fold Cross-Validation\nn_splits = 5  # Define the number of folds (k). 5 or 10 are common choices. More folds reduce bias in the performance estimate but increase variance and computational time.\nshuffle = True\nrandom_state=42\nkf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n                # Initialize KFold object.\n                # n_splits: Specifies the number of folds.\n                # shuffle=True: Shuffles the data randomly before splitting into folds. This is crucial\n                #               to ensure that folds are representative of the overall data, especially\n                #               if the data has some inherent ordering.\n                # random_state=42: Using a fixed random state ensures that the shuffle operation is\n                #                  the same every time the code runs. This makes the CV results reproducible.","metadata":{"_uuid":"cd293fd2-0ec3-4e1e-aee3-afe74c21bca1","_cell_guid":"e6f63f28-d68d-43b9-b611-2c4c88b8ab43","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.593946Z","iopub.execute_input":"2025-05-20T15:47:58.594226Z","iopub.status.idle":"2025-05-20T15:47:58.616839Z","shell.execute_reply.started":"2025-05-20T15:47:58.594207Z","shell.execute_reply":"2025-05-20T15:47:58.615685Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Prepare to store results from each fold\nfold_rmsle_scores = [] # List to store the Root Mean Squared Logarithmic Error (RMSLE) for each validation fold.\n                       # This helps in understanding the model's performance consistency using RMSLE.\noof_predictions = np.zeros(X_train.shape[0]) # Array to store out-of-fold (OOF) predictions.\n                                             # OOF predictions are made on data that the model (for that fold)\n                                             # was not trained on. The full array of OOF predictions can be\n                                             # used for a more robust single validation score or for ensembling.","metadata":{"_uuid":"7211a501-7045-49bb-8dca-ed54f9f56196","_cell_guid":"5447a265-bbda-4373-80e2-cbedade5f401","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.617939Z","iopub.execute_input":"2025-05-20T15:47:58.618247Z","iopub.status.idle":"2025-05-20T15:47:58.644997Z","shell.execute_reply.started":"2025-05-20T15:47:58.618226Z","shell.execute_reply":"2025-05-20T15:47:58.644028Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"--- Starting {n_splits}-Fold Cross-Validation for Linear Regression (evaluating with RMSLE) ---\\n\\n\")\n\n# 3. Iterate through each fold\n# The kf.split(X_train, y_train) method generates pairs of indices:\n# - train_idx: Indices for the data points to be used for training in the current fold.\n# - val_idx: Indices for the data points to be used for validation in the current fold.\n# 'enumerate' is used to get both the fold number (starting from 0) and the indices.\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n    print(f\"\\n  Processing Fold {fold + 1}/{n_splits}...\")\n\n    # 3.1. Split data into training and validation sets for the current fold\n    # .iloc is used to select rows from pandas DataFrames (X_train) and Series (y_train) based on integer indices.\n    X_train_fold = X_train.iloc[train_idx]  # Features for training in this specific fold.\n    y_train_fold = y_train.iloc[train_idx]  # Target variable for training in this specific fold.\n    X_val_fold = X_train.iloc[val_idx]    # Features for validation in this specific fold.\n    y_val_fold = y_train.iloc[val_idx]    # Target variable for validation in this specific fold.\n                                          # For RMSLE, y_val_fold must be non-negative.\n\n    # --- Note on Preprocessing (Scaling/Imputation) within CV ---\n    # As in the previous RMSE version, this CV block uses the already-globally-scaled `X_train`.\n    # For a more rigorous CV, scaling should be fit on X_train_fold and transformed on both.\n    # NaNs are assumed to be handled prior to this block (`X_train = X_train.fillna(0)`).\n\n\n    \n    start_time = time.time()  # Record start time\n    # 3.2. Initialize a new model instance for each fold\n    # It's important to create a new, untrained model instance for each fold.\n    model_fold = LinearRegression()\n    end_time = time.time()  # Record end time\n    print(f\"Initialize a new model instance for each fold.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    \n    start_time = time.time()  # Record start time\n    # 3.3. Train the model on the current fold's training data\n    model_fold.fit(X_train_fold, y_train_fold)\n    print(f\"    Model trained for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Train the model on the current fold's training data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    \n    start_time = time.time()  # Record start time\n    # 3.4. Make predictions on the current fold's validation data\n    val_preds = model_fold.predict(X_val_fold)\n    print(f\"    Predictions made for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Make predictions on the current fold's validation data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    # 3.5. Handle negative predictions (CRUCIAL for RMSLE)\n    # RMSLE (specifically, mean_squared_log_error) requires non-negative inputs for both true and predicted values.\n    # Your original script converts negative predictions by taking their absolute value.\n    # This is important here to avoid errors with `log(1 + pred)` if `pred` is too negative.\n    # We ensure predictions are non-negative.\n    val_preds[val_preds < 0] = -val_preds[val_preds < 0] # Makes them positive\n    # If any true values in y_val_fold could be negative, they would also need to be clipped to 0 or handled.\n    # However, 'Calories' should naturally be non-negative.\n\n    # 3.6. Store out-of-fold (OOF) predictions\n    # The (non-negatively adjusted) predictions for the validation set of the current fold\n    # are stored in the corresponding positions of the oof_predictions array.\n    oof_predictions[val_idx] = val_preds\n\n    # 3.7. Evaluate the model's performance on the validation set for this fold using RMSLE\n    # `mean_squared_log_error` calculates MSLE. We take its square root to get RMSLE.\n    # Both y_val_fold (true values) and val_preds (predictions) must be non-negative.\n    try:\n        fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n        fold_rmsle_scores.append(fold_rmsle) # Store the RMSLE for this fold.\n        print(f\"    Fold {fold + 1} RMSLE: {fold_rmsle:.4f}\")\n    except ValueError as e:\n        # This might happen if, despite efforts, negative values sneak into y_val_fold or val_preds.\n        # Or if y_val_fold contains values that are problematic for log(1+y).\n        print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n        print(f\"    Min y_val_fold: {y_val_fold.min()}, Min val_preds: {np.min(val_preds)}\")\n        # Add a placeholder or skip this fold's score if an error occurs.\n        # For robustness, you might add a large penalty value or handle it as per your strategy.\n        fold_rmsle_scores.append(np.nan) # Or some other indicator of failure","metadata":{"_uuid":"d00cf7f5-d44d-40d9-b359-ee3aa348b016","_cell_guid":"bc310e60-e708-4893-9660-35aaf0171218","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:47:58.646205Z","iopub.execute_input":"2025-05-20T15:47:58.646512Z","iopub.status.idle":"2025-05-20T15:48:01.167034Z","shell.execute_reply.started":"2025-05-20T15:47:58.64649Z","shell.execute_reply":"2025-05-20T15:48:01.165473Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Summarize Cross-Validation Results\n# After iterating through all folds, calculate the average and standard deviation of the RMSLE scores.\n# Filter out NaNs if any occurred during RMSLE calculation.\nvalid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\nif valid_fold_rmsle_scores:\n    mean_cv_rmsle = np.mean(valid_fold_rmsle_scores) # Average RMSLE provides an estimate of performance.\n    std_cv_rmsle = np.std(valid_fold_rmsle_scores)   # Standard deviation indicates consistency.\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    kfold_summary.append(\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\")\n    print(f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\")\n    \n    txt1 = f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\"\n    txt2 = f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\"\n    kfold_summary.append(txt1)\n    kfold_summary.append(txt2)\nelse:\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"RMSLE calculation failed for all folds.\")\n\n\n# (Optional) Calculate overall OOF RMSLE using all out-of-fold predictions\n# This provides a single RMSLE score for the entire training dataset.\n# Ensure y_train and oof_predictions are non-negative.\n# oof_predictions were already adjusted. y_train (Calories) should be non-negative.\nif y_train.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n    try:\n        overall_oof_rmsle = np.sqrt(mean_squared_log_error(y_train, oof_predictions))\n        print(f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\")\n        \n        txt3 = f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\"\n        kfold_summary.append(txt3)\n    except ValueError as e:\n        print(f\"Error calculating Overall OOF RMSLE: {e}\")\n        print(f\"Min y_train: {y_train.min()}, Min oof_predictions: {oof_predictions.min()}\")\nelse:\n    if y_train.min() < 0:\n        print(\"Cannot calculate Overall OOF RMSLE: y_train contains negative values.\")\n    if oof_predictions.min() < 0: # Should not happen due to adjustment\n        print(\"Cannot calculate Overall OOF RMSLE: oof_predictions contain negative values.\")\n    if not valid_fold_rmsle_scores:\n        print(\"Cannot calculate Overall OOF RMSLE: No valid fold scores were obtained.\")\n\n# --- END OF KFold CV CODE BLOCK (using RMSLE) ---\n\n# Following this CV block, your script would typically proceed to train the final\n# LinearRegression model on the *entire* X_train and y_train dataset.\n# The CV results (especially mean_cv_rmsle) help you to gauge how well this\n# final model is likely to perform on the actual test data, when evaluated with RMSLE.\n# Remember to apply the same non-negative adjustment to your final test predictions\n# if you were to evaluate them with RMSLE.","metadata":{"_uuid":"e04acd53-e430-4941-8973-050248dbf87c","_cell_guid":"a6609123-03a5-4105-a503-9d37c4100895","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:01.168121Z","iopub.execute_input":"2025-05-20T15:48:01.168522Z","iopub.status.idle":"2025-05-20T15:48:01.195862Z","shell.execute_reply.started":"2025-05-20T15:48:01.168487Z","shell.execute_reply":"2025-05-20T15:48:01.194576Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10 Fold CV","metadata":{"_uuid":"6db193dc-3900-4e6a-b255-31da2228e6b7","_cell_guid":"92ed3c3b-c443-4dbd-b388-3597e5ba719a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 1. Configure K-Fold Cross-Validation\nn_splits = 10\nshuffle = True\nrandom_state=42\nprint(f\"--- Preparing for K-Fold Cross-Validation with RMSLE ---\")\nkf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)","metadata":{"_uuid":"7fa5b2aa-c3f4-4a23-804c-a691fd3afc20","_cell_guid":"ef8311e7-bfa9-4602-b89e-d74c1125bfae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:01.196848Z","iopub.execute_input":"2025-05-20T15:48:01.197208Z","iopub.status.idle":"2025-05-20T15:48:01.206882Z","shell.execute_reply.started":"2025-05-20T15:48:01.197174Z","shell.execute_reply":"2025-05-20T15:48:01.205964Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Prepare to store results from each fold\nfold_rmsle_scores = []\noof_predictions = np.zeros(X_train.shape[0])\n\nprint(f\"--- Starting {n_splits}-Fold Cross-Validation for Linear Regression (evaluating with RMSLE) ---\\n\\n\")\n\n# 3. Iterate through each fold\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n    print(f\"\\n  Processing Fold {fold + 1}/{n_splits}...\")\n    X_train_fold = X_train.iloc[train_idx]  # Features for training in this specific fold.\n    y_train_fold = y_train.iloc[train_idx]  # Target variable for training in this specific fold.\n    X_val_fold = X_train.iloc[val_idx]    # Features for validation in this specific fold.\n    y_val_fold = y_train.iloc[val_idx]\n    \n    start_time = time.time()  # Record start time\n    # 3.2. Initialize a new model instance for each fold\n    # It's important to create a new, untrained model instance for each fold.\n    model_fold = LinearRegression()\n    end_time = time.time()  # Record end time\n    print(f\"Initialize a new model instance for each fold.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.3. Train the model on the current fold's training data\n    model_fold.fit(X_train_fold, y_train_fold)\n    print(f\"    Model trained for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Train the model on the current fold's training data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.4. Make predictions on the current fold's validation data\n    val_preds = model_fold.predict(X_val_fold)\n    print(f\"    Predictions made for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Make predictions on the current fold's validation data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    # 3.5. Handle negative predictions (CRUCIAL for RMSLE)\n    val_preds[val_preds < 0] = -val_preds[val_preds < 0]\n\n    # 3.6. Store out-of-fold (OOF) predictions\n    oof_predictions[val_idx] = val_preds\n\n    # 3.7. Evaluate the model's performance on the validation set for this fold using RMSLE\n    try:\n        fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n        fold_rmsle_scores.append(fold_rmsle) # Store the RMSLE for this fold.\n        print(f\"    Fold {fold + 1} RMSLE: {fold_rmsle:.4f}\")\n    except ValueError as e:\n        print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n        print(f\"    Min y_val_fold: {y_val_fold.min()}, Min val_preds: {np.min(val_preds)}\")\n        fold_rmsle_scores.append(np.nan) # Or some other indicator of failure\n\n# 4. Summarize Cross-Validation Results\nvalid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\nif valid_fold_rmsle_scores:\n    mean_cv_rmsle = np.mean(valid_fold_rmsle_scores) # Average RMSLE provides an estimate of performance.\n    std_cv_rmsle = np.std(valid_fold_rmsle_scores)   # Standard deviation indicates consistency.\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\")\n    print(f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\")\nelse:\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"RMSLE calculation failed for all folds.\")\n\nif y_train.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n    try:\n        overall_oof_rmsle = np.sqrt(mean_squared_log_error(y_train, oof_predictions))\n        print(f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\")\n        \n        txt3 = f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\"\n        kfold_summary.append(txt3)\n    except ValueError as e:\n        print(f\"Error calculating Overall OOF RMSLE: {e}\")\n        print(f\"Min y_train: {y_train.min()}, Min oof_predictions: {oof_predictions.min()}\")\nelse:\n    if y_train.min() < 0:\n        print(\"Cannot calculate Overall OOF RMSLE: y_train contains negative values.\")\n    if oof_predictions.min() < 0: # Should not happen due to adjustment\n        print(\"Cannot calculate Overall OOF RMSLE: oof_predictions contain negative values.\")\n    if not valid_fold_rmsle_scores:\n        print(\"Cannot calculate Overall OOF RMSLE: No valid fold scores were obtained.\")\n\n# --- END OF KFold CV CODE BLOCK (using RMSLE) ---","metadata":{"_uuid":"a25111ae-633d-476d-9cc8-a41396de281b","_cell_guid":"d7e973f9-adbb-4e39-b2b3-a6429a3880c8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:01.207723Z","iopub.execute_input":"2025-05-20T15:48:01.20838Z","iopub.status.idle":"2025-05-20T15:48:06.364801Z","shell.execute_reply.started":"2025-05-20T15:48:01.20835Z","shell.execute_reply":"2025-05-20T15:48:06.363758Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15 Fold CV","metadata":{"_uuid":"c62bbb19-b455-4aff-bd61-076750a591cc","_cell_guid":"961e0c12-f650-4c57-bc54-2d496ea33598","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 1. Configure K-Fold Cross-Validation\nn_splits = 15\nshuffle = True\nrandom_state=42\nprint(f\"--- Preparing for K-Fold Cross-Validation with RMSLE ---\")\nkf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)","metadata":{"_uuid":"37ec10b2-3db5-40b9-a84d-9d82bb0fae6c","_cell_guid":"9b0a4427-956c-4fb0-8423-658b7169bea2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:06.365877Z","iopub.execute_input":"2025-05-20T15:48:06.366247Z","iopub.status.idle":"2025-05-20T15:48:06.374992Z","shell.execute_reply.started":"2025-05-20T15:48:06.366218Z","shell.execute_reply":"2025-05-20T15:48:06.373845Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Prepare to store results from each fold\nfold_rmsle_scores = []\noof_predictions = np.zeros(X_train.shape[0])\n\nprint(f\"--- Starting {n_splits}-Fold Cross-Validation for Linear Regression (evaluating with RMSLE) ---\\n\\n\")\n\n# 3. Iterate through each fold\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n    print(f\"\\n  Processing Fold {fold + 1}/{n_splits}...\")\n    X_train_fold = X_train.iloc[train_idx]  # Features for training in this specific fold.\n    y_train_fold = y_train.iloc[train_idx]  # Target variable for training in this specific fold.\n    X_val_fold = X_train.iloc[val_idx]    # Features for validation in this specific fold.\n    y_val_fold = y_train.iloc[val_idx]\n    \n    start_time = time.time()  # Record start time\n    # 3.2. Initialize a new model instance for each fold\n    # It's important to create a new, untrained model instance for each fold.\n    model_fold = LinearRegression()\n    end_time = time.time()  # Record end time\n    print(f\"Initialize a new model instance for each fold.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.3. Train the model on the current fold's training data\n    model_fold.fit(X_train_fold, y_train_fold)\n    print(f\"    Model trained for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Train the model on the current fold's training data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.4. Make predictions on the current fold's validation data\n    val_preds = model_fold.predict(X_val_fold)\n    print(f\"    Predictions made for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Make predictions on the current fold's validation data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    # 3.5. Handle negative predictions (CRUCIAL for RMSLE)\n    val_preds[val_preds < 0] = -val_preds[val_preds < 0]\n\n    # 3.6. Store out-of-fold (OOF) predictions\n    oof_predictions[val_idx] = val_preds\n\n    # 3.7. Evaluate the model's performance on the validation set for this fold using RMSLE\n    try:\n        fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n        fold_rmsle_scores.append(fold_rmsle) # Store the RMSLE for this fold.\n        print(f\"    Fold {fold + 1} RMSLE: {fold_rmsle:.4f}\")\n    except ValueError as e:\n        print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n        print(f\"    Min y_val_fold: {y_val_fold.min()}, Min val_preds: {np.min(val_preds)}\")\n        fold_rmsle_scores.append(np.nan) # Or some other indicator of failure\n\n# 4. Summarize Cross-Validation Results\nvalid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\nif valid_fold_rmsle_scores:\n    mean_cv_rmsle = np.mean(valid_fold_rmsle_scores) # Average RMSLE provides an estimate of performance.\n    std_cv_rmsle = np.std(valid_fold_rmsle_scores)   # Standard deviation indicates consistency.\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\")\n    print(f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\")\nelse:\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"RMSLE calculation failed for all folds.\")\n\nif y_train.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n    try:\n        overall_oof_rmsle = np.sqrt(mean_squared_log_error(y_train, oof_predictions))\n        print(f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\")\n        \n        txt3 = f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\"\n        kfold_summary.append(txt3)\n    except ValueError as e:\n        print(f\"Error calculating Overall OOF RMSLE: {e}\")\n        print(f\"Min y_train: {y_train.min()}, Min oof_predictions: {oof_predictions.min()}\")\nelse:\n    if y_train.min() < 0:\n        print(\"Cannot calculate Overall OOF RMSLE: y_train contains negative values.\")\n    if oof_predictions.min() < 0: # Should not happen due to adjustment\n        print(\"Cannot calculate Overall OOF RMSLE: oof_predictions contain negative values.\")\n    if not valid_fold_rmsle_scores:\n        print(\"Cannot calculate Overall OOF RMSLE: No valid fold scores were obtained.\")\n\n# --- END OF KFold CV CODE BLOCK (using RMSLE) ---","metadata":{"_uuid":"d863d55d-c224-434f-b407-a819a0067c43","_cell_guid":"dcbd59c6-0a80-4d58-b50b-c69eb4ec33e8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:06.376476Z","iopub.execute_input":"2025-05-20T15:48:06.376935Z","iopub.status.idle":"2025-05-20T15:48:14.847672Z","shell.execute_reply.started":"2025-05-20T15:48:06.376781Z","shell.execute_reply":"2025-05-20T15:48:14.846405Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## KFold CV Summary","metadata":{"_uuid":"a2514055-dad2-4a97-abb2-e92529700a54","_cell_guid":"6141e612-cdb1-4cef-91ec-b91d1250ea96","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"for i in kfold_summary:\n    print(i)","metadata":{"_uuid":"dec0a71e-c16e-4462-9d79-52bd6b5338db","_cell_guid":"d93f92af-c36f-4303-b099-aa1f0b3e14e4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:14.848746Z","iopub.execute_input":"2025-05-20T15:48:14.849042Z","iopub.status.idle":"2025-05-20T15:48:14.854109Z","shell.execute_reply.started":"2025-05-20T15:48:14.849021Z","shell.execute_reply":"2025-05-20T15:48:14.853429Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initialize model","metadata":{"_uuid":"382d9cab-4e18-428e-b69f-406e92b92307","_cell_guid":"385302fb-3fd5-489e-b2f7-7441ead129c3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%time\nmodel = LinearRegression()","metadata":{"_uuid":"5654f14d-a0ef-430b-bd67-fd7b88b70aa9","_cell_guid":"dd0fcbe4-3335-4c41-9552-9970522fae35","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:14.854692Z","iopub.execute_input":"2025-05-20T15:48:14.854922Z","iopub.status.idle":"2025-05-20T15:48:14.887951Z","shell.execute_reply.started":"2025-05-20T15:48:14.854904Z","shell.execute_reply":"2025-05-20T15:48:14.886643Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train","metadata":{"_uuid":"d3dd427e-40cc-47b0-b59c-c9f1b88209dc","_cell_guid":"66ee5b71-93d5-4d3a-be9b-99d5f60d3d7b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%time\nprint(\"Training Linear Regression model...\")\nmodel.fit(X_train, y_train)\nprint(\"Training complete.\")","metadata":{"_uuid":"c01343de-f624-4344-b63e-652b3e5d5102","_cell_guid":"74125306-fc01-43d0-940b-28cf5e0f19e7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:14.888945Z","iopub.execute_input":"2025-05-20T15:48:14.889232Z","iopub.status.idle":"2025-05-20T15:48:15.472537Z","shell.execute_reply.started":"2025-05-20T15:48:14.889203Z","shell.execute_reply":"2025-05-20T15:48:15.470372Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predict","metadata":{"_uuid":"dc48767a-1628-403a-888a-30aac39776ed","_cell_guid":"3a98872f-1fce-4dce-a214-f40f53ff95b0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%time\npredictions = model.predict(X_test)","metadata":{"_uuid":"fa511b0c-ba80-4ed9-91e7-1b8440b3e1aa","_cell_guid":"159f93d7-69d6-4fde-a3e9-574b3db1355d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:15.473635Z","iopub.execute_input":"2025-05-20T15:48:15.473972Z","iopub.status.idle":"2025-05-20T15:48:15.499537Z","shell.execute_reply.started":"2025-05-20T15:48:15.473947Z","shell.execute_reply":"2025-05-20T15:48:15.498059Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handle negative predictions","metadata":{"_uuid":"4a094039-8100-434d-a17b-bfe0b81a1269","_cell_guid":"196e8168-4864-4e1a-9948-d1f04c6ee44d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"for i in range(len(predictions)):\n    if predictions[i]<0:\n        # print(f\"i : {i} ;\\t; predictions[{i}] : {predictions[i]}\")\n        predictions[i]=-predictions[i]","metadata":{"_uuid":"66749da6-e346-4c1a-ae90-a46174f3aec6","_cell_guid":"0419c486-6167-4058-b409-f69443322bc8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:15.500557Z","iopub.execute_input":"2025-05-20T15:48:15.500965Z","iopub.status.idle":"2025-05-20T15:48:15.58821Z","shell.execute_reply.started":"2025-05-20T15:48:15.500937Z","shell.execute_reply":"2025-05-20T15:48:15.58643Z"},"scrolled":true,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save CSV","metadata":{"_uuid":"2bf5a55a-b916-4e48-a5f6-b914edaf5659","_cell_guid":"ca055068-162b-4289-ba68-327fcf426246","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"submission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions})","metadata":{"_uuid":"6be6eda1-6422-4161-abbc-6a1604cc7484","_cell_guid":"0c459b33-315c-4328-b5ae-2740a5059f36","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:15.589566Z","iopub.execute_input":"2025-05-20T15:48:15.5907Z","iopub.status.idle":"2025-05-20T15:48:15.598797Z","shell.execute_reply.started":"2025-05-20T15:48:15.590641Z","shell.execute_reply":"2025-05-20T15:48:15.596588Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.to_csv('linear_regression_submission.csv', index=False)\nprint(\"\\nSubmission file 'linear_regression_submission.csv' created successfully.\")","metadata":{"_uuid":"5c486e3d-bd0a-4e0d-88eb-02205bfa3fc3","_cell_guid":"909421cc-2f49-420f-b89b-9290631ee2d9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:15.600093Z","iopub.execute_input":"2025-05-20T15:48:15.600466Z","iopub.status.idle":"2025-05-20T15:48:16.332113Z","shell.execute_reply.started":"2025-05-20T15:48:15.600436Z","shell.execute_reply":"2025-05-20T15:48:16.330708Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Coefficients","metadata":{"_uuid":"d047181c-e7c0-4a0f-a7e4-d06cbf1792d2","_cell_guid":"b1ff7589-05f0-4abd-83df-32828699739d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"\\nModel Coefficients:\")\nfor feature, coef in zip(features, model.coef_):\n    print(f\"{feature}: {coef:.6f}\")","metadata":{"_uuid":"1b2df6b9-43cd-44e1-9aad-0a89569708e2","_cell_guid":"4f5cb2e5-b6e1-4604-aaef-de2bff13d8c4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T15:48:16.332821Z","iopub.execute_input":"2025-05-20T15:48:16.33307Z","iopub.status.idle":"2025-05-20T15:48:16.340917Z","shell.execute_reply.started":"2025-05-20T15:48:16.333051Z","shell.execute_reply":"2025-05-20T15:48:16.339366Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nfor i in range(10):\n    start_time = time.time()  # Record start time\n    print(i)\n    end_time = time.time()  # Record end time\n    print(f\"Time taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds","metadata":{"_uuid":"55b5e804-922f-4d01-9fcf-80a08c5091ec","_cell_guid":"0cbca7e7-cdd1-4261-8b14-b2fcd14ab5ac","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-20T15:48:16.342592Z","iopub.execute_input":"2025-05-20T15:48:16.343887Z","iopub.status.idle":"2025-05-20T15:48:16.378503Z","shell.execute_reply.started":"2025-05-20T15:48:16.343778Z","shell.execute_reply":"2025-05-20T15:48:16.377162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Decision Tree Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntest_size=0.2\nrandom_state=42\n\nmodel_dt = DecisionTreeRegressor(random_state=random_state)\n\nprint(\"Training Decision Tree Regressor model...\")\n# 4. Train the model\nmodel_dt.fit(X_train, y_train)\nprint(\"Training complete.\")\n\nprint(\"Making predictions with Decision Tree Regressor...\")\n# 5. Make predictions on the test data\npredictions_dt = model_dt.predict(X_test)\nprint(\"Predictions made.\")\n\n# 6. Print the predictions\nprint(\"\\nTest Data Predictions:\")\nprint(predictions_dt)","metadata":{"_uuid":"9b807b05-a404-4e3d-97c1-a9b3f9f4befb","_cell_guid":"d8c85de8-003d-4ec1-8183-c9ed6b8a5ed8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-20T15:48:16.379667Z","iopub.execute_input":"2025-05-20T15:48:16.380378Z","iopub.status.idle":"2025-05-20T15:48:24.905148Z","shell.execute_reply.started":"2025-05-20T15:48:16.380341Z","shell.execute_reply":"2025-05-20T15:48:24.903439Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_dt)):\n    if predictions_dt[i]<0:\n        # print(f\"i : {i} ;\\t; predictions[{i}] : {predictions[i]}\")\n        predictions_dt[i]=-predictions_dt[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_dt})\n\nsubmission_df.to_csv('Decision_Tree_Regressor.csv', index=False)\nprint(\"\\nSubmission file 'Decision_Tree_Regressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:48:24.90751Z","iopub.execute_input":"2025-05-20T15:48:24.90839Z","iopub.status.idle":"2025-05-20T15:48:25.367642Z","shell.execute_reply.started":"2025-05-20T15:48:24.908351Z","shell.execute_reply":"2025-05-20T15:48:25.366411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nn_estimators=100\nrandom_state=42\n\n# 3. Initialize the Random Forest Regressor model\n# model_rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\nmodel_rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state, n_jobs=-1)\n# n_jobs=-1 uses all available CPU cores for parallel processing, often speeding up training.\n\nstart_time = time.time()  # Record start time\nprint(\"Training Random Forest Regressor model...\")\n# 4. Train the model\nmodel_rf.fit(X_train, y_train)\nprint(\"Training complete.\")\nend_time = time.time()  # Record end time\nprint(f\"Training Random Forest Regressor model.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\nstart_time = time.time()  # Record start time\nprint(\"Making predictions with Random Forest Regressor...\")\n# 5. Make predictions on the test data\npredictions_rf = model_rf.predict(X_test)\nprint(\"Predictions made.\")\nend_time = time.time()  # Record end time\nprint(f\"Making predictions with Random Forest Regressor.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions:\")\nprint(predictions_rf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:48:25.368978Z","iopub.execute_input":"2025-05-20T15:48:25.369396Z","iopub.status.idle":"2025-05-20T15:51:44.018951Z","shell.execute_reply.started":"2025-05-20T15:48:25.369359Z","shell.execute_reply":"2025-05-20T15:51:44.017944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_rf)):\n    if predictions_rf[i]<0:\n        predictions_rf[i]=-predictions_rf[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_rf})\n\nsubmission_df.to_csv('Random_Forest_Regressor.csv', index=False)\nprint(\"\\nSubmission file 'Random_Forest_Regressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:51:44.019918Z","iopub.execute_input":"2025-05-20T15:51:44.020218Z","iopub.status.idle":"2025-05-20T15:51:44.469881Z","shell.execute_reply.started":"2025-05-20T15:51:44.020199Z","shell.execute_reply":"2025-05-20T15:51:44.468262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model_rf.feature_importances_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:51:44.470684Z","iopub.execute_input":"2025-05-20T15:51:44.471034Z","iopub.status.idle":"2025-05-20T15:51:44.834911Z","shell.execute_reply.started":"2025-05-20T15:51:44.471006Z","shell.execute_reply":"2025-05-20T15:51:44.833777Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Gradient Boosting Regressor (from scikit-learn)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\nn_estimators=100\nlearning_rate=0.1\nmax_depth=3\nrandom_state=42\n\nmodel_gbr = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state)\n\nprint(\"Training Gradient Boosting Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_gbr.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with Gradient Boosting Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_gbr = model_gbr.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions (Gradient Boosting Regressor):\")\nprint(predictions_gbr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:51:44.835917Z","iopub.execute_input":"2025-05-20T15:51:44.836404Z","iopub.status.idle":"2025-05-20T15:54:16.909841Z","shell.execute_reply.started":"2025-05-20T15:51:44.836277Z","shell.execute_reply":"2025-05-20T15:54:16.908667Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_gbr)):\n    if predictions_gbr[i]<0:\n        predictions_gbr[i]=-predictions_gbr[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_gbr})\n\nsubmission_df.to_csv('Gradient_Boosting_Regressor.csv', index=False)\nprint(\"\\nSubmission file 'Gradient_Boosting_Regressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:16.910834Z","iopub.execute_input":"2025-05-20T15:54:16.911609Z","iopub.status.idle":"2025-05-20T15:54:17.554984Z","shell.execute_reply.started":"2025-05-20T15:54:16.911587Z","shell.execute_reply":"2025-05-20T15:54:17.553858Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. XGBoost Regressor","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\n# # 1. Create sample data\n# data = {'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n#         'Feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n#         'Target': [100, 120, 130, 150, 160, 170, 180, 190, 200, 210]}\n# df = pd.DataFrame(data)\n\n# # Define features (X) and target (y)\n# X = df[['Feature1', 'Feature2']]\n# y = df['Target']\n\n# # 2. Split data into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 3. Initialize the XGBoost Regressor model\n# Key parameters for potential optimization:\n# n_estimators: Number of boosting rounds.\n# learning_rate: Step size shrinkage used in update to prevent overfitting.\n# max_depth: Maximum depth of a tree.\n# n_jobs: Number of parallel threads. Use -1 to use all available cores.\n# tree_method: Algorithm used to construct the trees ('auto', 'exact', 'approx', 'hist'). 'hist' is often faster for large datasets.\n\nn_estimators=100\nlearning_rate=0.1\nmax_depth=3\nrandom_state=42\nn_jobs=-1\nmodel_xgb = xgb.XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state, n_jobs=n_jobs)\n\nprint(\"Training XGBoost Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_xgb.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with XGBoost Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_xgb = model_xgb.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions (XGBoost Regressor):\")\nprint(predictions_xgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:17.556282Z","iopub.execute_input":"2025-05-20T15:54:17.55716Z","iopub.status.idle":"2025-05-20T15:54:20.132411Z","shell.execute_reply.started":"2025-05-20T15:54:17.557129Z","shell.execute_reply":"2025-05-20T15:54:20.130809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_xgb)):\n    if predictions_xgb[i]<0:\n        predictions_xgb[i]=-predictions_xgb[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_xgb})\n\nsubmission_df.to_csv('xgboost.csv', index=False)\nprint(\"\\nSubmission file 'xgboost.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:20.13301Z","iopub.execute_input":"2025-05-20T15:54:20.13324Z","iopub.status.idle":"2025-05-20T15:54:21.155474Z","shell.execute_reply.started":"2025-05-20T15:54:20.133222Z","shell.execute_reply":"2025-05-20T15:54:21.154523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. LightGBM Regressor","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\n# 3. Initialize the LightGBM Regressor model\n# LightGBM is often faster than XGBoost and scikit-learn's GBR, especially on large datasets.\n# Key parameters for potential optimization:\n# n_estimators: Number of boosting rounds.\n# learning_rate: Step size shrinkage.\n# num_leaves: Maximum number of leaves in one tree (main complexity parameter).\n# n_jobs: Number of parallel threads. Use -1 to use all available cores.\n\nn_estimators=100\nlearning_rate=0.1\n# max_depth=3\nnum_leaves=31\nrandom_state=42\nn_jobs=-1\n\nmodel_lgb = lgb.LGBMRegressor(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves, random_state=random_state, n_jobs=n_jobs)\n\nprint(\"Training LightGBM Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_lgb.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with LightGBM Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_lgb = model_lgb.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions (LightGBM Regressor):\")\nprint(predictions_lgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:21.156959Z","iopub.execute_input":"2025-05-20T15:54:21.157247Z","iopub.status.idle":"2025-05-20T15:54:31.450215Z","shell.execute_reply.started":"2025-05-20T15:54:21.157227Z","shell.execute_reply":"2025-05-20T15:54:31.448671Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_lgb)):\n    if predictions_lgb[i]<0:\n        predictions_lgb[i]=-predictions_lgb[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_lgb})\n\nsubmission_df.to_csv('LightGBM.csv', index=False)\nprint(\"\\nSubmission file 'LightGBM.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:31.451044Z","iopub.execute_input":"2025-05-20T15:54:31.451681Z","iopub.status.idle":"2025-05-20T15:54:32.096095Z","shell.execute_reply.started":"2025-05-20T15:54:31.451657Z","shell.execute_reply":"2025-05-20T15:54:32.095048Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. CatBoost Regressor","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\n# 3. Initialize the CatBoost Regressor model\n# CatBoost is known for handling categorical features well and often provides good out-of-the-box results.\n# Key parameters for potential optimization:\n# iterations: Number of boosting iterations (trees).\n# learning_rate: Step size shrinkage.\n# depth: Depth of the trees.\n# l2_leaf_reg: L2 regularization term on weights.\n# verbose: Controls the amount of output during training (set to 0 for less output).\n# thread_count: Number of parallel threads. Use -1 to use all available cores.\n\niterations=100\nlearning_rate=0.1\ndepth=3\nrandom_state=42\nverbose=0\nthread_count=-1\n\nmodel_cat = CatBoostRegressor(iterations=iterations, learning_rate=learning_rate, depth=depth, random_state=random_state, verbose=verbose, thread_count=thread_count) # Set verbose to 0 for less output\n\nprint(\"Training CatBoost Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_cat.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with CatBoost Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_cat = model_cat.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nTest Data Predictions (CatBoost Regressor):\")\nprint(predictions_cat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:32.096944Z","iopub.execute_input":"2025-05-20T15:54:32.097196Z","iopub.status.idle":"2025-05-20T15:54:36.830088Z","shell.execute_reply.started":"2025-05-20T15:54:32.097177Z","shell.execute_reply":"2025-05-20T15:54:36.828878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_cat)):\n    if predictions_cat[i]<0:\n        predictions_cat[i]=-predictions_cat[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_cat})\n\nsubmission_df.to_csv('CatBoostRegressor.csv', index=False)\nprint(\"\\nSubmission file 'CatBoostRegressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:54:36.83119Z","iopub.execute_input":"2025-05-20T15:54:36.831784Z","iopub.status.idle":"2025-05-20T15:54:37.4798Z","shell.execute_reply.started":"2025-05-20T15:54:36.831749Z","shell.execute_reply":"2025-05-20T15:54:37.478814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nimport time\n\n# --- Helper Function for K-Fold Cross-Validation ---\ndef run_kfold_cv(model_class, model_params, X, y, n_splits_list, model_name):\n    \"\"\"\n    Runs K-Fold Cross-Validation for a given model and returns RMSLE scores.\n\n    Args:\n        model_class: The scikit-learn model class (e.g., SVR, Lasso).\n        model_params: A dictionary of parameters to initialize the model.\n        X (pd.DataFrame): Features DataFrame.\n        y (pd.Series): Target Series.\n        n_splits_list (list): A list of integers for the number of folds (e.g., [5, 10, 15]).\n        model_name (str): The name of the model for printing.\n\n    Returns:\n        dict: A dictionary containing CV results for each n_splits.\n    \"\"\"\n    cv_results = {}\n    print(f\"\\n--- Starting K-Fold Cross-Validation for {model_name} ---\")\n\n    for n_splits in n_splits_list:\n        print(f\"\\n  Running {n_splits}-Fold CV for {model_name}...\")\n        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n        fold_rmsle_scores = []\n        oof_predictions = np.zeros(X.shape[0]) # Out-of-fold predictions\n\n        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n\n            model_fold = model_class(**model_params)\n            model_fold.fit(X_train_fold, y_train_fold)\n            val_preds = model_fold.predict(X_val_fold)\n\n            # Handle negative predictions for RMSLE\n            val_preds[val_preds < 0] = np.abs(val_preds[val_preds < 0])\n\n            oof_predictions[val_idx] = val_preds\n\n            try:\n                fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n                fold_rmsle_scores.append(fold_rmsle)\n            except ValueError as e:\n                print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n                fold_rmsle_scores.append(np.nan)\n\n        valid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\n        if valid_fold_rmsle_scores:\n            mean_cv_rmsle = np.mean(valid_fold_rmsle_scores)\n            std_cv_rmsle = np.std(valid_fold_rmsle_scores)\n            print(f\"  Average RMSLE for {n_splits} folds: {mean_cv_rmsle:.4f} (Std: {std_cv_rmsle:.4f})\")\n\n            # Calculate overall OOF RMSLE\n            overall_oof_rmsle = np.nan\n            if y.min() >= 0 and oof_predictions.min() >= 0:\n                try:\n                    overall_oof_rmsle = np.sqrt(mean_squared_log_error(y, oof_predictions))\n                    print(f\"  Overall OOF RMSLE for {n_splits} folds: {overall_oof_rmsle:.4f}\")\n                except ValueError as e:\n                    print(f\"  Error calculating Overall OOF RMSLE for {n_splits} folds: {e}\")\n\n            cv_results[n_splits] = {\n                'Average RMSLE': mean_cv_rmsle,\n                'Std RMSLE': std_cv_rmsle,\n                'Overall OOF RMSLE': overall_oof_rmsle\n            }\n        else:\n            print(f\"  RMSLE calculation failed for all {n_splits} folds.\")\n            cv_results[n_splits] = {\n                'Average RMSLE': np.nan,\n                'Std RMSLE': np.nan,\n                'Overall OOF RMSLE': np.nan\n            }\n    return cv_results\n\n# # --- 1. Create Sample Data (consistent with previous examples) ---\n# data = {'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n#         'Feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n#         'Target': [100, 120, 130, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310]}\n# df = pd.DataFrame(data)\n\n# # Define features (X) and target (y)\n# X = df[['Feature1', 'Feature2']]\n# y = df['Target']\n\n# # Generate dummy test_ids for submission file creation\n# test_ids = pd.Series(range(len(X), len(X) + 5)) # 5 dummy IDs for test data\n\n# # Split data into training and testing sets (for final model training and prediction)\n# # Using a larger test_size for demonstration if X_test is used for final prediction.\n# # For CV, the splits are handled internally by KFold.\n# X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# For the purpose of running CV, we'll use the full dataset X and y,\n# as CV inherently splits the data.\n\n# --- List of models to evaluate ---\nmodels_to_evaluate = [\n    # {\"name\": \"Support Vector Regressor (SVR)\", \"class\": SVR, \"params\": {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}},\n    {\"name\": \"K-Nearest Neighbors Regressor\", \"class\": KNeighborsRegressor, \"params\": {'n_neighbors': 3}},\n    {\"name\": \"Lasso Regression\", \"class\": Lasso, \"params\": {'alpha': 0.1, 'random_state': 42}},\n    {\"name\": \"Ridge Regression\", \"class\": Ridge, \"params\": {'alpha': 1.0, 'random_state': 42}},\n    {\"name\": \"Elastic Net Regression\", \"class\": ElasticNet, \"params\": {'alpha': 0.1, 'l1_ratio': 0.5, 'random_state': 42}}\n]\n\nn_splits_list = [5, 10, 15]\nall_cv_results = {}\n\n# --- Train, Predict, Save, and Run CV for each model ---\nfor model_info in models_to_evaluate:\n    model_name = model_info[\"name\"]\n    model_class = model_info[\"class\"]\n    model_params = model_info[\"params\"]\n\n    print(f\"\\n======== Processing {model_name} ========\")\n\n    # --- Train the final model on full training data (for submission) ---\n    model = model_class(**model_params)\n    print(f\"Training final {model_name} model...\")\n    start_time = time.time()\n    model.fit(X_train, y_train) # Use X_train_full for final model training\n    end_time = time.time()\n    print(f\"Final model training complete in {end_time - start_time:.4f} seconds.\")\n\n    # --- Make predictions ---\n    print(f\"Making predictions with {model_name}...\")\n    start_time = time.time()\n    predictions = model.predict(X_test) # Use X_test_full for final prediction\n    end_time = time.time()\n    print(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n    # --- Handle negative predictions and save submission file ---\n    predictions[predictions < 0] = np.abs(predictions[predictions < 0])\n    submission_df = pd.DataFrame({'id': test_ids.iloc[:len(predictions)], 'Calories': predictions}) # Ensure test_ids matches prediction length\n    csv_filename = f'{model_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()}_submission.csv'\n    submission_df.to_csv(csv_filename, index=False)\n    print(f\"Submission file '{csv_filename}' created successfully.\")\n\n    # --- Run K-Fold CV ---\n    cv_results = run_kfold_cv(model_class, model_params, X_train, y_train, n_splits_list, model_name)\n    all_cv_results[model_name] = cv_results\n\n# --- Display K-Fold CV Results in Tabular Format ---\nprint(\"\\n\\n======== K-Fold Cross-Validation Summary (RMSLE) ========\")\nresults_data = []\n\nfor model_name, cv_res in all_cv_results.items():\n    for n_splits, metrics in cv_res.items():\n        results_data.append({\n            \"Model\": model_name,\n            \"N_Splits\": n_splits,\n            \"Avg RMSLE\": f\"{metrics['Average RMSLE']:.4f}\",\n            \"Std RMSLE\": f\"{metrics['Std RMSLE']:.4f}\",\n            \"Overall OOF RMSLE\": f\"{metrics['Overall OOF RMSLE']:.4f}\" if not np.isnan(metrics['Overall OOF RMSLE']) else \"N/A\"\n        })\n\nresults_df = pd.DataFrame(results_data)\nprint(results_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T16:15:30.461462Z","iopub.execute_input":"2025-05-20T16:15:30.461915Z","execution_failed":"2025-05-20T16:17:02.732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}