{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V","metadata":{"_uuid":"e892d7cb-b179-42f7-8fd6-1e757053626f","_cell_guid":"fb94bd38-d79e-4595-8de1-9ac99df56ab3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:20.55036Z","iopub.execute_input":"2025-05-19T15:37:20.550746Z","iopub.status.idle":"2025-05-19T15:37:20.688838Z","shell.execute_reply.started":"2025-05-19T15:37:20.550717Z","shell.execute_reply":"2025-05-19T15:37:20.68736Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import lib and Check Input","metadata":{"_uuid":"70804f5e-b23d-49eb-8b88-58a36883c12f","_cell_guid":"b351f33d-1a12-409c-b635-f408a8621abd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport time\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"0d16b8a7-1f10-47c3-b632-e3ab29fc1791","_cell_guid":"afbeed18-74a0-45de-8897-676811eb5a10","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:20.690921Z","iopub.execute_input":"2025-05-19T15:37:20.691254Z","iopub.status.idle":"2025-05-19T15:37:21.672141Z","shell.execute_reply.started":"2025-05-19T15:37:20.691221Z","shell.execute_reply":"2025-05-19T15:37:21.671113Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data","metadata":{"_uuid":"515a5a2b-2e90-4e6d-b532-23ed46897137","_cell_guid":"98a16328-261c-457c-a8b6-1a44e01f845d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_path = \"/kaggle/input/playground-series-s5e5/train.csv\"\ntest_path = \"/kaggle/input/playground-series-s5e5/test.csv\"","metadata":{"_uuid":"70683262-f493-4682-80bc-1fa5f4202cbd","_cell_guid":"6d51bba6-b599-47fa-83db-bb5d12008e8c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:21.673285Z","iopub.execute_input":"2025-05-19T15:37:21.673744Z","iopub.status.idle":"2025-05-19T15:37:21.679493Z","shell.execute_reply.started":"2025-05-19T15:37:21.67371Z","shell.execute_reply":"2025-05-19T15:37:21.678432Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"_uuid":"eb6ca5ab-5b2a-4a75-8be4-31a2b0391fac","_cell_guid":"7fedad59-0595-4aab-af4c-c620129d47c1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:21.681658Z","iopub.execute_input":"2025-05-19T15:37:21.681944Z","iopub.status.idle":"2025-05-19T15:37:23.049458Z","shell.execute_reply.started":"2025-05-19T15:37:21.681921Z","shell.execute_reply":"2025-05-19T15:37:23.048305Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Observe Data","metadata":{"_uuid":"a221c741-e9e6-4cbc-9891-a338ccec37a9","_cell_guid":"a953ba3a-470f-47bb-bee1-e5552be9a316","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(f\"Train data shape: {train_df.shape}\")\nprint(f\"Test data shape:  {test_df.shape}\")","metadata":{"_uuid":"aac7a61d-7b48-41f9-8369-db2ac4356b16","_cell_guid":"75bc575d-467e-4041-a160-c44fa418d0de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.050555Z","iopub.execute_input":"2025-05-19T15:37:23.05085Z","iopub.status.idle":"2025-05-19T15:37:23.057557Z","shell.execute_reply.started":"2025-05-19T15:37:23.050826Z","shell.execute_reply":"2025-05-19T15:37:23.056582Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.describe())","metadata":{"_uuid":"6e2beb87-342d-45e6-a7dc-ef4a2f014f2c","_cell_guid":"dc17be01-db4c-4371-8ac8-d4ebc7e6e5c9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.058597Z","iopub.execute_input":"2025-05-19T15:37:23.059325Z","iopub.status.idle":"2025-05-19T15:37:23.389095Z","shell.execute_reply.started":"2025-05-19T15:37:23.059293Z","shell.execute_reply":"2025-05-19T15:37:23.388158Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(test_df.describe())","metadata":{"_uuid":"affb0baf-4137-48f9-8cb7-d9146cfd1c3d","_cell_guid":"7d8c26a0-212b-4e84-8cf3-22da31b83fab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.390339Z","iopub.execute_input":"2025-05-19T15:37:23.390735Z","iopub.status.idle":"2025-05-19T15:37:23.486308Z","shell.execute_reply.started":"2025-05-19T15:37:23.390701Z","shell.execute_reply":"2025-05-19T15:37:23.484936Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"61d9b74c-91bc-4313-95ad-c9eaf49c9491","_cell_guid":"0dfeb41d-f5de-479e-8ac0-2179c87c19d7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.487665Z","iopub.execute_input":"2025-05-19T15:37:23.487989Z","iopub.status.idle":"2025-05-19T15:37:23.51149Z","shell.execute_reply.started":"2025-05-19T15:37:23.487966Z","shell.execute_reply":"2025-05-19T15:37:23.510341Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.tail()","metadata":{"_uuid":"468b29d5-3f54-4cd8-87f2-78a2854a1a5a","_cell_guid":"a1699f9f-5c4f-477c-ba27-508a37ffacee","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.51249Z","iopub.execute_input":"2025-05-19T15:37:23.513564Z","iopub.status.idle":"2025-05-19T15:37:23.534007Z","shell.execute_reply.started":"2025-05-19T15:37:23.513536Z","shell.execute_reply":"2025-05-19T15:37:23.533073Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"d9271665-8184-4b21-b5c4-bc9fefe1e26e","_cell_guid":"070cef3a-5239-4ab4-a3da-42c2b31f6523","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.53717Z","iopub.execute_input":"2025-05-19T15:37:23.537506Z","iopub.status.idle":"2025-05-19T15:37:23.565457Z","shell.execute_reply.started":"2025-05-19T15:37:23.537481Z","shell.execute_reply":"2025-05-19T15:37:23.564181Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.tail()","metadata":{"_uuid":"2586ec8c-c124-4760-9dc5-3e45511e6e58","_cell_guid":"e62d1aba-9b9e-4939-9c23-f4eba14df6ad","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.567967Z","iopub.execute_input":"2025-05-19T15:37:23.568807Z","iopub.status.idle":"2025-05-19T15:37:23.59588Z","shell.execute_reply.started":"2025-05-19T15:37:23.568774Z","shell.execute_reply":"2025-05-19T15:37:23.594798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Store test ids","metadata":{"_uuid":"388eb89b-2709-4543-8ed3-9ad2a8ddadb7","_cell_guid":"320ae4b2-2260-4f41-afb3-d7e03890ed90","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"test_ids = test_df['id']","metadata":{"_uuid":"6f4dac58-3cbf-4371-a25d-22b3df7289ba","_cell_guid":"06bb2244-8b54-40fa-b656-95d4f5023852","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.596897Z","iopub.execute_input":"2025-05-19T15:37:23.597194Z","iopub.status.idle":"2025-05-19T15:37:23.61786Z","shell.execute_reply.started":"2025-05-19T15:37:23.597173Z","shell.execute_reply":"2025-05-19T15:37:23.616738Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_ids","metadata":{"_uuid":"664bf52d-7131-4748-8426-602740383dab","_cell_guid":"c1e650cb-7c90-4bfa-b2f8-27248e57d24e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.619077Z","iopub.execute_input":"2025-05-19T15:37:23.619557Z","iopub.status.idle":"2025-05-19T15:37:23.645856Z","shell.execute_reply.started":"2025-05-19T15:37:23.619526Z","shell.execute_reply":"2025-05-19T15:37:23.644678Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Data","metadata":{"_uuid":"ac3e2636-e07d-467c-8cb7-d82b70f9bce8","_cell_guid":"79d73a30-42e2-419d-b8ee-c4b458811510","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(x='Sex', data=train_df)\nplt.title('Sex Distribution')\nplt.show()","metadata":{"_uuid":"51faabb6-5be4-403f-96ba-8f1da6909242","_cell_guid":"95a86e79-5f0e-4e24-842e-7394c53d0dd9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:23.646758Z","iopub.execute_input":"2025-05-19T15:37:23.647088Z","iopub.status.idle":"2025-05-19T15:37:24.361984Z","shell.execute_reply.started":"2025-05-19T15:37:23.647053Z","shell.execute_reply":"2025-05-19T15:37:24.360988Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.barplot(x='Sex', y='Calories', data=train_df)\nplt.title('Sex Distribution')\nplt.show()","metadata":{"_uuid":"ad85cc49-bf07-44e9-9101-14762bacc14d","_cell_guid":"1e8d8419-335e-4c78-b063-6e4384ef6f4e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:24.363007Z","iopub.execute_input":"2025-05-19T15:37:24.363332Z","iopub.status.idle":"2025-05-19T15:37:36.226816Z","shell.execute_reply.started":"2025-05-19T15:37:24.363304Z","shell.execute_reply":"2025-05-19T15:37:36.225527Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Age'].dropna(), kde=True)\nplt.title('Age Distribution')\nplt.show()","metadata":{"_uuid":"c6ee70bd-e307-4edb-b393-0888f7869e60","_cell_guid":"fcee84dc-df80-414a-90d1-828dd17edc55","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:36.227792Z","iopub.execute_input":"2025-05-19T15:37:36.228257Z","iopub.status.idle":"2025-05-19T15:37:39.790346Z","shell.execute_reply.started":"2025-05-19T15:37:36.228232Z","shell.execute_reply":"2025-05-19T15:37:39.789146Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Height'].dropna(), kde=True)\nplt.title('Height Distribution')\nplt.show()","metadata":{"_uuid":"1052d6a5-f467-4a2b-b625-38c8198049ab","_cell_guid":"38af4921-59b5-4b36-80c8-b604d7ba460a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:39.791467Z","iopub.execute_input":"2025-05-19T15:37:39.791744Z","iopub.status.idle":"2025-05-19T15:37:43.819867Z","shell.execute_reply.started":"2025-05-19T15:37:39.791723Z","shell.execute_reply":"2025-05-19T15:37:43.818798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Weight'].dropna(), kde=True)\nplt.title('Weight Distribution')\nplt.show()","metadata":{"_uuid":"a8887ffe-9cd8-42f9-ab68-b630b810ee4a","_cell_guid":"aeef6460-f2a9-43f5-8d25-d7aac2486350","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:43.821312Z","iopub.execute_input":"2025-05-19T15:37:43.821729Z","iopub.status.idle":"2025-05-19T15:37:47.741525Z","shell.execute_reply.started":"2025-05-19T15:37:43.821696Z","shell.execute_reply":"2025-05-19T15:37:47.740589Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Duration'].dropna(), kde=True)\nplt.title('Duration Distribution')\nplt.show()","metadata":{"_uuid":"637f2475-5add-4953-80bd-3e1d8e12c8a5","_cell_guid":"2dfb3825-37f6-4b03-8b31-b19a1b06a7ab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:47.742704Z","iopub.execute_input":"2025-05-19T15:37:47.743805Z","iopub.status.idle":"2025-05-19T15:37:51.127632Z","shell.execute_reply.started":"2025-05-19T15:37:47.743778Z","shell.execute_reply":"2025-05-19T15:37:51.12649Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Heart_Rate'].dropna(), kde=True)\nplt.title('Heart_Rate Distribution')\nplt.show()","metadata":{"_uuid":"2f861e7f-e1c1-4c50-859e-837177640758","_cell_guid":"7a5fb2d6-3901-4692-89c5-866d514b9cd4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:51.128957Z","iopub.execute_input":"2025-05-19T15:37:51.129528Z","iopub.status.idle":"2025-05-19T15:37:55.005341Z","shell.execute_reply.started":"2025-05-19T15:37:51.12949Z","shell.execute_reply":"2025-05-19T15:37:55.004139Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.histplot(train_df['Body_Temp'].dropna(), kde=True)\nplt.title('Body_Temp Distribution')\nplt.show()","metadata":{"_uuid":"2054592e-9b83-43ce-9de8-ea50d2cfcbf9","_cell_guid":"2afacaf3-5f7e-4cb8-9e9e-051605af2112","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:55.00654Z","iopub.execute_input":"2025-05-19T15:37:55.006945Z","iopub.status.idle":"2025-05-19T15:37:58.966313Z","shell.execute_reply.started":"2025-05-19T15:37:55.00692Z","shell.execute_reply":"2025-05-19T15:37:58.965271Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{"_uuid":"7b99a93c-2a7e-48ba-96da-3c93e703902d","_cell_guid":"6ee4426f-d021-4f6b-a8a3-2ec7d2a8bb35","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Encoding Categorical Variables","metadata":{"_uuid":"f24d877d-edda-4183-97f3-544f848a98ec","_cell_guid":"98b12efc-2a9a-43de-80f1-a5012f0293eb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})","metadata":{"_uuid":"83cd95d9-03ae-4594-aea5-1a172a2f74a4","_cell_guid":"3109ba27-3a97-44ca-b00f-d970a646c020","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:58.967339Z","iopub.execute_input":"2025-05-19T15:37:58.967697Z","iopub.status.idle":"2025-05-19T15:37:59.038473Z","shell.execute_reply.started":"2025-05-19T15:37:58.967669Z","shell.execute_reply":"2025-05-19T15:37:59.037514Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Data","metadata":{"_uuid":"6f1a2577-1dfa-4bf3-b9da-6034ff8927fd","_cell_guid":"1b50cf9d-46f7-49bb-a8fe-bfb6331b7e4c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"fa2e14f0-6d1d-4f6c-b8da-734bf05aa92b","_cell_guid":"bc37dc9a-2c02-4679-b120-b5dc034d3287","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.039471Z","iopub.execute_input":"2025-05-19T15:37:59.039789Z","iopub.status.idle":"2025-05-19T15:37:59.055128Z","shell.execute_reply.started":"2025-05-19T15:37:59.03976Z","shell.execute_reply":"2025-05-19T15:37:59.054172Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"32639795-a2d5-487a-9ad1-8fe942b740b3","_cell_guid":"3a9dc1e8-2e0e-4b5b-ab4c-9e02c6c88774","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.056199Z","iopub.execute_input":"2025-05-19T15:37:59.05658Z","iopub.status.idle":"2025-05-19T15:37:59.083452Z","shell.execute_reply.started":"2025-05-19T15:37:59.056549Z","shell.execute_reply":"2025-05-19T15:37:59.082474Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check For Missing Values","metadata":{"_uuid":"374d144f-91bd-449f-a0e5-a385cf4ac8b2","_cell_guid":"25a39552-9710-4fa8-8d67-70e3d4aa401b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"missing_age_values_train = train_df['Age'].isnull().sum()\nmissing_age_values_test = test_df['Age'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Age' column of train.csv: {missing_age_values_train}\")\nprint(f\"Number of missing values in the 'Age' column of test.csv: {missing_age_values_test}\")","metadata":{"_uuid":"6deed246-600a-4bd6-884b-eff2537eb4fc","_cell_guid":"0c15261b-e069-41f7-8b17-479d216c0d07","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.084562Z","iopub.execute_input":"2025-05-19T15:37:59.084824Z","iopub.status.idle":"2025-05-19T15:37:59.109218Z","shell.execute_reply.started":"2025-05-19T15:37:59.084786Z","shell.execute_reply":"2025-05-19T15:37:59.108189Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Height'].isnull().sum()\nmissing_values_test = test_df['Height'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Height' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Height' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"57c9cfa3-3df0-422b-9876-3bfb82139fae","_cell_guid":"6d7e5f07-9867-4eca-881a-37b1cd56f636","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.110444Z","iopub.execute_input":"2025-05-19T15:37:59.111689Z","iopub.status.idle":"2025-05-19T15:37:59.13837Z","shell.execute_reply.started":"2025-05-19T15:37:59.111655Z","shell.execute_reply":"2025-05-19T15:37:59.137354Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Weight'].isnull().sum()\nmissing_values_test = test_df['Weight'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Weight' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Weight' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"a3662cd0-8509-44c9-9269-1489febb4215","_cell_guid":"6b61f48a-a931-489f-bf58-f6ce9fcbca8e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.139369Z","iopub.execute_input":"2025-05-19T15:37:59.139679Z","iopub.status.idle":"2025-05-19T15:37:59.160814Z","shell.execute_reply.started":"2025-05-19T15:37:59.139657Z","shell.execute_reply":"2025-05-19T15:37:59.15984Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Duration'].isnull().sum()\nmissing_values_test = test_df['Duration'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Duration' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Duration' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"4f5d3d9c-d85b-4e15-8bb9-7b19445e7197","_cell_guid":"8bf5b928-67b4-46f5-ab35-e6e3c7354b5d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.166555Z","iopub.execute_input":"2025-05-19T15:37:59.166854Z","iopub.status.idle":"2025-05-19T15:37:59.183582Z","shell.execute_reply.started":"2025-05-19T15:37:59.166823Z","shell.execute_reply":"2025-05-19T15:37:59.182285Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Heart_Rate'].isnull().sum()\nmissing_values_test = test_df['Heart_Rate'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Heart_Rate' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Heart_Rate' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"e7062b57-ef01-4797-9b8f-ba2c91194753","_cell_guid":"4faef343-e9b2-415d-a8c3-f031357984a7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.184646Z","iopub.execute_input":"2025-05-19T15:37:59.18501Z","iopub.status.idle":"2025-05-19T15:37:59.19781Z","shell.execute_reply.started":"2025-05-19T15:37:59.184985Z","shell.execute_reply":"2025-05-19T15:37:59.196819Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Body_Temp'].isnull().sum()\nmissing_values_test = test_df['Body_Temp'].isnull().sum()\n\n# Print the number of missing values\nprint(f\"Number of missing values in the 'Body_Temp' column of train.csv: {missing_values_train}\")\nprint(f\"Number of missing values in the 'Body_Temp' column of test.csv: {missing_values_test}\")","metadata":{"_uuid":"3d6609c5-8382-40a6-9edb-b997747b303a","_cell_guid":"52e94ac4-8733-4be9-9c53-1c10927ad966","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.199006Z","iopub.execute_input":"2025-05-19T15:37:59.199357Z","iopub.status.idle":"2025-05-19T15:37:59.219589Z","shell.execute_reply.started":"2025-05-19T15:37:59.199333Z","shell.execute_reply":"2025-05-19T15:37:59.218473Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values_train = train_df['Calories'].isnull().sum()\nprint(f\"Number of missing values in the 'Calories' column of train.csv: {missing_values_train}\")","metadata":{"_uuid":"5571534d-08bf-4c3b-bb60-b6140e74e786","_cell_guid":"b5df4bae-1283-4963-b699-06a4548c7481","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.22066Z","iopub.execute_input":"2025-05-19T15:37:59.221176Z","iopub.status.idle":"2025-05-19T15:37:59.244573Z","shell.execute_reply.started":"2025-05-19T15:37:59.220969Z","shell.execute_reply":"2025-05-19T15:37:59.243481Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{"_uuid":"bc82cfea-218a-4604-a6b7-27319197abd7","_cell_guid":"5ef17f18-54ca-44b6-b9de-764da5b0355d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['BMI'] = train_df['Weight'] / (train_df['Height']/100)**2\ntest_df['BMI'] = test_df['Weight'] / (test_df['Height']/100)**2","metadata":{"_uuid":"ae496b03-daa6-4ebb-832e-dfe8ade0efcd","_cell_guid":"f5771909-26bd-432e-9d02-68c5e53ab215","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.245915Z","iopub.execute_input":"2025-05-19T15:37:59.246436Z","iopub.status.idle":"2025-05-19T15:37:59.275328Z","shell.execute_reply.started":"2025-05-19T15:37:59.246386Z","shell.execute_reply":"2025-05-19T15:37:59.274098Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Duration_HR'] = train_df['Duration'] * train_df['Heart_Rate']\ntest_df['Duration_HR'] = test_df['Duration'] * test_df['Heart_Rate']","metadata":{"_uuid":"bb1205cf-320c-4972-b565-ec42501310c8","_cell_guid":"12762f49-6a4d-410f-a732-87482ba24c49","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.276674Z","iopub.execute_input":"2025-05-19T15:37:59.276987Z","iopub.status.idle":"2025-05-19T15:37:59.286534Z","shell.execute_reply.started":"2025-05-19T15:37:59.276966Z","shell.execute_reply":"2025-05-19T15:37:59.285175Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A feature like Duration^2 x Heart_Rate to capture potentially accelerating calorie burn with concurrent high values of these strongly correlated features.","metadata":{"_uuid":"02da8ccb-3b36-4282-98e6-23291c82223d","_cell_guid":"a17590fb-79ef-41df-a17b-62f91fb6bfc2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['Duration2_HR'] = (train_df['Duration'])**2 * train_df['Heart_Rate']\ntest_df['Duration2_HR'] = (test_df['Duration'])**2 * test_df['Heart_Rate']","metadata":{"_uuid":"c3db0147-42d4-4dea-9475-072ccfb545cf","_cell_guid":"56ed914a-2b9c-4eba-afd0-b2d0a82a2839","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-19T15:37:59.287644Z","iopub.execute_input":"2025-05-19T15:37:59.287951Z","iopub.status.idle":"2025-05-19T15:37:59.312733Z","shell.execute_reply.started":"2025-05-19T15:37:59.287922Z","shell.execute_reply":"2025-05-19T15:37:59.311507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"8e9e1a45-c43c-4cbc-9e4e-6064c6fb022e","_cell_guid":"ff08f9cb-51b9-42ef-8486-9689f8570baa","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.313923Z","iopub.execute_input":"2025-05-19T15:37:59.314297Z","iopub.status.idle":"2025-05-19T15:37:59.331005Z","shell.execute_reply.started":"2025-05-19T15:37:59.314273Z","shell.execute_reply":"2025-05-19T15:37:59.329751Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"05321894-c83c-423b-9681-ed7452b9e1f8","_cell_guid":"bf5afce0-4aec-4c21-8c95-d082e20d84b1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.332003Z","iopub.execute_input":"2025-05-19T15:37:59.332343Z","iopub.status.idle":"2025-05-19T15:37:59.361539Z","shell.execute_reply.started":"2025-05-19T15:37:59.332315Z","shell.execute_reply":"2025-05-19T15:37:59.360467Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Body_Temp'] = train_df['Body_Temp'] - 37.0\ntest_df['Body_Temp'] = test_df['Body_Temp'] - 37.0","metadata":{"_uuid":"41dd1d01-8d7e-45a9-8c9a-38ac77aa15f2","_cell_guid":"37abdedc-65e2-490a-a2ac-0c6f7d54c890","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.362477Z","iopub.execute_input":"2025-05-19T15:37:59.362741Z","iopub.status.idle":"2025-05-19T15:37:59.385921Z","shell.execute_reply.started":"2025-05-19T15:37:59.362718Z","shell.execute_reply":"2025-05-19T15:37:59.3848Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"ad04c2b1-fa0e-47cd-82df-01e5af83f098","_cell_guid":"fe28d39d-8d30-4080-b1a3-5b81a2b4b9e3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.386968Z","iopub.execute_input":"2025-05-19T15:37:59.387235Z","iopub.status.idle":"2025-05-19T15:37:59.415553Z","shell.execute_reply.started":"2025-05-19T15:37:59.387213Z","shell.execute_reply":"2025-05-19T15:37:59.414459Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"8506dcd2-fb78-4237-b255-c6a719be0c80","_cell_guid":"2da09496-77d5-47f8-b23e-7a5ec47d475a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.416654Z","iopub.execute_input":"2025-05-19T15:37:59.416936Z","iopub.status.idle":"2025-05-19T15:37:59.447307Z","shell.execute_reply.started":"2025-05-19T15:37:59.416911Z","shell.execute_reply":"2025-05-19T15:37:59.446088Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling Numeric Features","metadata":{"_uuid":"1bbb0f62-0b1d-4d4f-8357-5b0c41781d60","_cell_guid":"b124b505-6d4b-417e-b3b8-ca82460fe740","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n# # train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'Calories']])\n# # test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n\n# train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n# test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n\n# train_df[['Age', 'BMI', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n# test_df[['Age', 'BMI', 'Duration', 'Heart_Rate', 'Body_Temp']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']])\n\n# train_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']] = scaler.fit_transform(train_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']])\n# test_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']] = scaler.transform(test_df[['Age', 'BMI', 'Duration_HR', 'Body_Temp']])\n\ntrain_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]] = scaler.fit_transform(train_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]])\ntest_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', 'Duration2_HR']] = scaler.transform(test_df[['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]])","metadata":{"_uuid":"8f51e5c8-81b8-4fd7-b757-c425ec86b0c1","_cell_guid":"706c6d45-0f72-4538-8f1f-ce4ec0ec6bfc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.448135Z","iopub.execute_input":"2025-05-19T15:37:59.448573Z","iopub.status.idle":"2025-05-19T15:37:59.69124Z","shell.execute_reply.started":"2025-05-19T15:37:59.448538Z","shell.execute_reply":"2025-05-19T15:37:59.689916Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{"_uuid":"32f6c039-cb8a-4346-bb16-e107b140ae0f","_cell_guid":"574b66aa-692c-40fd-b185-59d52af1afa7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# 1. Linear Regression","metadata":{"_uuid":"1beadc5a-a987-40bc-88db-4bab705250ae","_cell_guid":"82b3d528-d6e2-4361-8af8-e8391b3ffbcb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression","metadata":{"_uuid":"3a58d706-87b8-4edc-bac1-35667dfde275","_cell_guid":"f2120d4e-c571-48a8-818a-f83c38ea0d95","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.692696Z","iopub.execute_input":"2025-05-19T15:37:59.693056Z","iopub.status.idle":"2025-05-19T15:37:59.699303Z","shell.execute_reply.started":"2025-05-19T15:37:59.693025Z","shell.execute_reply":"2025-05-19T15:37:59.697757Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Features","metadata":{"_uuid":"6ce12bc7-2f9b-4143-9bd2-a0367f8f6372","_cell_guid":"3094689d-73f1-4504-aa60-b273c25872c9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# features = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n# features = ['Age', 'BMI', 'Duration', 'Heart_Rate', 'Body_Temp']\n# features = ['Age', 'BMI', 'Duration_HR', 'Body_Temp']\nfeatures = ['Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI', 'Duration_HR', \"Duration2_HR\"]","metadata":{"_uuid":"2e13cc95-2687-4092-b52a-fddc0939812c","_cell_guid":"ef95a2e3-5b03-4787-8dbf-9d780cd6e1ae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.700504Z","iopub.execute_input":"2025-05-19T15:37:59.70082Z","iopub.status.idle":"2025-05-19T15:37:59.724681Z","shell.execute_reply.started":"2025-05-19T15:37:59.700794Z","shell.execute_reply":"2025-05-19T15:37:59.723419Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Preparation","metadata":{"_uuid":"b40ffbbf-8a67-4dba-8532-3db5e523ed5f","_cell_guid":"ec7f1fe7-2902-4448-8df2-a16b60eb1111","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"X_train = train_df[features]\ny_train = train_df['Calories']","metadata":{"_uuid":"b57878fe-d12a-4b2e-8b4a-fd59236fff6c","_cell_guid":"c7ebcecd-076e-4931-b902-bc457243914f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.725837Z","iopub.execute_input":"2025-05-19T15:37:59.726268Z","iopub.status.idle":"2025-05-19T15:37:59.779262Z","shell.execute_reply.started":"2025-05-19T15:37:59.726236Z","shell.execute_reply":"2025-05-19T15:37:59.778342Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test = test_df[features]","metadata":{"_uuid":"972298cc-1ce0-4744-a380-615e29489800","_cell_guid":"22402664-4490-4356-ab07-dbe559108812","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.780381Z","iopub.execute_input":"2025-05-19T15:37:59.780739Z","iopub.status.idle":"2025-05-19T15:37:59.803611Z","shell.execute_reply.started":"2025-05-19T15:37:59.78071Z","shell.execute_reply":"2025-05-19T15:37:59.802509Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = X_train.fillna(0) # Fill NaNs in training features\nX_test = X_test.fillna(0) # Fill NaNs in test features","metadata":{"_uuid":"40254446-8994-4f60-ae7c-9e50bf239f4c","_cell_guid":"25ba0e1b-c3f8-41cc-bb73-5fe3e30193db","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.80476Z","iopub.execute_input":"2025-05-19T15:37:59.805099Z","iopub.status.idle":"2025-05-19T15:37:59.869268Z","shell.execute_reply.started":"2025-05-19T15:37:59.805068Z","shell.execute_reply":"2025-05-19T15:37:59.868357Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## K Fold CV","metadata":{"_uuid":"22d9e58d-d6ab-42d3-9c25-c274a82d3add","_cell_guid":"42584a4d-80b4-4be1-be8f-98740d63cc6e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from sklearn.model_selection import KFold  # For creating K-Fold cross-validation splits\nfrom sklearn.metrics import mean_squared_log_error # For calculating Mean Squared Logarithmic Error","metadata":{"_uuid":"6bc65f45-9dee-476c-b3ff-876703beeba7","_cell_guid":"151fc775-20e8-4844-acf6-eb3f052db9df","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.870286Z","iopub.execute_input":"2025-05-19T15:37:59.870566Z","iopub.status.idle":"2025-05-19T15:37:59.875463Z","shell.execute_reply.started":"2025-05-19T15:37:59.870545Z","shell.execute_reply":"2025-05-19T15:37:59.874478Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kfold_summary = []","metadata":{"_uuid":"18b3888a-3c07-4842-91f1-75fce92c9834","_cell_guid":"d00496d6-db3a-4f30-b22d-3fbae221b00f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.876512Z","iopub.execute_input":"2025-05-19T15:37:59.876797Z","iopub.status.idle":"2025-05-19T15:37:59.897447Z","shell.execute_reply.started":"2025-05-19T15:37:59.876775Z","shell.execute_reply":"2025-05-19T15:37:59.896359Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5 Fold CV","metadata":{"_uuid":"a43b5703-5e62-42ac-a546-23550c900428","_cell_guid":"fb00c35c-eb23-4da5-92b4-3ad0284b6fd4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# This KFold CV block assumes X_train and y_train are already defined and preprocessed\n# as they are in your script before the final model training:\n# - X_train: pandas DataFrame containing the selected features.\n#            It is assumed to have been derived from a globally scaled train_df\n#            and to have had NaNs filled (e.g., with X_train.fillna(0)).\n# - y_train: pandas Series containing the target variable 'Calories'.\n#            'Calories' must be non-negative for RMSLE. Your data exploration\n#            (train_df.describe()) should confirm this (min value >= 0).\n\n# --- START OF KFold CV CODE BLOCK (using RMSLE) ---","metadata":{"_uuid":"c16f5ce4-8b8d-4e96-986d-6165d2345488","_cell_guid":"5abd3c6c-6945-4973-a296-56c1848b9c48","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.898736Z","iopub.execute_input":"2025-05-19T15:37:59.899043Z","iopub.status.idle":"2025-05-19T15:37:59.921561Z","shell.execute_reply.started":"2025-05-19T15:37:59.899012Z","shell.execute_reply":"2025-05-19T15:37:59.920175Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"--- Preparing for K-Fold Cross-Validation with RMSLE ---\")\n# 1. Configure K-Fold Cross-Validation\nn_splits = 5  # Define the number of folds (k). 5 or 10 are common choices. More folds reduce bias in the performance estimate but increase variance and computational time.\nshuffle = True\nrandom_state=42\nkf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n                # Initialize KFold object.\n                # n_splits: Specifies the number of folds.\n                # shuffle=True: Shuffles the data randomly before splitting into folds. This is crucial\n                #               to ensure that folds are representative of the overall data, especially\n                #               if the data has some inherent ordering.\n                # random_state=42: Using a fixed random state ensures that the shuffle operation is\n                #                  the same every time the code runs. This makes the CV results reproducible.","metadata":{"_uuid":"cd293fd2-0ec3-4e1e-aee3-afe74c21bca1","_cell_guid":"e6f63f28-d68d-43b9-b611-2c4c88b8ab43","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.922773Z","iopub.execute_input":"2025-05-19T15:37:59.923735Z","iopub.status.idle":"2025-05-19T15:37:59.948522Z","shell.execute_reply.started":"2025-05-19T15:37:59.923707Z","shell.execute_reply":"2025-05-19T15:37:59.947459Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Prepare to store results from each fold\nfold_rmsle_scores = [] # List to store the Root Mean Squared Logarithmic Error (RMSLE) for each validation fold.\n                       # This helps in understanding the model's performance consistency using RMSLE.\noof_predictions = np.zeros(X_train.shape[0]) # Array to store out-of-fold (OOF) predictions.\n                                             # OOF predictions are made on data that the model (for that fold)\n                                             # was not trained on. The full array of OOF predictions can be\n                                             # used for a more robust single validation score or for ensembling.","metadata":{"_uuid":"7211a501-7045-49bb-8dca-ed54f9f56196","_cell_guid":"5447a265-bbda-4373-80e2-cbedade5f401","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.949514Z","iopub.execute_input":"2025-05-19T15:37:59.949758Z","iopub.status.idle":"2025-05-19T15:37:59.978302Z","shell.execute_reply.started":"2025-05-19T15:37:59.94974Z","shell.execute_reply":"2025-05-19T15:37:59.977223Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"--- Starting {n_splits}-Fold Cross-Validation for Linear Regression (evaluating with RMSLE) ---\\n\\n\")\n\n# 3. Iterate through each fold\n# The kf.split(X_train, y_train) method generates pairs of indices:\n# - train_idx: Indices for the data points to be used for training in the current fold.\n# - val_idx: Indices for the data points to be used for validation in the current fold.\n# 'enumerate' is used to get both the fold number (starting from 0) and the indices.\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n    print(f\"\\n  Processing Fold {fold + 1}/{n_splits}...\")\n\n    # 3.1. Split data into training and validation sets for the current fold\n    # .iloc is used to select rows from pandas DataFrames (X_train) and Series (y_train) based on integer indices.\n    X_train_fold = X_train.iloc[train_idx]  # Features for training in this specific fold.\n    y_train_fold = y_train.iloc[train_idx]  # Target variable for training in this specific fold.\n    X_val_fold = X_train.iloc[val_idx]    # Features for validation in this specific fold.\n    y_val_fold = y_train.iloc[val_idx]    # Target variable for validation in this specific fold.\n                                          # For RMSLE, y_val_fold must be non-negative.\n\n    # --- Note on Preprocessing (Scaling/Imputation) within CV ---\n    # As in the previous RMSE version, this CV block uses the already-globally-scaled `X_train`.\n    # For a more rigorous CV, scaling should be fit on X_train_fold and transformed on both.\n    # NaNs are assumed to be handled prior to this block (`X_train = X_train.fillna(0)`).\n\n\n    \n    start_time = time.time()  # Record start time\n    # 3.2. Initialize a new model instance for each fold\n    # It's important to create a new, untrained model instance for each fold.\n    model_fold = LinearRegression()\n    end_time = time.time()  # Record end time\n    print(f\"Initialize a new model instance for each fold.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    \n    start_time = time.time()  # Record start time\n    # 3.3. Train the model on the current fold's training data\n    model_fold.fit(X_train_fold, y_train_fold)\n    print(f\"    Model trained for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Train the model on the current fold's training data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    \n    start_time = time.time()  # Record start time\n    # 3.4. Make predictions on the current fold's validation data\n    val_preds = model_fold.predict(X_val_fold)\n    print(f\"    Predictions made for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Make predictions on the current fold's validation data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    # 3.5. Handle negative predictions (CRUCIAL for RMSLE)\n    # RMSLE (specifically, mean_squared_log_error) requires non-negative inputs for both true and predicted values.\n    # Your original script converts negative predictions by taking their absolute value.\n    # This is important here to avoid errors with `log(1 + pred)` if `pred` is too negative.\n    # We ensure predictions are non-negative.\n    val_preds[val_preds < 0] = -val_preds[val_preds < 0] # Makes them positive\n    # If any true values in y_val_fold could be negative, they would also need to be clipped to 0 or handled.\n    # However, 'Calories' should naturally be non-negative.\n\n    # 3.6. Store out-of-fold (OOF) predictions\n    # The (non-negatively adjusted) predictions for the validation set of the current fold\n    # are stored in the corresponding positions of the oof_predictions array.\n    oof_predictions[val_idx] = val_preds\n\n    # 3.7. Evaluate the model's performance on the validation set for this fold using RMSLE\n    # `mean_squared_log_error` calculates MSLE. We take its square root to get RMSLE.\n    # Both y_val_fold (true values) and val_preds (predictions) must be non-negative.\n    try:\n        fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n        fold_rmsle_scores.append(fold_rmsle) # Store the RMSLE for this fold.\n        print(f\"    Fold {fold + 1} RMSLE: {fold_rmsle:.4f}\")\n    except ValueError as e:\n        # This might happen if, despite efforts, negative values sneak into y_val_fold or val_preds.\n        # Or if y_val_fold contains values that are problematic for log(1+y).\n        print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n        print(f\"    Min y_val_fold: {y_val_fold.min()}, Min val_preds: {np.min(val_preds)}\")\n        # Add a placeholder or skip this fold's score if an error occurs.\n        # For robustness, you might add a large penalty value or handle it as per your strategy.\n        fold_rmsle_scores.append(np.nan) # Or some other indicator of failure","metadata":{"_uuid":"d00cf7f5-d44d-40d9-b359-ee3aa348b016","_cell_guid":"bc310e60-e708-4893-9660-35aaf0171218","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:37:59.979628Z","iopub.execute_input":"2025-05-19T15:37:59.980147Z","iopub.status.idle":"2025-05-19T15:38:02.424179Z","shell.execute_reply.started":"2025-05-19T15:37:59.980123Z","shell.execute_reply":"2025-05-19T15:38:02.422104Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Summarize Cross-Validation Results\n# After iterating through all folds, calculate the average and standard deviation of the RMSLE scores.\n# Filter out NaNs if any occurred during RMSLE calculation.\nvalid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\nif valid_fold_rmsle_scores:\n    mean_cv_rmsle = np.mean(valid_fold_rmsle_scores) # Average RMSLE provides an estimate of performance.\n    std_cv_rmsle = np.std(valid_fold_rmsle_scores)   # Standard deviation indicates consistency.\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    kfold_summary.append(\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\")\n    print(f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\")\n    \n    txt1 = f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\"\n    txt2 = f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\"\n    kfold_summary.append(txt1)\n    kfold_summary.append(txt2)\nelse:\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"RMSLE calculation failed for all folds.\")\n\n\n# (Optional) Calculate overall OOF RMSLE using all out-of-fold predictions\n# This provides a single RMSLE score for the entire training dataset.\n# Ensure y_train and oof_predictions are non-negative.\n# oof_predictions were already adjusted. y_train (Calories) should be non-negative.\nif y_train.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n    try:\n        overall_oof_rmsle = np.sqrt(mean_squared_log_error(y_train, oof_predictions))\n        print(f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\")\n        \n        txt3 = f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\"\n        kfold_summary.append(txt3)\n    except ValueError as e:\n        print(f\"Error calculating Overall OOF RMSLE: {e}\")\n        print(f\"Min y_train: {y_train.min()}, Min oof_predictions: {oof_predictions.min()}\")\nelse:\n    if y_train.min() < 0:\n        print(\"Cannot calculate Overall OOF RMSLE: y_train contains negative values.\")\n    if oof_predictions.min() < 0: # Should not happen due to adjustment\n        print(\"Cannot calculate Overall OOF RMSLE: oof_predictions contain negative values.\")\n    if not valid_fold_rmsle_scores:\n        print(\"Cannot calculate Overall OOF RMSLE: No valid fold scores were obtained.\")\n\n# --- END OF KFold CV CODE BLOCK (using RMSLE) ---\n\n# Following this CV block, your script would typically proceed to train the final\n# LinearRegression model on the *entire* X_train and y_train dataset.\n# The CV results (especially mean_cv_rmsle) help you to gauge how well this\n# final model is likely to perform on the actual test data, when evaluated with RMSLE.\n# Remember to apply the same non-negative adjustment to your final test predictions\n# if you were to evaluate them with RMSLE.","metadata":{"_uuid":"e04acd53-e430-4941-8973-050248dbf87c","_cell_guid":"a6609123-03a5-4105-a503-9d37c4100895","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:02.424954Z","iopub.execute_input":"2025-05-19T15:38:02.425215Z","iopub.status.idle":"2025-05-19T15:38:02.456166Z","shell.execute_reply.started":"2025-05-19T15:38:02.425186Z","shell.execute_reply":"2025-05-19T15:38:02.454916Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10 Fold CV","metadata":{"_uuid":"6db193dc-3900-4e6a-b255-31da2228e6b7","_cell_guid":"92ed3c3b-c443-4dbd-b388-3597e5ba719a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 1. Configure K-Fold Cross-Validation\nn_splits = 10\nshuffle = True\nrandom_state=42\nprint(f\"--- Preparing for K-Fold Cross-Validation with RMSLE ---\")\nkf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)","metadata":{"_uuid":"7fa5b2aa-c3f4-4a23-804c-a691fd3afc20","_cell_guid":"ef8311e7-bfa9-4602-b89e-d74c1125bfae","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:02.458342Z","iopub.execute_input":"2025-05-19T15:38:02.458899Z","iopub.status.idle":"2025-05-19T15:38:02.472741Z","shell.execute_reply.started":"2025-05-19T15:38:02.458873Z","shell.execute_reply":"2025-05-19T15:38:02.471348Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Prepare to store results from each fold\nfold_rmsle_scores = []\noof_predictions = np.zeros(X_train.shape[0])\n\nprint(f\"--- Starting {n_splits}-Fold Cross-Validation for Linear Regression (evaluating with RMSLE) ---\\n\\n\")\n\n# 3. Iterate through each fold\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n    print(f\"\\n  Processing Fold {fold + 1}/{n_splits}...\")\n    X_train_fold = X_train.iloc[train_idx]  # Features for training in this specific fold.\n    y_train_fold = y_train.iloc[train_idx]  # Target variable for training in this specific fold.\n    X_val_fold = X_train.iloc[val_idx]    # Features for validation in this specific fold.\n    y_val_fold = y_train.iloc[val_idx]\n    \n    start_time = time.time()  # Record start time\n    # 3.2. Initialize a new model instance for each fold\n    # It's important to create a new, untrained model instance for each fold.\n    model_fold = LinearRegression()\n    end_time = time.time()  # Record end time\n    print(f\"Initialize a new model instance for each fold.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.3. Train the model on the current fold's training data\n    model_fold.fit(X_train_fold, y_train_fold)\n    print(f\"    Model trained for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Train the model on the current fold's training data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.4. Make predictions on the current fold's validation data\n    val_preds = model_fold.predict(X_val_fold)\n    print(f\"    Predictions made for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Make predictions on the current fold's validation data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    # 3.5. Handle negative predictions (CRUCIAL for RMSLE)\n    val_preds[val_preds < 0] = -val_preds[val_preds < 0]\n\n    # 3.6. Store out-of-fold (OOF) predictions\n    oof_predictions[val_idx] = val_preds\n\n    # 3.7. Evaluate the model's performance on the validation set for this fold using RMSLE\n    try:\n        fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n        fold_rmsle_scores.append(fold_rmsle) # Store the RMSLE for this fold.\n        print(f\"    Fold {fold + 1} RMSLE: {fold_rmsle:.4f}\")\n    except ValueError as e:\n        print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n        print(f\"    Min y_val_fold: {y_val_fold.min()}, Min val_preds: {np.min(val_preds)}\")\n        fold_rmsle_scores.append(np.nan) # Or some other indicator of failure\n\n# 4. Summarize Cross-Validation Results\nvalid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\nif valid_fold_rmsle_scores:\n    mean_cv_rmsle = np.mean(valid_fold_rmsle_scores) # Average RMSLE provides an estimate of performance.\n    std_cv_rmsle = np.std(valid_fold_rmsle_scores)   # Standard deviation indicates consistency.\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\")\n    print(f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\")\nelse:\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"RMSLE calculation failed for all folds.\")\n\nif y_train.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n    try:\n        overall_oof_rmsle = np.sqrt(mean_squared_log_error(y_train, oof_predictions))\n        print(f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\")\n        \n        txt3 = f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\"\n        kfold_summary.append(txt3)\n    except ValueError as e:\n        print(f\"Error calculating Overall OOF RMSLE: {e}\")\n        print(f\"Min y_train: {y_train.min()}, Min oof_predictions: {oof_predictions.min()}\")\nelse:\n    if y_train.min() < 0:\n        print(\"Cannot calculate Overall OOF RMSLE: y_train contains negative values.\")\n    if oof_predictions.min() < 0: # Should not happen due to adjustment\n        print(\"Cannot calculate Overall OOF RMSLE: oof_predictions contain negative values.\")\n    if not valid_fold_rmsle_scores:\n        print(\"Cannot calculate Overall OOF RMSLE: No valid fold scores were obtained.\")\n\n# --- END OF KFold CV CODE BLOCK (using RMSLE) ---","metadata":{"_uuid":"a25111ae-633d-476d-9cc8-a41396de281b","_cell_guid":"d7e973f9-adbb-4e39-b2b3-a6429a3880c8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:02.473778Z","iopub.execute_input":"2025-05-19T15:38:02.47412Z","iopub.status.idle":"2025-05-19T15:38:07.521747Z","shell.execute_reply.started":"2025-05-19T15:38:02.474092Z","shell.execute_reply":"2025-05-19T15:38:07.520565Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 15 Fold CV","metadata":{"_uuid":"c62bbb19-b455-4aff-bd61-076750a591cc","_cell_guid":"961e0c12-f650-4c57-bc54-2d496ea33598","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 1. Configure K-Fold Cross-Validation\nn_splits = 15\nshuffle = True\nrandom_state=42\nprint(f\"--- Preparing for K-Fold Cross-Validation with RMSLE ---\")\nkf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)","metadata":{"_uuid":"37ec10b2-3db5-40b9-a84d-9d82bb0fae6c","_cell_guid":"9b0a4427-956c-4fb0-8423-658b7169bea2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:07.522817Z","iopub.execute_input":"2025-05-19T15:38:07.523159Z","iopub.status.idle":"2025-05-19T15:38:07.530831Z","shell.execute_reply.started":"2025-05-19T15:38:07.523128Z","shell.execute_reply":"2025-05-19T15:38:07.529585Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Prepare to store results from each fold\nfold_rmsle_scores = []\noof_predictions = np.zeros(X_train.shape[0])\n\nprint(f\"--- Starting {n_splits}-Fold Cross-Validation for Linear Regression (evaluating with RMSLE) ---\\n\\n\")\n\n# 3. Iterate through each fold\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n    print(f\"\\n  Processing Fold {fold + 1}/{n_splits}...\")\n    X_train_fold = X_train.iloc[train_idx]  # Features for training in this specific fold.\n    y_train_fold = y_train.iloc[train_idx]  # Target variable for training in this specific fold.\n    X_val_fold = X_train.iloc[val_idx]    # Features for validation in this specific fold.\n    y_val_fold = y_train.iloc[val_idx]\n    \n    start_time = time.time()  # Record start time\n    # 3.2. Initialize a new model instance for each fold\n    # It's important to create a new, untrained model instance for each fold.\n    model_fold = LinearRegression()\n    end_time = time.time()  # Record end time\n    print(f\"Initialize a new model instance for each fold.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.3. Train the model on the current fold's training data\n    model_fold.fit(X_train_fold, y_train_fold)\n    print(f\"    Model trained for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Train the model on the current fold's training data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    start_time = time.time()  # Record start time\n    # 3.4. Make predictions on the current fold's validation data\n    val_preds = model_fold.predict(X_val_fold)\n    print(f\"    Predictions made for Fold {fold + 1}.\")\n    end_time = time.time()  # Record end time\n    print(f\"Make predictions on the current fold's validation data.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n    # 3.5. Handle negative predictions (CRUCIAL for RMSLE)\n    val_preds[val_preds < 0] = -val_preds[val_preds < 0]\n\n    # 3.6. Store out-of-fold (OOF) predictions\n    oof_predictions[val_idx] = val_preds\n\n    # 3.7. Evaluate the model's performance on the validation set for this fold using RMSLE\n    try:\n        fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n        fold_rmsle_scores.append(fold_rmsle) # Store the RMSLE for this fold.\n        print(f\"    Fold {fold + 1} RMSLE: {fold_rmsle:.4f}\")\n    except ValueError as e:\n        print(f\"    Error calculating RMSLE for Fold {fold + 1}: {e}\")\n        print(f\"    Min y_val_fold: {y_val_fold.min()}, Min val_preds: {np.min(val_preds)}\")\n        fold_rmsle_scores.append(np.nan) # Or some other indicator of failure\n\n# 4. Summarize Cross-Validation Results\nvalid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\nif valid_fold_rmsle_scores:\n    mean_cv_rmsle = np.mean(valid_fold_rmsle_scores) # Average RMSLE provides an estimate of performance.\n    std_cv_rmsle = np.std(valid_fold_rmsle_scores)   # Standard deviation indicates consistency.\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"Average RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {mean_cv_rmsle:.4f}\")\n    print(f\"Standard Deviation of RMSLE across {len(valid_fold_rmsle_scores)} valid folds: {std_cv_rmsle:.4f}\")\nelse:\n    print(f\"--- Cross-Validation Summary (RMSLE) ---\")\n    print(f\"RMSLE calculation failed for all folds.\")\n\nif y_train.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n    try:\n        overall_oof_rmsle = np.sqrt(mean_squared_log_error(y_train, oof_predictions))\n        print(f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\")\n        \n        txt3 = f\"Overall OOF RMSLE (from concatenated fold predictions): {overall_oof_rmsle:.4f}\"\n        kfold_summary.append(txt3)\n    except ValueError as e:\n        print(f\"Error calculating Overall OOF RMSLE: {e}\")\n        print(f\"Min y_train: {y_train.min()}, Min oof_predictions: {oof_predictions.min()}\")\nelse:\n    if y_train.min() < 0:\n        print(\"Cannot calculate Overall OOF RMSLE: y_train contains negative values.\")\n    if oof_predictions.min() < 0: # Should not happen due to adjustment\n        print(\"Cannot calculate Overall OOF RMSLE: oof_predictions contain negative values.\")\n    if not valid_fold_rmsle_scores:\n        print(\"Cannot calculate Overall OOF RMSLE: No valid fold scores were obtained.\")\n\n# --- END OF KFold CV CODE BLOCK (using RMSLE) ---","metadata":{"_uuid":"d863d55d-c224-434f-b407-a819a0067c43","_cell_guid":"dcbd59c6-0a80-4d58-b50b-c69eb4ec33e8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:07.531975Z","iopub.execute_input":"2025-05-19T15:38:07.532299Z","iopub.status.idle":"2025-05-19T15:38:16.159045Z","shell.execute_reply.started":"2025-05-19T15:38:07.532275Z","shell.execute_reply":"2025-05-19T15:38:16.157522Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## KFold CV Summary","metadata":{"_uuid":"a2514055-dad2-4a97-abb2-e92529700a54","_cell_guid":"6141e612-cdb1-4cef-91ec-b91d1250ea96","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"for i in kfold_summary:\n    print(i)","metadata":{"_uuid":"dec0a71e-c16e-4462-9d79-52bd6b5338db","_cell_guid":"d93f92af-c36f-4303-b099-aa1f0b3e14e4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.160429Z","iopub.execute_input":"2025-05-19T15:38:16.160814Z","iopub.status.idle":"2025-05-19T15:38:16.168129Z","shell.execute_reply.started":"2025-05-19T15:38:16.16078Z","shell.execute_reply":"2025-05-19T15:38:16.16615Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initialize model","metadata":{"_uuid":"382d9cab-4e18-428e-b69f-406e92b92307","_cell_guid":"385302fb-3fd5-489e-b2f7-7441ead129c3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%time\nmodel = LinearRegression()","metadata":{"_uuid":"5654f14d-a0ef-430b-bd67-fd7b88b70aa9","_cell_guid":"dd0fcbe4-3335-4c41-9552-9970522fae35","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.169099Z","iopub.execute_input":"2025-05-19T15:38:16.169497Z","iopub.status.idle":"2025-05-19T15:38:16.202476Z","shell.execute_reply.started":"2025-05-19T15:38:16.169463Z","shell.execute_reply":"2025-05-19T15:38:16.200439Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train","metadata":{"_uuid":"d3dd427e-40cc-47b0-b59c-c9f1b88209dc","_cell_guid":"66ee5b71-93d5-4d3a-be9b-99d5f60d3d7b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%time\nprint(\"Training Linear Regression model...\")\nmodel.fit(X_train, y_train)\nprint(\"Training complete.\")","metadata":{"_uuid":"c01343de-f624-4344-b63e-652b3e5d5102","_cell_guid":"74125306-fc01-43d0-940b-28cf5e0f19e7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.203725Z","iopub.execute_input":"2025-05-19T15:38:16.204277Z","iopub.status.idle":"2025-05-19T15:38:16.725955Z","shell.execute_reply.started":"2025-05-19T15:38:16.204244Z","shell.execute_reply":"2025-05-19T15:38:16.724471Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predict","metadata":{"_uuid":"dc48767a-1628-403a-888a-30aac39776ed","_cell_guid":"3a98872f-1fce-4dce-a214-f40f53ff95b0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"%%time\npredictions = model.predict(X_test)","metadata":{"_uuid":"fa511b0c-ba80-4ed9-91e7-1b8440b3e1aa","_cell_guid":"159f93d7-69d6-4fde-a3e9-574b3db1355d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.727194Z","iopub.execute_input":"2025-05-19T15:38:16.727601Z","iopub.status.idle":"2025-05-19T15:38:16.742917Z","shell.execute_reply.started":"2025-05-19T15:38:16.727565Z","shell.execute_reply":"2025-05-19T15:38:16.741657Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Handle negative predictions","metadata":{"_uuid":"4a094039-8100-434d-a17b-bfe0b81a1269","_cell_guid":"196e8168-4864-4e1a-9948-d1f04c6ee44d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"for i in range(len(predictions)):\n    if predictions[i]<0:\n        # print(f\"i : {i} ;\\t; predictions[{i}] : {predictions[i]}\")\n        predictions[i]=-predictions[i]","metadata":{"_uuid":"66749da6-e346-4c1a-ae90-a46174f3aec6","_cell_guid":"0419c486-6167-4058-b409-f69443322bc8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.744157Z","iopub.execute_input":"2025-05-19T15:38:16.744453Z","iopub.status.idle":"2025-05-19T15:38:16.828231Z","shell.execute_reply.started":"2025-05-19T15:38:16.74443Z","shell.execute_reply":"2025-05-19T15:38:16.827086Z"},"scrolled":true,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save CSV","metadata":{"_uuid":"2bf5a55a-b916-4e48-a5f6-b914edaf5659","_cell_guid":"ca055068-162b-4289-ba68-327fcf426246","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"submission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions})","metadata":{"_uuid":"6be6eda1-6422-4161-abbc-6a1604cc7484","_cell_guid":"0c459b33-315c-4328-b5ae-2740a5059f36","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.829518Z","iopub.execute_input":"2025-05-19T15:38:16.829811Z","iopub.status.idle":"2025-05-19T15:38:16.836426Z","shell.execute_reply.started":"2025-05-19T15:38:16.829788Z","shell.execute_reply":"2025-05-19T15:38:16.835485Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.to_csv('linear_regression_submission.csv', index=False)\nprint(\"\\nSubmission file 'linear_regression_submission.csv' created successfully.\")","metadata":{"_uuid":"5c486e3d-bd0a-4e0d-88eb-02205bfa3fc3","_cell_guid":"909421cc-2f49-420f-b89b-9290631ee2d9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:16.837433Z","iopub.execute_input":"2025-05-19T15:38:16.837719Z","iopub.status.idle":"2025-05-19T15:38:17.460903Z","shell.execute_reply.started":"2025-05-19T15:38:16.837693Z","shell.execute_reply":"2025-05-19T15:38:17.459879Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Coefficients","metadata":{"_uuid":"d047181c-e7c0-4a0f-a7e4-d06cbf1792d2","_cell_guid":"b1ff7589-05f0-4abd-83df-32828699739d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"print(\"\\nModel Coefficients:\")\nfor feature, coef in zip(features, model.coef_):\n    print(f\"{feature}: {coef:.6f}\")","metadata":{"_uuid":"1b2df6b9-43cd-44e1-9aad-0a89569708e2","_cell_guid":"4f5cb2e5-b6e1-4604-aaef-de2bff13d8c4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-05-19T15:38:17.461858Z","iopub.execute_input":"2025-05-19T15:38:17.462096Z","iopub.status.idle":"2025-05-19T15:38:17.468378Z","shell.execute_reply.started":"2025-05-19T15:38:17.462077Z","shell.execute_reply":"2025-05-19T15:38:17.467354Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nfor i in range(10):\n    start_time = time.time()  # Record start time\n    print(i)\n    end_time = time.time()  # Record end time\n    print(f\"Time taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds","metadata":{"_uuid":"55b5e804-922f-4d01-9fcf-80a08c5091ec","_cell_guid":"0cbca7e7-cdd1-4261-8b14-b2fcd14ab5ac","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-19T15:38:17.469416Z","iopub.execute_input":"2025-05-19T15:38:17.469737Z","iopub.status.idle":"2025-05-19T15:38:17.4943Z","shell.execute_reply.started":"2025-05-19T15:38:17.469708Z","shell.execute_reply":"2025-05-19T15:38:17.493324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Decision Tree Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntest_size=0.2\nrandom_state=42\n\nmodel_dt = DecisionTreeRegressor(random_state=random_state)\n\nprint(\"Training Decision Tree Regressor model...\")\n# 4. Train the model\nmodel_dt.fit(X_train, y_train)\nprint(\"Training complete.\")\n\nprint(\"Making predictions with Decision Tree Regressor...\")\n# 5. Make predictions on the test data\npredictions_dt = model_dt.predict(X_test)\nprint(\"Predictions made.\")\n\n# 6. Print the predictions\nprint(\"\\nTest Data Predictions:\")\nprint(predictions_dt)","metadata":{"_uuid":"9b807b05-a404-4e3d-97c1-a9b3f9f4befb","_cell_guid":"d8c85de8-003d-4ec1-8183-c9ed6b8a5ed8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-05-19T15:46:41.623383Z","iopub.execute_input":"2025-05-19T15:46:41.623747Z","iopub.status.idle":"2025-05-19T15:46:48.815948Z","shell.execute_reply.started":"2025-05-19T15:46:41.623722Z","shell.execute_reply":"2025-05-19T15:46:48.814753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_dt)):\n    if predictions_dt[i]<0:\n        # print(f\"i : {i} ;\\t; predictions[{i}] : {predictions[i]}\")\n        predictions_dt[i]=-predictions_dt[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_dt})\n\nsubmission_df.to_csv('Decision_Tree_Regressor.csv', index=False)\nprint(\"\\nSubmission file 'Decision_Tree_Regressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:43:31.489668Z","iopub.execute_input":"2025-05-19T15:43:31.489999Z","iopub.status.idle":"2025-05-19T15:43:31.88596Z","shell.execute_reply.started":"2025-05-19T15:43:31.489975Z","shell.execute_reply":"2025-05-19T15:43:31.884847Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nn_estimators=100\nrandom_state=42\n\n# 3. Initialize the Random Forest Regressor model\n# model_rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\nmodel_rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state, n_jobs=-1)\n# n_jobs=-1 uses all available CPU cores for parallel processing, often speeding up training.\n\nstart_time = time.time()  # Record start time\nprint(\"Training Random Forest Regressor model...\")\n# 4. Train the model\nmodel_rf.fit(X_train, y_train)\nprint(\"Training complete.\")\nend_time = time.time()  # Record end time\nprint(f\"Training Random Forest Regressor model.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\nstart_time = time.time()  # Record start time\nprint(\"Making predictions with Random Forest Regressor...\")\n# 5. Make predictions on the test data\npredictions_rf = model_rf.predict(X_test)\nprint(\"Predictions made.\")\nend_time = time.time()  # Record end time\nprint(f\"Making predictions with Random Forest Regressor.\\tTime taken: {(end_time - start_time) * 1000:.3f} ms\")  # Print time in milliseconds\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions:\")\nprint(predictions_rf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T15:52:03.516442Z","iopub.execute_input":"2025-05-19T15:52:03.517467Z","iopub.status.idle":"2025-05-19T16:00:24.601283Z","shell.execute_reply.started":"2025-05-19T15:52:03.517435Z","shell.execute_reply":"2025-05-19T16:00:24.600219Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_rf)):\n    if predictions_rf[i]<0:\n        predictions_rf[i]=-predictions_rf[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_rf})\n\nsubmission_df.to_csv('Random_Forest_Regressor.csv', index=False)\nprint(\"\\nSubmission file 'Random_Forest_Regressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:00:24.602981Z","iopub.execute_input":"2025-05-19T16:00:24.60334Z","iopub.status.idle":"2025-05-19T16:00:25.051929Z","shell.execute_reply.started":"2025-05-19T16:00:24.603309Z","shell.execute_reply":"2025-05-19T16:00:25.050948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(model_rf.feature_importances_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:00:25.052893Z","iopub.execute_input":"2025-05-19T16:00:25.053234Z","iopub.status.idle":"2025-05-19T16:00:25.956033Z","shell.execute_reply.started":"2025-05-19T16:00:25.053205Z","shell.execute_reply":"2025-05-19T16:00:25.955119Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Gradient Boosting Regressor (from scikit-learn)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\nn_estimators=100\nlearning_rate=0.1\nmax_depth=3\nrandom_state=42\n\nmodel_gbr = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state)\n\nprint(\"Training Gradient Boosting Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_gbr.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with Gradient Boosting Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_gbr = model_gbr.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions (Gradient Boosting Regressor):\")\nprint(predictions_gbr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:04:27.350202Z","iopub.execute_input":"2025-05-19T16:04:27.350541Z","iopub.status.idle":"2025-05-19T16:06:58.25452Z","shell.execute_reply.started":"2025-05-19T16:04:27.35052Z","shell.execute_reply":"2025-05-19T16:06:58.253338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_gbr)):\n    if predictions_gbr[i]<0:\n        predictions_gbr[i]=-predictions_gbr[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_gbr})\n\nsubmission_df.to_csv('Gradient_Boosting_Regressor.csv', index=False)\nprint(\"\\nSubmission file 'Gradient_Boosting_Regressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:06:58.255993Z","iopub.execute_input":"2025-05-19T16:06:58.256367Z","iopub.status.idle":"2025-05-19T16:06:58.906616Z","shell.execute_reply.started":"2025-05-19T16:06:58.256342Z","shell.execute_reply":"2025-05-19T16:06:58.894423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. XGBoost Regressor","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\n# # 1. Create sample data\n# data = {'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n#         'Feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n#         'Target': [100, 120, 130, 150, 160, 170, 180, 190, 200, 210]}\n# df = pd.DataFrame(data)\n\n# # Define features (X) and target (y)\n# X = df[['Feature1', 'Feature2']]\n# y = df['Target']\n\n# # 2. Split data into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 3. Initialize the XGBoost Regressor model\n# Key parameters for potential optimization:\n# n_estimators: Number of boosting rounds.\n# learning_rate: Step size shrinkage used in update to prevent overfitting.\n# max_depth: Maximum depth of a tree.\n# n_jobs: Number of parallel threads. Use -1 to use all available cores.\n# tree_method: Algorithm used to construct the trees ('auto', 'exact', 'approx', 'hist'). 'hist' is often faster for large datasets.\n\nn_estimators=100\nlearning_rate=0.1\nmax_depth=3\nrandom_state=42\nn_jobs=-1\nmodel_xgb = xgb.XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=random_state, n_jobs=n_jobs)\n\nprint(\"Training XGBoost Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_xgb.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with XGBoost Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_xgb = model_xgb.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions (XGBoost Regressor):\")\nprint(predictions_xgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:18:39.950919Z","iopub.execute_input":"2025-05-19T16:18:39.951299Z","iopub.status.idle":"2025-05-19T16:18:42.524041Z","shell.execute_reply.started":"2025-05-19T16:18:39.951272Z","shell.execute_reply":"2025-05-19T16:18:42.523283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_xgb)):\n    if predictions_xgb[i]<0:\n        predictions_xgb[i]=-predictions_xgb[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_xgb})\n\nsubmission_df.to_csv('xgboost.csv', index=False)\nprint(\"\\nSubmission file 'xgboost.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:18:42.525002Z","iopub.execute_input":"2025-05-19T16:18:42.525609Z","iopub.status.idle":"2025-05-19T16:18:43.528495Z","shell.execute_reply.started":"2025-05-19T16:18:42.525579Z","shell.execute_reply":"2025-05-19T16:18:43.527631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. LightGBM Regressor","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n\n# 3. Initialize the LightGBM Regressor model\n# LightGBM is often faster than XGBoost and scikit-learn's GBR, especially on large datasets.\n# Key parameters for potential optimization:\n# n_estimators: Number of boosting rounds.\n# learning_rate: Step size shrinkage.\n# num_leaves: Maximum number of leaves in one tree (main complexity parameter).\n# n_jobs: Number of parallel threads. Use -1 to use all available cores.\n\nn_estimators=100\nlearning_rate=0.1\n# max_depth=3\nnum_leaves=31\nrandom_state=42\nn_jobs=-1\n\nmodel_lgb = lgb.LGBMRegressor(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves, random_state=random_state, n_jobs=n_jobs)\n\nprint(\"Training LightGBM Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_lgb.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with LightGBM Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_lgb = model_lgb.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nSample Test Data Predictions (LightGBM Regressor):\")\nprint(predictions_lgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:20:20.14462Z","iopub.execute_input":"2025-05-19T16:20:20.145024Z","iopub.status.idle":"2025-05-19T16:20:24.231936Z","shell.execute_reply.started":"2025-05-19T16:20:20.144998Z","shell.execute_reply":"2025-05-19T16:20:24.230794Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_lgb)):\n    if predictions_lgb[i]<0:\n        predictions_lgb[i]=-predictions_lgb[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_lgb})\n\nsubmission_df.to_csv('LightGBM.csv', index=False)\nprint(\"\\nSubmission file 'LightGBM.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:20:24.613013Z","iopub.execute_input":"2025-05-19T16:20:24.613458Z","iopub.status.idle":"2025-05-19T16:20:25.252737Z","shell.execute_reply.started":"2025-05-19T16:20:24.613431Z","shell.execute_reply":"2025-05-19T16:20:25.251795Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. CatBoost Regressor","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\n# 3. Initialize the CatBoost Regressor model\n# CatBoost is known for handling categorical features well and often provides good out-of-the-box results.\n# Key parameters for potential optimization:\n# iterations: Number of boosting iterations (trees).\n# learning_rate: Step size shrinkage.\n# depth: Depth of the trees.\n# l2_leaf_reg: L2 regularization term on weights.\n# verbose: Controls the amount of output during training (set to 0 for less output).\n# thread_count: Number of parallel threads. Use -1 to use all available cores.\n\niterations=100\nlearning_rate=0.1\ndepth=3\nrandom_state=42\nverbose=0\nthread_count=-1\n\nmodel_cat = CatBoostRegressor(iterations=iterations, learning_rate=learning_rate, depth=depth, random_state=random_state, verbose=verbose, thread_count=thread_count) # Set verbose to 0 for less output\n\nprint(\"Training CatBoost Regressor model...\")\nstart_time = time.time()\n# 4. Train the model\nmodel_cat.fit(X_train, y_train)\nend_time = time.time()\nprint(f\"Training complete in {end_time - start_time:.4f} seconds.\")\n\nprint(\"Making predictions with CatBoost Regressor...\")\nstart_time = time.time()\n# 5. Make predictions on the test data\npredictions_cat = model_cat.predict(X_test)\nend_time = time.time()\nprint(f\"Predictions made in {end_time - start_time:.4f} seconds.\")\n\n# 6. Print the predictions\nprint(\"\\nTest Data Predictions (CatBoost Regressor):\")\nprint(predictions_cat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:22:06.776059Z","iopub.execute_input":"2025-05-19T16:22:06.776383Z","iopub.status.idle":"2025-05-19T16:22:10.979169Z","shell.execute_reply.started":"2025-05-19T16:22:06.776364Z","shell.execute_reply":"2025-05-19T16:22:10.978211Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save submission.csv","metadata":{}},{"cell_type":"code","source":"for i in range(len(predictions_cat)):\n    if predictions_cat[i]<0:\n        predictions_cat[i]=-predictions_cat[i]\n\nsubmission_df = pd.DataFrame({'id': test_ids, 'Calories': predictions_cat})\n\nsubmission_df.to_csv('CatBoostRegressor.csv', index=False)\nprint(\"\\nSubmission file 'CatBoostRegressor.csv' created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:22:10.980753Z","iopub.execute_input":"2025-05-19T16:22:10.981033Z","iopub.status.idle":"2025-05-19T16:22:11.623273Z","shell.execute_reply.started":"2025-05-19T16:22:10.981012Z","shell.execute_reply":"2025-05-19T16:22:11.621907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}