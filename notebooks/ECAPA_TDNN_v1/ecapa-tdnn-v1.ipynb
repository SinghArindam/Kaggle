{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10545331,"sourceType":"datasetVersion","datasetId":6524657},{"sourceId":10671289,"sourceType":"datasetVersion","datasetId":6609570},{"sourceId":10671348,"sourceType":"datasetVersion","datasetId":6609614}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# print(\"Input Dir :\")\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nprint(\"Output Dir :\")\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install jupyter_core","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/TaoRuijie/ECAPA-TDNN.git\n!cp /kaggle/input/trainecapamodel/trainECAPAModel.py /kaggle/working/ECAPA-TDNN/trainECAPAModel.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n# print(\"Input Dir :\")\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\nprint(\"Output Dir :\")\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sudo apt-get update && sudo apt-get install -y python3.7 python3.7 python3.7-venv python3-pip\n!sudo rm /usr/bin/python3\n!sudo ln -s /usr/bin/python3.7 /usr/bin/python3\n!sudo ln -sf /usr/bin/python3.7 /usr/bin/python\n\n!python --version\n!python3 --version\n!which python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install jupyter_core","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working/ECAPA-TDNN/ && python -m venv venv && source ./venv/bin/activate && python -m pip install -r requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working/ECAPA-TDNN/ && python -m venv venv && source ./venv/bin/activate && python -m pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n!cd /kaggle/working/ECAPA-TDNN/ && python -m venv venv && source ./venv/bin/activate && python -m pip install numpy scipy scikit-learn tqdm torchvision soundfile \n!cd /kaggle/working/ECAPA-TDNN/ && python -m venv venv && source ./venv/bin/activate && python -m pip install jupyter_core","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working/ECAPA-TDNN/ && source ./venv/bin/activate && python trainECAPAModel.py --save_path exps/exp2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !cd /kaggle/working/ECAPA-TDNN/ && pip install pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n# !cd /kaggle/working/ECAPA-TDNN/ && pip install numpy scipy scikit-learn tqdm torchvision soundfile ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !python /kaggle/working/ECAPA-TDNN/trainECAPAModel.py --save_path exps/exp1 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working/ECAPA-TDNN/ && source ./venv/bin/activate && python trainECAPAModel.py --eval --initial_model /kaggle/working/ECAPA-TDNN/exps/pretrain.model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\nThis is the main code of the ECAPATDNN project, to define the parameters and build the construction\n'''\n\nimport argparse, glob, os, torch, warnings, time\nfrom tools import *\nfrom dataLoader import train_loader\nfrom ECAPAModel import ECAPAModel\n\nparser = argparse.ArgumentParser(description = \"ECAPA_trainer\")\n## Training Settings\nparser.add_argument('--num_frames', type=int,   default=200,     help='Duration of the input segments, eg: 200 for 2 second')\nparser.add_argument('--max_epoch',  type=int,   default=80,      help='Maximum number of epochs')\nparser.add_argument('--batch_size', type=int,   default=400,     help='Batch size')\nparser.add_argument('--n_cpu',      type=int,   default=4,       help='Number of loader threads')\nparser.add_argument('--test_step',  type=int,   default=1,       help='Test and save every [test_step] epochs')\nparser.add_argument('--lr',         type=float, default=0.001,   help='Learning rate')\nparser.add_argument(\"--lr_decay\",   type=float, default=0.97,    help='Learning rate decay every [test_step] epochs')\n\n## Training and evaluation path/lists, save path\nparser.add_argument('--train_list', type=str,   default=\"/data08/VoxCeleb2/train_list.txt\",     help='The path of the training list, https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/train_list.txt')\nparser.add_argument('--train_path', type=str,   default=\"/data08/VoxCeleb2/train/wav\",                    help='The path of the training data, eg:\"/data08/VoxCeleb2/train/wav\" in my case')\nparser.add_argument('--eval_list',  type=str,   default=\"/data08/VoxCeleb1/veri_test2.txt\",              help='The path of the evaluation list, veri_test2.txt comes from https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test2.txt')\nparser.add_argument('--eval_path',  type=str,   default=\"/data08/VoxCeleb1/test/wav\",                    help='The path of the evaluation data, eg:\"/data08/VoxCeleb1/test/wav\" in my case')\nparser.add_argument('--musan_path', type=str,   default=\"/data08/Others/musan_split\",                    help='The path to the MUSAN set, eg:\"/data08/Others/musan_split\" in my case')\nparser.add_argument('--rir_path',   type=str,   default=\"/data08/Others/RIRS_NOISES/simulated_rirs\",     help='The path to the RIR set, eg:\"/data08/Others/RIRS_NOISES/simulated_rirs\" in my case');\nparser.add_argument('--save_path',  type=str,   default=\"exps/exp1\",                                     help='Path to save the score.txt and models')\nparser.add_argument('--initial_model',  type=str,   default=\"\",                                          help='Path of the initial_model')\n\n## Model and Loss settings\nparser.add_argument('--C',       type=int,   default=1024,   help='Channel size for the speaker encoder')\nparser.add_argument('--m',       type=float, default=0.2,    help='Loss margin in AAM softmax')\nparser.add_argument('--s',       type=float, default=30,     help='Loss scale in AAM softmax')\nparser.add_argument('--n_class', type=int,   default=5994,   help='Number of speakers')\n\n## Command\nparser.add_argument('--eval',    dest='eval', action='store_true', help='Only do evaluation')\n\n## Initialization\nwarnings.simplefilter(\"ignore\")\ntorch.multiprocessing.set_sharing_strategy('file_system')\nargs = parser.parse_args()\nargs = init_args(args)\n\n## Define the data loader\ntrainloader = train_loader(**vars(args))\ntrainLoader = torch.utils.data.DataLoader(trainloader, batch_size = args.batch_size, shuffle = True, num_workers = args.n_cpu, drop_last = True)\n\n## Search for the exist models\nmodelfiles = glob.glob('%s/model_0*.model'%args.model_save_path)\nmodelfiles.sort()\n\n## Only do evaluation, the initial_model is necessary\neval=True\nif eval == True:\n\ts = ECAPAModel(**vars(args))\n\tprint(\"Model %s loaded from previous state!\"%initial_model)\n\ts.load_parameters(args.initial_model)\n\tEER, minDCF = s.eval_network(eval_list = args.eval_list, eval_path = args.eval_path)\n\tprint(\"EER %2.2f%%, minDCF %.4f%%\"%(EER, minDCF))\n\tquit()\n\n## If initial_model is exist, system will train from the initial_model\ninitial_model = \"/kaggle/working/ECAPA-TDNN/exps/pretrain.model\"\nif initial_model != \"\":\n\tprint(\"Model %s loaded from previous state!\"%initial_model)\n\ts = ECAPAModel(**vars(args))\n\ts.load_parameters(args.initial_model)\n\tepoch = 1\n\n## Otherwise, system will try to start from the saved model&epoch\nelif len(modelfiles) >= 1:\n\tprint(\"Model %s loaded from previous state!\"%modelfiles[-1])\n\tepoch = int(os.path.splitext(os.path.basename(modelfiles[-1]))[0][6:]) + 1\n\ts = ECAPAModel(**vars(args))\n\ts.load_parameters(modelfiles[-1])\n## Otherwise, system will train from scratch\nelse:\n\tepoch = 1\n\ts = ECAPAModel(**vars(args))\n\nEERs = []\nscore_file = open(args.score_save_path, \"a+\")\n\nwhile(1):\n\t## Training for one epoch\n\tloss, lr, acc = s.train_network(epoch = epoch, loader = trainLoader)\n\n\t## Evaluation every [test_step] epochs\n\tif epoch % args.test_step == 0:\n\t\ts.save_parameters(args.model_save_path + \"/model_%04d.model\"%epoch)\n\t\tEERs.append(s.eval_network(eval_list = args.eval_list, eval_path = args.eval_path)[0])\n\t\tprint(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%d epoch, ACC %2.2f%%, EER %2.2f%%, bestEER %2.2f%%\"%(epoch, acc, EERs[-1], min(EERs)))\n\t\tscore_file.write(\"%d epoch, LR %f, LOSS %f, ACC %2.2f%%, EER %2.2f%%, bestEER %2.2f%%\\n\"%(epoch, lr, loss, acc, EERs[-1], min(EERs)))\n\t\tscore_file.flush()\n\n\tif epoch >= args.max_epoch:\n\t\tquit()\n\n\tepoch += 1\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}