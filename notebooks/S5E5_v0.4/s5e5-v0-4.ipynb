{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":256.253653,"end_time":"2025-06-04T07:02:50.951596","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-04T06:58:34.697943","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"11b9694176bf47ecb7d5b1a461165c90":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"158368f055324a5a8dd0c0d78a08ad74":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45c967a500874fd2af87a70aad04d290","IPY_MODEL_f409c73184a143469ab215429c321854","IPY_MODEL_e99f08833a354a73a78aa422f480351e"],"layout":"IPY_MODEL_11b9694176bf47ecb7d5b1a461165c90","tabbable":null,"tooltip":null}},"45c967a500874fd2af87a70aad04d290":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9062301ad3a7480299bbd60f3b496f64","placeholder":"​","style":"IPY_MODEL_c3fee6522e4f471cbed00a81d2eef916","tabbable":null,"tooltip":null,"value":"  0%"}},"4b86fb25e64346ae83133ed52a9e0ffa":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7235a362a94e494b9f422bae131dfa70":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9062301ad3a7480299bbd60f3b496f64":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9598a533ff4d46e6aaa497f8f8dd8d5a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcb25bf44b194ccc8277023f8c75fd8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"c3fee6522e4f471cbed00a81d2eef916":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e99f08833a354a73a78aa422f480351e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9598a533ff4d46e6aaa497f8f8dd8d5a","placeholder":"​","style":"IPY_MODEL_bcb25bf44b194ccc8277023f8c75fd8f","tabbable":null,"tooltip":null,"value":" 0/1 [00:15&lt;?, ?it/s]"}},"f409c73184a143469ab215429c321854":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_allow_html":false,"layout":"IPY_MODEL_7235a362a94e494b9f422bae131dfa70","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b86fb25e64346ae83133ed52a9e0ffa","tabbable":null,"tooltip":null,"value":0}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"f2432da4","cell_type":"code","source":"!pip install --upgrade scikit-learn scikit-learn==1.6.1 xgboost==3.0.1 lightgbm==4.6.0 numpy==1.26.4 scipy==1.14.1","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-06-07T18:03:25.35936Z","iopub.execute_input":"2025-06-07T18:03:25.35976Z","iopub.status.idle":"2025-06-07T18:03:31.50089Z","shell.execute_reply.started":"2025-06-07T18:03:25.359732Z","shell.execute_reply":"2025-06-07T18:03:31.499789Z"},"papermill":{"duration":30.628345,"end_time":"2025-06-04T06:59:10.253019","exception":false,"start_time":"2025-06-04T06:58:39.624674","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"cced23ef","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, label_binarize, OrdinalEncoder, QuantileTransformer, TargetEncoder\nfrom category_encoders import CatBoostEncoder, MEstimateEncoder\n\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, HistGradientBoostingRegressor\nfrom sklearn.linear_model import RidgeClassifier, LogisticRegression, LinearRegression, BayesianRidge, Ridge\n\nfrom sklearn import set_config\nimport os\n\nimport optuna\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, root_mean_squared_error, mean_squared_error, precision_recall_curve, make_scorer, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, matthews_corrcoef\nfrom scipy.stats import norm, skew\n\nfrom colorama import Fore, Style, init\nfrom copy import deepcopy\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom pprint import pprint\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold, KFold, RepeatedKFold, cross_val_score, StratifiedGroupKFold\nfrom xgboost import DMatrix, XGBClassifier, XGBRegressor\nfrom lightgbm import log_evaluation, early_stopping, LGBMClassifier, LGBMRegressor, Dataset\nfrom catboost import CatBoostClassifier, CatBoostRegressor, Pool\nfrom tqdm.notebook import tqdm\nfrom optuna.samplers import TPESampler, CmaEsSampler\nfrom optuna.pruners import HyperbandPruner\nfrom functools import partial\nfrom IPython.display import display_html, clear_output\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.compose import ColumnTransformer\nimport gc\nimport re\nfrom typing import Literal, NamedTuple\nfrom itertools import combinations\n\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import regularizers\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:03:31.502809Z","iopub.execute_input":"2025-06-07T18:03:31.503121Z","iopub.status.idle":"2025-06-07T18:03:31.516276Z","shell.execute_reply.started":"2025-06-07T18:03:31.503093Z","shell.execute_reply":"2025-06-07T18:03:31.51477Z"},"papermill":{"duration":26.21445,"end_time":"2025-06-04T06:59:36.476692","exception":false,"start_time":"2025-06-04T06:59:10.262242","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"53e18145","cell_type":"markdown","source":"# <p style=\"border-radius: 40px; color: white; font-weight: bold; font-size: 150%; text-align: center; background-color:#3cb371; padding: 5px 5px 5px 5px;\">Configuration</p>","metadata":{"papermill":{"duration":0.009541,"end_time":"2025-06-04T06:59:36.49574","exception":false,"start_time":"2025-06-04T06:59:36.486199","status":"completed"},"tags":[]}},{"id":"f91f1933","cell_type":"code","source":"class Config:\n    \n    state = 42\n    n_splits = 10\n    early_stop = 100\n        \n    target = 'Fertilizer Name'\n    train = pd.read_csv('/kaggle/input/playground-series-s5e6/train.csv', index_col='id')\n    test = pd.read_csv('/kaggle/input/playground-series-s5e6/test.csv', index_col='id')\n    submission = pd.read_csv('/kaggle/input/playground-series-s5e6/sample_submission.csv')\n    train_org = train.copy() #pd.read_csv('/kaggle/input/playground-series-s5e6/train.csv')#/kaggle/input/fertilizer-prediction/Fertilizer Prediction.csv')\n    train_org = pd.DataFrame(columns=train_org.columns)\n    \n    original_data = 'N'\n    outliers = 'N'\n    log_trf = 'N'\n    feature_eng = 'N'\n    missing = 'N'\n\n    labels = list(train[target].unique())\n    nclass = len(labels)\n    label_encoder = LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:03:31.517323Z","iopub.execute_input":"2025-06-07T18:03:31.51778Z","iopub.status.idle":"2025-06-07T18:03:32.592899Z","shell.execute_reply.started":"2025-06-07T18:03:31.517735Z","shell.execute_reply":"2025-06-07T18:03:32.59167Z"},"papermill":{"duration":1.789965,"end_time":"2025-06-04T06:59:38.295004","exception":false,"start_time":"2025-06-04T06:59:36.505039","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"7bc0109d","cell_type":"markdown","source":"# <p style=\"border-radius: 40px; color: white; font-weight: bold; font-size: 150%; text-align: center; background-color:#3cb371; padding: 5px 5px 5px 5px;\">EDA</p>","metadata":{"papermill":{"duration":0.009853,"end_time":"2025-06-04T06:59:38.319052","exception":false,"start_time":"2025-06-04T06:59:38.309199","status":"completed"},"tags":[]}},{"id":"097b516b","cell_type":"code","source":"class EDA(Config):\n    \n    def __init__(self):\n        super().__init__()\n\n        self.cat_features = self.train.drop(self.target, axis=1).select_dtypes(include=['object']).columns.tolist()\n        self.num_features = self.train.drop(self.target, axis=1).select_dtypes(exclude=['object']).columns.tolist()\n        self.data_info()\n        self.heatmap()\n        self.dist_plots()\n        self.cat_feature_plots()\n        self.target_pie()\n                \n    def data_info(self):\n        \n        for data, label in zip([self.train, self.test], ['Train', 'Test']):\n            table_style = [{'selector': 'th:not(.index_name)',\n                            'props': [('background-color', '#3cb371'),\n                                      ('color', '#FFFFFF'),\n                                      ('font-weight', 'bold'),\n                                      ('border', '1px solid #DCDCDC'),\n                                      ('text-align', 'center')]\n                            }, \n                            {'selector': 'tbody td',\n                             'props': [('border', '1px solid #DCDCDC'),\n                                       ('font-weight', 'normal')]\n                            }]\n            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} head\\n')\n            display(data.head().style.set_table_styles(table_style))\n                           \n            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} info\\n'+Style.RESET_ALL)               \n            display(data.info())\n                           \n            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} describe\\n')\n            display(data.describe().drop(index='count', columns=self.target, errors = 'ignore').T\n                    .style.set_table_styles(table_style).format('{:.3f}'))\n            \n            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} missing values\\n'+Style.RESET_ALL)               \n            display(data.isna().sum())\n        return self\n    \n    def heatmap(self):\n        print(Style.BRIGHT+Fore.GREEN+f'\\nCorrelation Heatmap\\n')\n        plt.figure(figsize=(7,7))\n        corr = self.train.select_dtypes(exclude='object').corr(method='pearson')\n        sns.heatmap(corr, fmt = '0.4f', cmap = 'Greens', annot=True, cbar=False)\n        plt.show()\n        \n    def dist_plots(self):\n        print(Style.BRIGHT+Fore.GREEN+f\"\\nDistribution analysis\\n\")\n        df = pd.concat([self.train[self.num_features].assign(Source = 'Train'), \n                        self.test[self.num_features].assign(Source = 'Test'),], \n                        axis=0, ignore_index = True)\n\n        fig, axes = plt.subplots(len(self.num_features), 2 ,figsize = (18, len(self.num_features) * 6), \n                                 gridspec_kw = {'hspace': 0.3, \n                                                'wspace': 0.2, \n                                                'width_ratios': [0.70, 0.30]\n                                               }\n                                )\n        for i,col in enumerate(self.num_features):\n            ax = axes[i,0]\n            sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source', \n                        palette = ['#3cb371', 'r'], ax = ax, linewidth = 2\n                       )\n            ax.set(xlabel = '', ylabel = '')\n            ax.set_title(f\"\\n{col}\")\n            ax.grid()\n\n            ax = axes[i,1]\n            sns.boxplot(data = df, y = col, x=df.Source, width = 0.5,\n                        linewidth = 1, fliersize= 1,\n                        ax = ax, palette=['#3cb371', 'r']\n                       )\n            ax.set_title(f\"\\n{col}\")\n            ax.set(xlabel = '', ylabel = '')\n            ax.tick_params(axis='both', which='major')\n            ax.set_xticklabels(['Train', 'Test'])\n\n        plt.tight_layout()\n        plt.show()\n               \n    def cat_feature_plots(self):\n        fig, axes = plt.subplots(max(len(self.cat_features), 1), 2 ,figsize = (18, len(self.cat_features) * 6), \n                                 gridspec_kw = {'hspace': 0.5, \n                                                'wspace': 0.2,\n                                               }\n                                )\n        if len(self.cat_features) == 1:\n            axes = np.array([axes])\n            \n        for i, col in enumerate(self.cat_features):\n            ax = axes[i,0]\n            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='#3cb371')\n            ax.set(xlabel = '', ylabel = '')\n            ax.set_title(f\"\\n{col} Train\")\n            \n            ax = axes[i,1]\n            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='r')\n            ax.set(xlabel = '', ylabel = '')\n            ax.set_title(f\"\\n{col} Test\")\n\n        plt.tight_layout()\n        plt.show()\n\n    def target_pie(self):\n        print(Style.BRIGHT+Fore.GREEN+f\"\\nTarget feature distribution\\n\")\n        targets = self.train[self.target]\n        plt.figure(figsize=(6, 6))\n        plt.pie(targets.value_counts(), labels=targets.value_counts().index, autopct='%1.2f%%', colors=sns.color_palette('viridis', len(targets.value_counts())))\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:03:32.595324Z","iopub.execute_input":"2025-06-07T18:03:32.595662Z","iopub.status.idle":"2025-06-07T18:03:32.619029Z","shell.execute_reply.started":"2025-06-07T18:03:32.595638Z","shell.execute_reply":"2025-06-07T18:03:32.617691Z"},"papermill":{"duration":0.031606,"end_time":"2025-06-04T06:59:38.360219","exception":false,"start_time":"2025-06-04T06:59:38.328613","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"eb0c8604","cell_type":"code","source":"eda = EDA()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:03:32.6202Z","iopub.execute_input":"2025-06-07T18:03:32.620473Z","iopub.status.idle":"2025-06-07T18:04:08.701491Z","shell.execute_reply.started":"2025-06-07T18:03:32.620454Z","shell.execute_reply":"2025-06-07T18:04:08.700616Z"},"papermill":{"duration":35.528024,"end_time":"2025-06-04T07:00:13.897286","exception":false,"start_time":"2025-06-04T06:59:38.369262","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"9a89fc94","cell_type":"markdown","source":"# <p style=\"border-radius: 40px; color: white; font-weight: bold; font-size: 150%; text-align: center; background-color:#3cb371; padding: 5px 5px 5px 5px;\">Data Transformation</p>","metadata":{"papermill":{"duration":0.021074,"end_time":"2025-06-04T07:00:13.939975","exception":false,"start_time":"2025-06-04T07:00:13.918901","status":"completed"},"tags":[]}},{"id":"54201aed","cell_type":"code","source":"class Transform(Config):\n    \n    def __init__(self):\n        super().__init__()\n        if Config.original_data == 'Y':\n            self.train = pd.concat([self.train, self.train_org], ignore_index=True).drop_duplicates()\n            self.train.reset_index(drop=True, inplace=True)\n            \n        self.num_features = self.train.drop(self.target, axis=1).select_dtypes(exclude=['object', 'bool']).columns.tolist()\n        self.cat_features = self.train.drop(self.target, axis=1).select_dtypes(include=['object', 'bool']).columns.tolist()\n        \n        if self.missing == 'Y':\n            self.missing_values()\n\n        self.train_raw = self.train.copy()\n        \n        if self.feature_eng == 'Y':\n            self.train = self.new_features(self.train)\n            self.test = self.new_features(self.test)\n            \n        self.num_features = self.train.drop(self.target, axis=1).select_dtypes(exclude=['object', 'bool', 'string']).columns.tolist()\n        self.cat_features = self.train.drop(self.target, axis=1).select_dtypes(include=['object', 'bool']).columns.tolist()\n            \n        if self.outliers == 'Y':    \n            self.remove_outliers()\n            \n        if self.log_trf == 'Y':\n            self.log_transformation()\n            \n        self.train_enc = self.train.copy()\n        self.test_enc = self.test.copy()\n        self.encode()\n        \n        if self.outliers == 'Y' or self.log_trf == 'Y':\n            self.distribution()\n        \n    def __call__(self):\n        self.train[self.cat_features] = self.train[self.cat_features].astype('category')\n        self.test[self.cat_features] = self.test[self.cat_features].astype('category')\n        self.y = self.train[self.target]\n        self.y = pd.DataFrame(label_binarize(self.y, classes=self.labels), columns=self.labels)\n        self.y['Target'] = np.argmax(self.y[self.labels].values, axis=1)\n        \n        self.X = self.train.drop(self.target, axis=1)\n        self.X_enc = self.train_enc.drop(self.target, axis=1)\n        self.X = self.reduce_mem(self.X)\n        self.test = self.reduce_mem(self.test)\n        return self.X, self.X_enc, self.y, self.test, self.test_enc, self.cat_features, self.num_features\n    \n    def encode(self):\n        self.train_enc[self.num_features] = self.train_enc[self.num_features].fillna(self.train_enc[self.num_features].median())\n        self.test_enc[self.num_features] = self.test_enc[self.num_features].fillna(self.test_enc[self.num_features].median())\n        self.train_enc[self.cat_features] = self.train_enc[self.cat_features].fillna('NaN')\n        self.test_enc[self.cat_features] = self.test_enc[self.cat_features].fillna('NaN')\n        \n        self.cat_features_card = []\n        for f in self.cat_features:\n            self.cat_features_card.append(self.train[f].nunique())\n            \n        data = pd.concat([self.train_enc, self.test_enc])\n        oe = OrdinalEncoder()\n        data[self.cat_features] = oe.fit_transform(data[self.cat_features]).astype('int')\n        \n        scaler = StandardScaler()\n        data[self.num_features] = scaler.fit_transform(data[self.num_features])\n        \n        self.train_enc = data[~data[self.target].isna()]\n        self.test_enc = data[data[self.target].isna()].drop(self.target, axis=1)\n            \n    def new_features(self, data):\n        for c1, c2 in list(combinations(self.num_features,2)):\n            data[f\"{c1}_{c2}\"] = data[c1]*data[c2]        \n        return data\n\n    def log_transformation(self):\n        self.train[self.target] = np.log1p(self.train[self.target]) \n        \n        return self\n    \n    def distribution(self):\n        print(Style.BRIGHT+Fore.GREEN+f'\\nHistograms of distribution\\n')\n        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n\n        ax_r, ax_n = axes\n\n        ax_r.set_title(f'{self.target} ($\\mu=$ {self.train_raw[self.target].mean():.2f} and $\\sigma=$ {self.train[self.target].std():.2f} )')\n        ax_r.hist(self.train_raw[self.target], bins=30, color='#3cb371')\n        ax_r.axvline(self.train_raw[self.target].mean(), color='r', label='Mean')\n        ax_r.axvline(self.train_raw[self.target].median(), color='y', linestyle='--', label='Median')\n        ax_r.legend()\n\n        ax_n.set_title(f'{self.target} Normalized ($\\mu=$ {self.train_enc[self.target].mean():.2f} and $\\sigma=$ {self.train_enc[self.target].std():.2f} )')\n        ax_n.hist(self.train_enc[self.target], bins=30, color='#3cb371')\n        ax_n.axvline(self.train_enc[self.target].mean(), color='r', label='Mean')\n        ax_n.axvline(self.train_enc[self.target].median(), color='y', linestyle='--', label='Median')\n        ax_n.legend()\n        \n    def remove_outliers(self):\n        Q1 = self.train[self.targets].quantile(0.25)\n        Q3 = self.train[self.targets].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_limit = Q1 - 1.5*IQR\n        upper_limit = Q3 + 1.5*IQR\n        self.train = self.train[(self.train[self.targets] >= lower_limit) & (self.train[self.targets] <= upper_limit)]\n        self.train.reset_index(drop=True, inplace=True)\n    \n    def missing_values(self):\n        self.train[self.cat_features] = self.train[self.cat_features].fillna('NaN')\n        self.test[self.cat_features] = self.test[self.cat_features].fillna('NaN')\n        return self\n\n    def reduce_mem(self, df):\n\n        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', \"uint16\", \"uint32\", \"uint64\"]\n        \n        for col in df.columns:\n            col_type = df[col].dtypes\n            \n            if col_type in numerics:\n                c_min = df[col].min()\n                c_max = df[col].max()\n\n                if \"int\" in str(col_type):\n                    if c_min >= np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif c_min >= np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif c_min >= np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif c_min >= np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)  \n                else:\n                    if c_min >= np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        df[col] = df[col].astype(np.float16)\n                    if c_min >= np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        df[col] = df[col].astype(np.float32)\n                    else:\n                        df[col] = df[col].astype(np.float64)  \n\n        return df","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:04:08.702754Z","iopub.execute_input":"2025-06-07T18:04:08.702999Z","iopub.status.idle":"2025-06-07T18:04:08.730495Z","shell.execute_reply.started":"2025-06-07T18:04:08.702983Z","shell.execute_reply":"2025-06-07T18:04:08.729244Z"},"papermill":{"duration":0.053509,"end_time":"2025-06-04T07:00:14.014798","exception":false,"start_time":"2025-06-04T07:00:13.961289","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a0813c56","cell_type":"code","source":"t = Transform()\nX, X_enc, y, test, test_enc, cat_features, num_features = t()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:04:08.731654Z","iopub.execute_input":"2025-06-07T18:04:08.731967Z","iopub.status.idle":"2025-06-07T18:04:13.140871Z","shell.execute_reply.started":"2025-06-07T18:04:08.731939Z","shell.execute_reply":"2025-06-07T18:04:13.139018Z"},"papermill":{"duration":3.465588,"end_time":"2025-06-04T07:00:17.500733","exception":false,"start_time":"2025-06-04T07:00:14.035145","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c59073b0","cell_type":"markdown","source":"# <p style=\"border-radius: 40px; color: white; font-weight: bold; font-size: 150%; text-align: center; background-color:#3cb371; padding: 5px 5px 5px 5px;\">Model Training</p>","metadata":{"papermill":{"duration":0.021252,"end_time":"2025-06-04T07:00:17.543573","exception":false,"start_time":"2025-06-04T07:00:17.522321","status":"completed"},"tags":[]}},{"id":"fae84475","cell_type":"code","source":"models = {\n    'XGB': [XGBClassifier(**{'tree_method': 'hist',\n                             'n_estimators': 3000,\n                             'objective': 'multi:softprob',\n                             'random_state': Config.state,\n                             'enable_categorical': True,\n                             'verbosity': 0,\n                             'early_stopping_rounds': Config.early_stop,\n                             'eval_metric': 'mlogloss',\n                             'booster': 'gbtree',\n                             \"device\": \"cuda\",\n                             'n_jobs': -1,\n                             'learning_rate': 0.1,\n                             'num_class': Config.nclass,\n                             'lambda': 0.05656209749983576,\n                             'alpha': 5.620898657099113,\n                             'colsample_bytree': 0.2587327850345624, \n                             'subsample': 0.8276149323901826,\n                             'max_depth': 20,\n                             'min_child_weight': 10\n                           }),\n            False],\n}","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:04:13.141413Z","iopub.status.idle":"2025-06-07T18:04:13.14176Z","shell.execute_reply.started":"2025-06-07T18:04:13.141606Z","shell.execute_reply":"2025-06-07T18:04:13.14162Z"},"papermill":{"duration":0.029165,"end_time":"2025-06-04T07:00:17.593328","exception":false,"start_time":"2025-06-04T07:00:17.564163","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"aa0dbb49","cell_type":"code","source":"class Model(Config):\n    \n    def __init__(self, X, X_enc, y, test, test_enc, models):\n        self.y = y\n        self.models = models\n        self.scores = pd.DataFrame(columns=['Score'])\n        self.OOF_preds = pd.DataFrame()\n        self.TEST_preds = pd.DataFrame()\n        self.OOF_Ensemble = pd.DataFrame(columns=self.labels)\n        self.TEST_Ensemble = pd.DataFrame(columns=self.labels)\n        \n    def mapk(self, actual, predicted, k=3):\n        def apk(a, p, k):\n            p = p[:k]\n            score = 0.0\n            hits = 0\n            seen = set()\n            for i, pred in enumerate(p):\n                if pred in a and pred not in seen:\n                    hits += 1\n                    score += hits / (i + 1.0)\n                    seen.add(pred)\n            return score / min(len(a), k)\n        return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n    \n    def train(self):\n        \n        self.folds = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.state)\n \n        for model_name, [model, training] in tqdm(self.models.items()):\n            oof_pred = np.zeros((X.shape[0], self.nclass))\n            test_pred = np.zeros((test.shape[0], self.nclass))\n\n            if training:\n                print('='*20)\n                print(model_name)\n                if any(model in model_name for model in ['LGBM', 'CAT', 'XGB', 'HGB', 'YDF']):\n                    self.X = X.copy()\n                    self.test = test.copy()\n \n                else:\n                    self.X = X_enc.copy()\n                    self.test = test_enc.copy()\n                    \n                if 'NN' in model_name:\n                    for n_fold, (train_id, valid_id) in enumerate(self.folds.split(self.X)):\n                        X_train = self.X.loc[train_id].copy()\n                        y_train = self.y.iloc[train_id]\n                        X_val = self.X.loc[valid_id].copy()\n                        y_val = self.y.iloc[valid_id]\n                        \n                        X_train_cats = X_train[cat_features]\n                        X_train_nums = X_train[num_features]\n\n                        X_val_cats = X_val[cat_features]\n                        X_val_nums = X_val[num_features]\n\n                        X_test_cats = self.test[cat_features]\n                        X_test_nums = self.test[num_features]\n                        print(f'Fold {n_fold+1}')\n                        \n                        model = build_model(cat_features, num_features)                        \n                        keras.utils.set_random_seed(self.state)\n                        optimizer = keras.optimizers.Adam(learning_rate=1e-2, weight_decay=1e-3)\n                        model.compile(optimizer=optimizer, loss='mean_squared_error')\n                        model.fit([X_train_cats,X_train_nums], y_train, \n                                  validation_data=([X_val_cats, X_val_nums], y_val),\n                                  epochs=20,\n                                  batch_size=1000,\n                                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=1),\n                                             keras.callbacks.EarlyStopping(patience=3)\n                                            ])\n                        \n                        y_pred_val = model.predict([X_val_cats, X_val_nums])\n                        oof_pred[valid_id] = y_pred_val.flatten()\n                        test_pred += model.predict([X_test_cats, X_test_nums]).flatten() / self.n_splits\n                        \n                        score = root_mean_squared_error(y_val, y_pred_val)\n                        print(score)\n                        self.scores.loc[f'{model_name}', f'Fold {n_fold+1}'] = score                 \n                                              \n                else:                          \n                    for n_fold, (train_id, valid_id) in enumerate(self.folds.split(self.X, self.y.Target)):\n                        X_train = self.X.iloc[train_id]\n                        y_train = self.y.Target.iloc[train_id]\n                        X_val = self.X.iloc[valid_id]\n                        y_val = self.y.Target.iloc[valid_id]  \n                        X_test = self.test.copy()\n                        \n                        print(f'Fold {n_fold+1}')\n\n                        if \"XGB\" in model_name:\n                            model.fit(X_train, y_train, \n                                      eval_set = [(X_val, y_val)], \n                                      verbose = False\n                                     )\n\n                        elif \"CAT\" in model_name:\n                            model.fit(X_train, y_train, \n                                      eval_set = [(X_val, y_val)],\n                                      verbose=False\n                                      ) \n\n                        elif \"LGBM\" in model_name:\n                            model.fit(X_train, y_train, \n                                       eval_set = [(X_val, y_val)], \n                                       callbacks = [log_evaluation(0),\n                                                    early_stopping(self.early_stop, verbose = False)\n                                                   ])  \n\n                        else:                           \n                            model.fit(X_train, y_train)\n\n                        y_pred_val = model.predict_proba(X_val)                        \n                        oof_pred[valid_id] = y_pred_val\n                        test_pred += model.predict_proba(X_test) / self.n_splits\n\n                        y_pred_val = np.argsort(y_pred_val, axis=1)[:, -3:][:, ::-1]\n                        y_val = [[label] for label in y_val]\n                        score = self.mapk(y_val, y_pred_val)\n                        print(score)\n                        self.scores.loc[f'{model_name}', f'Fold {n_fold+1}'] = score\n\n                oof_pred = pd.DataFrame(oof_pred, columns=self.labels)\n                test_pred = pd.DataFrame(test_pred, columns=self.labels)\n                oof_pred.to_csv(f'{model_name}_oof.csv', index=False)\n                test_pred.to_csv(f'{model_name}_test.csv', index=False)\n            \n            else:\n\n                oof_pred = pd.read_csv(f'/kaggle/input/fertilizers-models/{model_name}_oof.csv')\n                test_pred = pd.read_csv(f'/kaggle/input/fertilizers-models/{model_name}_test.csv')\n                for n_fold, (train_id, valid_id) in enumerate(self.folds.split(oof_pred, self.y.Target)):\n                    y_pred_val, y_val = oof_pred.iloc[valid_id], self.y.Target.iloc[valid_id]\n                    y_pred_val = y_pred_val.apply(lambda row: np.argsort(row.values)[-3:][::-1], axis=1)\n                    y_val = [[label] for label in y_val]\n                    self.scores.loc[f'{model_name}', f'Fold {n_fold+1}'] = self.mapk(y_val, y_pred_val)\n\n            self.scores.loc[f'{model_name}', 'Score'] = self.scores.loc[f'{model_name}'][1:].mean()\n            \n            if len(self.models)>1:\n                self.OOF_preds[f'{model_name}'] = oof_pred.apply(lambda row: row.values.argmax(), axis=1)\n                self.TEST_preds[f'{model_name}'] = test_pred.apply(lambda row: row.values.argmax(), axis=1)\n\n            else:\n                self.OOF_Ensemble = oof_pred\n                print(Style.BRIGHT+Fore.GREEN+f'{model_name} score {self.scores.loc[f\"{model_name}\", \"Score\"]:.5f}\\n')\n                self.result()\n                return test_pred\n                \n        self.scores.loc['Ensemble', 'Score'], self.OOF_Ensemble, self.TEST_Ensemble = self.ensemble(self.OOF_preds, self.y.Target, self.TEST_preds)\n        self.scores = self.scores.sort_values('Score')\n\n        self.result()\n\n        return self.TEST_Ensemble\n    \n    def ensemble(self, X, y, test):\n        scores = []\n        oof_pred = np.zeros((X.shape[0],self.nclass))\n        test_pred = np.zeros((test.shape[0],self.nclass))\n        model = LogisticRegression(C = 0.10, random_state = self.state, max_iter = 500)\n\n        for fold_idx, (train_idx, val_idx) in enumerate(self.folds.split(X, y)):\n            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n            model.fit(X_train, y_train)\n\n            y_pred_val = model.predict_proba(X_val)            \n            oof_pred[val_idx] = y_pred_val\n            test_pred += model.predict_proba(test) / self.n_splits\n\n            y_pred_val = np.argsort(y_pred_val, axis=1)[:, -3:][:, ::-1]\n            y_val = [[label] for label in y_val]\n            score = self.mapk(y_val, y_pred_val)\n\n            scores.append(score)\n                   \n        return np.mean(scores), pd.DataFrame(oof_pred, columns=self.labels), pd.DataFrame(test_pred, columns=self.labels)\n    \n    def result(self):\n               \n        if len(self.models)>1:       \n            plt.figure(figsize=(14, 8))\n            colors = ['#3cb371' if i != 'Ensemble' else 'r' for i in self.scores.Score.index]\n            hbars = plt.barh(self.scores.index, self.scores.Score, color=colors, height=0.5)\n            plt.bar_label(hbars, fmt='%.5f')\n            plt.xlim(0.1,0.4)\n            plt.ylabel('Models')\n            plt.xlabel('Score')              \n            plt.show()\n\n        fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n\n        for i, col in enumerate(self.labels):\n            RocCurveDisplay.from_predictions(self.y[col].sort_index(), self.OOF_Ensemble[col], name=f\"{col}\", ax=axes[0])\n            \n        axes[0].plot([0, 1], [0, 1], linestyle='--', lw=2, color='black')\n        axes[0].set_xlabel('False Positive Rate')\n        axes[0].set_ylabel('True Positive Rate')\n        axes[0].set_title('ROC')\n        axes[0].legend(loc=\"lower right\")\n        \n        ConfusionMatrixDisplay.from_predictions(self.y.Target.sort_index(), np.argmax(self.OOF_Ensemble, axis=1), display_labels=self.labels, xticks_rotation='vertical', colorbar=False, ax=axes[1], cmap = 'Greens')\n        axes[1].set_title('Confusion Matrix')\n        \n        plt.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:04:13.14342Z","iopub.status.idle":"2025-06-07T18:04:13.143834Z","shell.execute_reply.started":"2025-06-07T18:04:13.143634Z","shell.execute_reply":"2025-06-07T18:04:13.143652Z"},"papermill":{"duration":0.056943,"end_time":"2025-06-04T07:00:17.671156","exception":false,"start_time":"2025-06-04T07:00:17.614213","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"62f61d25","cell_type":"code","source":"model = Model(X, X_enc, y, test, test_enc, models)\nTEST_preds = model.train()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:04:13.145187Z","iopub.status.idle":"2025-06-07T18:04:13.145553Z","shell.execute_reply.started":"2025-06-07T18:04:13.145355Z","shell.execute_reply":"2025-06-07T18:04:13.145366Z"},"papermill":{"duration":15.741098,"end_time":"2025-06-04T07:00:33.432887","exception":false,"start_time":"2025-06-04T07:00:17.691789","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"85027469","cell_type":"code","source":"submission = Config.submission\nsubmission[Config.target] = TEST_preds.apply(lambda row: ' '.join(row.nlargest(3).index), axis=1)\nsubmission.to_csv(\"submission.csv\", index=False)\n\ndisplay(submission.head())\ncounts = submission[Config.target].value_counts().sample(100)\nplt.figure(figsize=(20, 10))\nsns.barplot(x=counts.index, y=counts.values, color='#3cb371', width=0.9)\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T18:04:13.146701Z","iopub.status.idle":"2025-06-07T18:04:13.146998Z","shell.execute_reply.started":"2025-06-07T18:04:13.14687Z","shell.execute_reply":"2025-06-07T18:04:13.146881Z"},"papermill":{"duration":133.885787,"end_time":"2025-06-04T07:02:47.346481","exception":false,"start_time":"2025-06-04T07:00:33.460694","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}