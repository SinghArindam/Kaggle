{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11241750,"sourceType":"datasetVersion","datasetId":7023664}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:15:25.75078Z","iopub.execute_input":"2025-04-13T17:15:25.751412Z","iopub.status.idle":"2025-04-13T17:15:26.419733Z","shell.execute_reply.started":"2025-04-13T17:15:25.751376Z","shell.execute_reply":"2025-04-13T17:15:26.418919Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ebooks-epubs/sample_01.epub\n/kaggle/input/ebooks-epubs/Reverend_Insanity.epub\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%time\n!sudo apt-get install ffmpeg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:21:39.621363Z","iopub.execute_input":"2025-04-13T17:21:39.621935Z","iopub.status.idle":"2025-04-13T17:21:41.751387Z","shell.execute_reply.started":"2025-04-13T17:21:39.621908Z","shell.execute_reply":"2025-04-13T17:21:41.750478Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 122 not upgraded.\nCPU times: user 34.5 ms, sys: 22.1 ms, total: 56.6 ms\nWall time: 2.13 s\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%time\n!pip uninstall pylibcugraph-cu12 -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:17:34.768231Z","iopub.execute_input":"2025-04-13T17:17:34.768888Z","iopub.status.idle":"2025-04-13T17:17:36.111096Z","shell.execute_reply.started":"2025-04-13T17:17:34.768862Z","shell.execute_reply":"2025-04-13T17:17:36.110174Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping pylibcugraph-cu12 as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCPU times: user 13.2 ms, sys: 18.8 ms, total: 32 ms\nWall time: 1.34 s\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%%time\n# !pip install ebooklib beautifulsoup4 kokoro>=0.9.2 soundfile torch pydub\n!pip install ebooklib beautifulsoup4 kokoro>=0.9.2 soundfile torch pydub pylibraft-cu12==24.12.0 rmm-cu12==24.12.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:17:48.778729Z","iopub.execute_input":"2025-04-13T17:17:48.7793Z","iopub.status.idle":"2025-04-13T17:17:52.2872Z","shell.execute_reply.started":"2025-04-13T17:17:48.779269Z","shell.execute_reply":"2025-04-13T17:17:52.286298Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 43.6 ms, sys: 20.8 ms, total: 64.4 ms\nWall time: 3.5 s\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:17:52.288621Z","iopub.execute_input":"2025-04-13T17:17:52.288852Z","iopub.status.idle":"2025-04-13T17:17:55.288881Z","shell.execute_reply.started":"2025-04-13T17:17:52.288832Z","shell.execute_reply":"2025-04-13T17:17:55.28818Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"%%time\nimport os\nimport logging\nimport subprocess\nfrom concurrent.futures import ThreadPoolExecutor\nfrom ebooklib import epub\nimport ebooklib\nfrom bs4 import BeautifulSoup\nimport soundfile as sf\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport hashlib\n\n# Placeholder for KPipeline (replace with your actual text-to-speech library)\nclass KPipeline:\n    def __init__(self, lang_code, device):\n        self.lang_code = lang_code\n        self.device = device\n\n    def __call__(self, text, voice):\n        # Dummy implementation: replace with actual TTS logic\n        import numpy as np\n        for i in range(0, len(text), 100):  # Simulate chunked audio generation\n            yield (None, None, np.random.rand(24000))  # 1-second dummy audio\n\nclass AudiobookCreator:\n    def __init__(self, epub_path, output_dir=\"audiobooks\", voice='af_heart', max_workers=4):\n        \"\"\"Initialize the AudiobookCreator with EPUB path and output settings.\"\"\"\n        self.epub_path = epub_path\n        self.epub_name = os.path.splitext(os.path.basename(epub_path))[0]\n        self.output_dir = os.path.join(output_dir, self.epub_name)\n        self.txt_dir = os.path.join(self.output_dir, \"txt\")\n        self.audio_dir = os.path.join(self.output_dir, \"audio\")\n        self.voice = voice\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.pipeline = KPipeline(lang_code='a', device=self.device)  # Replace with actual TTS\n        self.max_workers = max_workers\n        self.chapter_names = []\n\n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.INFO)\n        handler = logging.StreamHandler()\n        handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))\n        self.logger.addHandler(handler)\n\n    def extract_chapters(self):\n        \"\"\"\n        **Improvement 1: Enhanced Chapter Extraction**\n        Extract chapters from EPUB, using TOC for titles or falling back to headings.\n        \"\"\"\n        os.makedirs(self.txt_dir, exist_ok=True)\n        try:\n            book = epub.read_epub(self.epub_path)\n        except Exception as e:\n            self.logger.error(f\"Failed to read EPUB file: {e}\")\n            return\n\n        # Extract chapter names from TOC\n        for item in book.toc:\n            if isinstance(item, epub.Link):\n                self.chapter_names.append(item.title)\n\n        chapter_count = 0\n        items = list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT))\n        for item in tqdm(items, desc=\"Extracting chapters\"):\n            chapter_count += 1\n            content = item.get_content().decode('utf-8')\n            soup = BeautifulSoup(content, 'html.parser')\n            text = soup.get_text(separator='\\n', strip=True)\n\n            # Determine chapter title\n            if chapter_count <= len(self.chapter_names):\n                chapter_name = self.chapter_names[chapter_count - 1]\n            else:\n                # Fallback to first heading\n                heading = soup.find(['h1', 'h2'])\n                chapter_name = heading.get_text(strip=True) if heading else f\"Chapter {chapter_count}\"\n\n            chapter_file = os.path.join(self.txt_dir, f\"{chapter_name}.txt\")\n            try:\n                with open(chapter_file, 'w', encoding='utf-8') as f:\n                    f.write(text)\n                self.logger.info(f\"Saved chapter text: {chapter_file}\")\n            except Exception as e:\n                self.logger.error(f\"Error writing {chapter_file}: {e}\")\n\n    def text_to_audio(self):\n        \"\"\"\n        **Improvement 2: Parallel Audio Generation**\n        **Improvement 5: Robust Error Handling**\n        **Improvement 6: Audio Caching**\n        Convert text files to audio with parallel processing, retries, and caching.\n        \"\"\"\n        os.makedirs(self.audio_dir, exist_ok=True)\n        txt_files = [f for f in os.listdir(self.txt_dir) if f.endswith('.txt')]\n\n        def generate_audio(txt_file):\n            chapter_name = os.path.splitext(txt_file)[0]\n            chapter_path = os.path.join(self.txt_dir, txt_file)\n            audio_path = os.path.join(self.audio_dir, f\"{chapter_name}.wav\")\n            cached_hash_path = audio_path + '.md5'\n\n            # Check cache (Improvement 6)\n            if os.path.exists(audio_path):\n                with open(chapter_path, 'r', encoding='utf-8') as f:\n                    text_hash = hashlib.md5(f.read().encode()).hexdigest()\n                if os.path.exists(cached_hash_path):\n                    with open(cached_hash_path, 'r') as f:\n                        cached_hash = f.read()\n                    if cached_hash == text_hash:\n                        self.logger.info(f\"Using cached audio for {chapter_name}\")\n                        return\n\n            # Generate audio with retries (Improvement 5)\n            for attempt in range(3):  # Retry up to 3 times\n                try:\n                    with open(chapter_path, \"r\", encoding=\"utf-8\") as f:\n                        text = f.read()\n                    generator = self.pipeline(text, voice=self.voice)\n                    combined_audio = []\n                    for _, _, audio in generator:\n                        combined_audio.append(audio)\n                    combined_audio = np.concatenate(combined_audio)\n                    sf.write(audio_path, combined_audio, 24000)\n                    # Save hash for caching\n                    with open(cached_hash_path, 'w') as f:\n                        f.write(text_hash)\n                    self.logger.info(f\"Saved audio: {audio_path}\")\n                    break\n                except Exception as e:\n                    self.logger.error(f\"Error converting {chapter_path} (attempt {attempt+1}): {e}\")\n                    if attempt == 2:\n                        raise\n\n        # Parallel processing (Improvement 2)\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            list(tqdm(executor.map(generate_audio, txt_files), total=len(txt_files), desc=\"Generating audio\"))\n\n    def create_audiobook(self):\n        \"\"\"\n        **Improvement 3: Optimized Audio Combination**\n        Combine audio files into a single M4B audiobook using ffmpeg.\n        \"\"\"\n        audio_files = sorted([f for f in os.listdir(self.audio_dir) if f.endswith(\".wav\")])\n        concat_file = os.path.join(self.output_dir, \"concat.txt\")\n        with open(concat_file, 'w') as f:\n            for audio_file in audio_files:\n                f.write(f\"file '{os.path.join(self.audio_dir, audio_file)}'\\n\")\n\n        combined_path = os.path.join(self.output_dir, f\"{self.epub_name}.m4b\")\n        cmd = [\n            \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", concat_file,\n            \"-c\", \"copy\", combined_path\n        ]\n        try:\n            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            self.logger.info(f\"Audiobook created: {combined_path}\")\n        except subprocess.CalledProcessError as e:\n            self.logger.error(f\"FFmpeg error: {e.stderr.decode()}\")\n\n    def run(self):\n        \"\"\"Execute the full audiobook creation process.\"\"\"\n        self.extract_chapters()\n        self.text_to_audio()\n        self.create_audiobook()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:17:57.212806Z","iopub.execute_input":"2025-04-13T17:17:57.213123Z","iopub.status.idle":"2025-04-13T17:17:57.230599Z","shell.execute_reply.started":"2025-04-13T17:17:57.213096Z","shell.execute_reply":"2025-04-13T17:17:57.22994Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 83 µs, sys: 18 µs, total: 101 µs\nWall time: 107 µs\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%time\nimport os\nimport logging\nimport subprocess\nfrom concurrent.futures import ThreadPoolExecutor\nfrom ebooklib import epub\nimport ebooklib\nfrom bs4 import BeautifulSoup\nimport soundfile as sf\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nimport hashlib\n\n# Placeholder for KPipeline (replace with your actual text-to-speech library)\nclass KPipeline:\n    def __init__(self, lang_code, device):\n        self.lang_code = lang_code\n        self.device = device\n\n    def __call__(self, text, voice):\n        # Dummy implementation: replace with actual TTS logic\n        for i in range(0, len(text), 100):  # Simulate chunked audio generation\n            yield (None, None, np.random.rand(24000))  # 1-second dummy audio\n\nclass AudiobookCreator:\n    def __init__(self, epub_path, output_dir=\"audiobooks\", voice='af_heart', max_workers=4):\n        \"\"\"Initialize the AudiobookCreator with EPUB path and output settings.\"\"\"\n        self.epub_path = epub_path\n        self.epub_name = os.path.splitext(os.path.basename(epub_path))[0]\n        self.output_dir = os.path.join(output_dir, self.epub_name)\n        self.txt_dir = os.path.join(self.output_dir, \"txt\")\n        self.audio_dir = os.path.join(self.output_dir, \"audio\")\n        self.voice = voice\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.pipeline = KPipeline(lang_code='a', device=self.device)  # Replace with actual TTS\n        self.max_workers = max_workers\n        self.chapter_names = []\n\n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.INFO)\n        handler = logging.StreamHandler()\n        handler.setFormatter(logging.Formatter('%(levelname)s: %(message)s'))\n        self.logger.addHandler(handler)\n\n    def extract_chapters(self):\n        \"\"\"\n        Extract chapters from EPUB, using TOC for titles or falling back to headings.\n        \"\"\"\n        os.makedirs(self.txt_dir, exist_ok=True)\n        try:\n            book = epub.read_epub(self.epub_path)\n        except Exception as e:\n            self.logger.error(f\"Failed to read EPUB file: {e}\")\n            return\n\n        # Extract chapter names from TOC\n        for item in book.toc:\n            if isinstance(item, epub.Link):\n                self.chapter_names.append(item.title)\n\n        chapter_count = 0\n        items = list(book.get_items_of_type(ebooklib.ITEM_DOCUMENT))\n        for item in tqdm(items, desc=\"Extracting chapters\"):\n            chapter_count += 1\n            content = item.get_content().decode('utf-8')\n            soup = BeautifulSoup(content, 'html.parser')\n            text = soup.get_text(separator='\\n', strip=True)\n\n            # Determine chapter title\n            if chapter_count <= len(self.chapter_names):\n                chapter_name = self.chapter_names[chapter_count - 1]\n            else:\n                # Fallback to first heading\n                heading = soup.find(['h1', 'h2'])\n                chapter_name = heading.get_text(strip=True) if heading else f\"Chapter {chapter_count}\"\n\n            chapter_file = os.path.join(self.txt_dir, f\"{chapter_name}.txt\")\n            try:\n                with open(chapter_file, 'w', encoding='utf-8') as f:\n                    f.write(text)\n                self.logger.info(f\"Saved chapter text: {chapter_file}\")\n            except Exception as e:\n                self.logger.error(f\"Error writing {chapter_file}: {e}\")\n\n    def text_to_audio(self):\n        \"\"\"\n        Convert text files to audio with parallel processing, retries, and caching.\n        \"\"\"\n        os.makedirs(self.audio_dir, exist_ok=True)\n        txt_files = [f for f in os.listdir(self.txt_dir) if f.endswith('.txt')]\n\n        def generate_audio(txt_file):\n            chapter_name = os.path.splitext(txt_file)[0]\n            chapter_path = os.path.join(self.txt_dir, txt_file)\n            audio_path = os.path.join(self.audio_dir, f\"{chapter_name}.wav\")\n            cached_hash_path = audio_path + '.md5'\n\n            # Check cache\n            try:\n                with open(chapter_path, 'r', encoding='utf-8') as f:\n                    text = f.read()\n                text_hash = hashlib.md5(text.encode()).hexdigest()\n                if os.path.exists(audio_path) and os.path.exists(cached_hash_path):\n                    with open(cached_hash_path, 'r') as f:\n                        cached_hash = f.read().strip()\n                    if cached_hash == text_hash:\n                        self.logger.info(f\"Using cached audio for {chapter_name}\")\n                        return\n            except Exception as e:\n                self.logger.error(f\"Error checking cache for {chapter_path}: {e}\")\n\n            # Generate audio with retries\n            for attempt in range(3):  # Retry up to 3 times\n                try:\n                    generator = self.pipeline(text, voice=self.voice)\n                    combined_audio = []\n                    for _, _, audio in generator:\n                        combined_audio.append(audio)\n                    combined_audio = np.concatenate(combined_audio)\n                    sf.write(audio_path, combined_audio, 24000)\n                    # Save hash for caching\n                    with open(cached_hash_path, 'w') as f:\n                        f.write(text_hash)\n                    self.logger.info(f\"Saved audio: {audio_path}\")\n                    break\n                except Exception as e:\n                    self.logger.error(f\"Error converting {chapter_path} (attempt {attempt+1}): {e}\")\n                    if attempt == 2:\n                        self.logger.error(f\"Failed to convert {chapter_path} after 3 attempts\")\n                        raise\n\n        # Parallel processing\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            list(tqdm(executor.map(generate_audio, txt_files), total=len(txt_files), desc=\"Generating audio\"))\n\n    def create_audiobook(self):\n        \"\"\"\n        Combine audio files into a single M4B audiobook using ffmpeg.\n        \"\"\"\n        audio_files = sorted([f for f in os.listdir(self.audio_dir) if f.endswith(\".wav\")])\n        concat_file = os.path.join(self.output_dir, \"concat.txt\")\n        with open(concat_file, 'w') as f:\n            for audio_file in audio_files:\n                f.write(f\"file '{os.path.join(self.audio_dir, audio_file)}'\\n\")\n\n        combined_path = os.path.join(self.output_dir, f\"{self.epub_name}.m4b\")\n        cmd = [\n            \"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", concat_file,\n            \"-c\", \"copy\", combined_path\n        ]\n        try:\n            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            self.logger.info(f\"Audiobook created: {combined_path}\")\n        except subprocess.CalledProcessError as e:\n            self.logger.error(f\"FFmpeg error: {e.stderr.decode()}\")\n\n    def run(self):\n        \"\"\"Execute the full audiobook creation process.\"\"\"\n        self.extract_chapters()\n        self.text_to_audio()\n        self.create_audiobook()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:20:52.955287Z","iopub.execute_input":"2025-04-13T17:20:52.955889Z","iopub.status.idle":"2025-04-13T17:20:52.968801Z","shell.execute_reply.started":"2025-04-13T17:20:52.955865Z","shell.execute_reply":"2025-04-13T17:20:52.968096Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 52 µs, sys: 12 µs, total: 64 µs\nWall time: 67.7 µs\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"%%time\n# Example usage\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    creator = AudiobookCreator(\"/kaggle/input/ebooks-epubs/sample_01.epub\")\n    creator.run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:22:51.182447Z","iopub.execute_input":"2025-04-13T17:22:51.183356Z","iopub.status.idle":"2025-04-13T17:22:51.51943Z","shell.execute_reply.started":"2025-04-13T17:22:51.183322Z","shell.execute_reply":"2025-04-13T17:22:51.518907Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n/usr/local/lib/python3.11/dist-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\nExtracting chapters:   0%|          | 0/21 [00:00<?, ?it/s]INFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 1.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 1.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 1.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 1.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 2.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 2.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 2.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 2.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 3.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 3.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 3.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 3.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 4.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 4.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 4.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 4.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 5.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 5.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 5.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 5.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 6.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 6.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 6.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 6.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 7.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 7.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 7.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 7.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 8.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 8.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 8.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 8.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 9.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 9.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 9.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 9.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 10.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 10.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 10.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 10.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 11.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 11.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 11.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 11.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 12.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 12.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 12.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 12.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 13.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 13.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 13.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 13.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 14.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 14.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 14.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 14.txt\nExtracting chapters:  67%|██████▋   | 14/21 [00:00<00:00, 134.64it/s]INFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 15.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 15.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 15.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 15.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 16.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 16.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 16.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 16.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 17.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 17.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 17.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 17.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 18.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 18.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 18.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 18.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 19.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 19.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 19.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 19.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 20.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 20.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 20.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 20.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 21.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 21.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 21.txt\nINFO: Saved chapter text: audiobooks/sample_01/txt/Chapter 21.txt\nExtracting chapters: 100%|██████████| 21/21 [00:00<00:00, 132.92it/s]\nINFO: Using cached audio for Chapter 7\nINFO: Using cached audio for Chapter 7\nGenerating audio:   0%|          | 0/21 [00:00<?, ?it/s]INFO: Using cached audio for Chapter 7\nINFO: Using cached audio for Chapter 18\nINFO: Using cached audio for Chapter 18\nINFO: Using cached audio for Chapter 7\nINFO: Using cached audio for Chapter 17\nINFO: Using cached audio for Chapter 18\nINFO: Using cached audio for Chapter 17\nINFO: Using cached audio for Chapter 18\nINFO: Using cached audio for Chapter 14\nINFO: Using cached audio for Chapter 17\nINFO: Using cached audio for Chapter 17\nINFO: Using cached audio for Chapter 14\nINFO: Using cached audio for Chapter 14\nINFO: Using cached audio for Chapter 14\nINFO: Using cached audio for Chapter 16\nINFO: Using cached audio for Chapter 16\nINFO: Using cached audio for Chapter 19\nINFO: Using cached audio for Chapter 16\nINFO: Using cached audio for Chapter 4\nINFO: Using cached audio for Chapter 16\nINFO: Using cached audio for Chapter 19\nINFO: Using cached audio for Chapter 19\nINFO: Using cached audio for Chapter 19\nINFO: Using cached audio for Chapter 4\nINFO: Using cached audio for Chapter 20\nINFO: Using cached audio for Chapter 4\nINFO: Using cached audio for Chapter 20\nINFO: Using cached audio for Chapter 4\nINFO: Using cached audio for Chapter 20\nINFO: Using cached audio for Chapter 5\nINFO: Using cached audio for Chapter 20\nINFO: Using cached audio for Chapter 5\nINFO: Using cached audio for Chapter 10\nINFO: Using cached audio for Chapter 5\nINFO: Using cached audio for Chapter 10\nINFO: Using cached audio for Chapter 12\nINFO: Using cached audio for Chapter 12\nINFO: Using cached audio for Chapter 5\nINFO: Using cached audio for Chapter 10\nINFO: Using cached audio for Chapter 12\nINFO: Using cached audio for Chapter 10\nINFO: Using cached audio for Chapter 3\nINFO: Using cached audio for Chapter 3\nINFO: Using cached audio for Chapter 12\nINFO: Using cached audio for Chapter 3\nINFO: Using cached audio for Chapter 3\nINFO: Using cached audio for Chapter 8\nINFO: Using cached audio for Chapter 8\nINFO: Using cached audio for Chapter 21\nINFO: Using cached audio for Chapter 8\nINFO: Using cached audio for Chapter 21\nINFO: Using cached audio for Chapter 8\nINFO: Using cached audio for Chapter 21\nINFO: Using cached audio for Chapter 21\nINFO: Using cached audio for Chapter 15\nINFO: Using cached audio for Chapter 15\nINFO: Using cached audio for Chapter 1\nINFO: Using cached audio for Chapter 6\nINFO: Using cached audio for Chapter 15\nINFO: Using cached audio for Chapter 1\nINFO: Using cached audio for Chapter 15\nINFO: Using cached audio for Chapter 1\nINFO: Using cached audio for Chapter 6\nINFO: Using cached audio for Chapter 13\nINFO: Using cached audio for Chapter 1\nINFO: Using cached audio for Chapter 6\nINFO: Using cached audio for Chapter 13\nINFO: Using cached audio for Chapter 6\nINFO: Using cached audio for Chapter 11\nINFO: Using cached audio for Chapter 13\nINFO: Using cached audio for Chapter 11\nINFO: Using cached audio for Chapter 13\nINFO: Using cached audio for Chapter 11\nINFO: Using cached audio for Chapter 9\nINFO: Using cached audio for Chapter 11\nINFO: Using cached audio for Chapter 9\nINFO: Using cached audio for Chapter 2\nINFO: Using cached audio for Chapter 9\nINFO: Using cached audio for Chapter 2\nINFO: Using cached audio for Chapter 9\nINFO: Using cached audio for Chapter 2\nINFO: Using cached audio for Chapter 2\nGenerating audio: 100%|██████████| 21/21 [00:00<00:00, 412.82it/s]\nERROR: FFmpeg error: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[concat @ 0x5ba2adc3c540] Impossible to open 'audiobooks/sample_01/audiobooks/sample_01/audio/Chapter 1.wav'\naudiobooks/sample_01/concat.txt: No such file or directory\n\nERROR: FFmpeg error: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[concat @ 0x5ba2adc3c540] Impossible to open 'audiobooks/sample_01/audiobooks/sample_01/audio/Chapter 1.wav'\naudiobooks/sample_01/concat.txt: No such file or directory\n\nERROR: FFmpeg error: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[concat @ 0x5ba2adc3c540] Impossible to open 'audiobooks/sample_01/audiobooks/sample_01/audio/Chapter 1.wav'\naudiobooks/sample_01/concat.txt: No such file or directory\n\nERROR: FFmpeg error: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n[concat @ 0x5ba2adc3c540] Impossible to open 'audiobooks/sample_01/audiobooks/sample_01/audio/Chapter 1.wav'\naudiobooks/sample_01/concat.txt: No such file or directory\n\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 225 ms, sys: 47.2 ms, total: 272 ms\nWall time: 332 ms\n","output_type":"stream"}],"execution_count":17}]}