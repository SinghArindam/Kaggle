{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n# Set device to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Define VGG architecture\nclass VGG(nn.Module):\n    def __init__(self, vgg_name):\n        super(VGG, self).__init__()\n        self.cfg = {\n            'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n            'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n        }\n        self.features = self._make_layers(self.cfg[vgg_name])\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),  # Adjusted for 224x224 input after 5 max-pooling layers\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 10)  # CIFAR-10 has 10 classes\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _make_layers(self, cfg):\n        layers = []\n        in_channels = 3\n        for x in cfg:\n            if x == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                layers += [\n                    nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n                    nn.BatchNorm2d(x),\n                    nn.ReLU(inplace=True)\n                ]\n                in_channels = x\n        return nn.Sequential(*layers)\n\n# Data preprocessing and loading\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # VGG expects 224x224 images\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n\n# Initialize models\nvgg16 = VGG('VGG16').to(device)\nvgg19 = VGG('VGG19').to(device)\n\n# Loss function and optimizers\ncriterion = nn.CrossEntropyLoss()\noptimizer_vgg16 = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\noptimizer_vgg19 = optim.SGD(vgg19.parameters(), lr=0.001, momentum=0.9)\n\n# Training function with metrics tracking\ndef train_model(model, optimizer, num_epochs=10):\n    model.train()\n    train_losses = []\n    train_accuracies = []\n    test_accuracies = []\n    \n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        for i, data in enumerate(trainloader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            if i % 100 == 99:\n                batch_loss = running_loss / 100\n                batch_acc = 100 * correct / total\n                print(f'[Epoch {epoch + 1}, Batch {i + 1}] Loss: {batch_loss:.3f}, Accuracy: {batch_acc:.2f}%')\n                running_loss = 0.0\n                correct = 0\n                total = 0\n        \n        # Compute epoch metrics\n        epoch_loss = running_loss / len(trainloader)\n        epoch_acc = 100 * correct / total\n        train_losses.append(epoch_loss)\n        train_accuracies.append(epoch_acc)\n        \n        # Evaluate on test set\n        test_acc = evaluate_model(model, verbose=False)\n        test_accuracies.append(test_acc)\n    \n    return train_losses, train_accuracies, test_accuracies\n\n# Evaluation function\ndef evaluate_model(model, verbose=True):\n    model.eval()\n    correct = 0\n    total = 0\n    test_loss = 0.0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    if verbose:\n        print(f'Test Loss: {test_loss / len(testloader):.3f}, Accuracy: {accuracy:.2f}%')\n    return accuracy\n\n# Train and evaluate VGG-16\nprint(\"Training VGG-16...\")\nvgg16_train_losses, vgg16_train_accs, vgg16_test_accs = train_model(vgg16, optimizer_vgg16, num_epochs=10)\nprint(\"\\nEvaluating VGG-16...\")\nevaluate_model(vgg16)\n\n# Train and evaluate VGG-19\nprint(\"\\nTraining VGG-19...\")\nvgg19_train_losses, vgg19_train_accs, vgg19_test_accs = train_model(vgg19, optimizer_vgg19, num_epochs=10)\nprint(\"\\nEvaluating VGG-19...\")\nevaluate_model(vgg19)\n\n# Save models\ntorch.save(vgg16.state_dict(), 'vgg16_cifar10.pth')\ntorch.save(vgg19.state_dict(), 'vgg19_cifar10.pth')\n\n# Plotting results\nplt.figure(figsize=(15, 5))\n\n# Plot Training Loss\nplt.subplot(1, 3, 1)\nplt.plot(range(1, 11), vgg16_train_losses, label='VGG-16')\nplt.plot(range(1, 11), vgg19_train_losses, label='VGG-19')\nplt.title('Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot Training Accuracy\nplt.subplot(1, 3, 2)\nplt.plot(range(1, 11), vgg16_train_accs, label='VGG-16')\nplt.plot(range(1, 11), vgg19_train_accs, label='VGG-19')\nplt.title('Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\n\n# Plot Test Accuracy\nplt.subplot(1, 3, 3)\nplt.plot(range(1, 11), vgg16_test_accs, label='VGG-16')\nplt.plot(range(1, 11), vgg19_test_accs, label='VGG-19')\nplt.title('Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Print model summaries\nprint(\"\\nVGG-16 Summary:\")\nprint(vgg16)\nprint(\"\\nVGG-19 Summary:\")\nprint(vgg19)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:25:10.647303Z","iopub.execute_input":"2025-04-20T11:25:10.647587Z","execution_failed":"2025-04-20T11:31:38.927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}