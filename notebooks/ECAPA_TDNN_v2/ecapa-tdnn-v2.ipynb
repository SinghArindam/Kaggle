{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10545331,"sourceType":"datasetVersion","datasetId":6524657},{"sourceId":10671289,"sourceType":"datasetVersion","datasetId":6609570}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(\"Output Dir:\")\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:38:44.561393Z","iopub.execute_input":"2025-02-06T07:38:44.561829Z","iopub.status.idle":"2025-02-06T07:38:44.568532Z","shell.execute_reply.started":"2025-02-06T07:38:44.561793Z","shell.execute_reply":"2025-02-06T07:38:44.567429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# main.py - Combined ECAPA-TDNN code (Python 3.10)\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport numpy as np\nfrom typing import List, Tuple\n\n# ========================\n# dataLoader.py contents\n# ========================\nclass CustomDataset(data.Dataset):\n    def __init__(self, data_list: torch.Tensor, labels: torch.Tensor):\n        self.data_list = data_list.clone().detach()\n        self.labels = labels.clone().detach()\n\n    def __len__(self) -> int:\n        return len(self.data_list)\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        return self.data_list[idx].clone().detach(), self.labels[idx].clone().detach()\n\n# ========================\n# model.py contents\n# ========================\nclass ECAPA_TDNN(nn.Module):\n    def __init__(self, input_dim: int, output_dim: int):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, output_dim)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return self.fc(x)\n\n# ========================\n# loss.py contents\n# ========================\nclass SoftmaxLoss(nn.Module):\n    def __init__(self, num_classes: int, embedding_dim: int):\n        super().__init__()\n        self.fc = nn.Linear(embedding_dim, num_classes)\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, embeddings: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n        logits = self.fc(embeddings)\n        return self.loss_fn(logits, labels)\n\n# ========================\n# tools.py contents\n# ========================\ndef compute_accuracy(predictions: torch.Tensor, labels: torch.Tensor) -> float:\n    _, predicted = torch.max(predictions, 1)\n    return (predicted == labels).sum().item() / labels.size(0)\n\n# ========================\n# ECAPAModel.py & trainECAPAModel.py contents\n# ========================\ndef train_model(model: nn.Module, train_loader: data.DataLoader, criterion: nn.Module, optimizer: optim.Optimizer, epochs: int = 10) -> None:\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(torch.float32), labels.to(torch.long)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n\n# Main execution\nif __name__ == \"__main__\":\n    input_dim, output_dim, num_classes = 256, 512, 10\n    train_data = torch.randn(100, input_dim)\n    train_labels = torch.randint(0, num_classes, (100,))\n    train_dataset = CustomDataset(train_data, train_labels)\n    train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n    \n    model = ECAPA_TDNN(input_dim, output_dim)\n    criterion = SoftmaxLoss(num_classes, output_dim)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    train_model(model, train_loader, criterion, optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:38:44.572669Z","iopub.execute_input":"2025-02-06T07:38:44.573047Z","iopub.status.idle":"2025-02-06T07:38:44.694065Z","shell.execute_reply.started":"2025-02-06T07:38:44.573013Z","shell.execute_reply":"2025-02-06T07:38:44.692967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:38:44.69529Z","iopub.execute_input":"2025-02-06T07:38:44.695735Z","iopub.status.idle":"2025-02-06T07:38:44.701345Z","shell.execute_reply.started":"2025-02-06T07:38:44.695702Z","shell.execute_reply":"2025-02-06T07:38:44.700171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# main.py - ECAPA-TDNN for VoxCeleb on Kaggle (Python 3.10)\n\nimport os\nfrom glob import glob\nfrom typing import List, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchaudio\nimport torchaudio.transforms as T\nimport numpy as np\n\n# =======================\n# Custom VoxCeleb Dataset\n# =======================\nclass VoxCelebDataset(data.Dataset):\n    \"\"\"\n    Custom dataset loader for VoxCeleb data.\n    \n    Assumes a directory structure such as:\n      root/\n         id00001/\n             some_subfolder/\n                 *.wav\n         id00002/\n             some_subfolder/\n                 *.wav\n    \"\"\"\n    def __init__(self, root: str, transform=None):\n        self.transform = transform\n        self.file_list = []\n        self.speaker_list = []\n        # Walk through each speaker folder\n        for speaker in sorted(os.listdir(root)):\n            speaker_path = os.path.join(root, speaker)\n            if not os.path.isdir(speaker_path):\n                continue\n            # Each speaker folder may have multiple subfolders\n            for subfolder in sorted(os.listdir(speaker_path)):\n                subfolder_path = os.path.join(speaker_path, subfolder)\n                if not os.path.isdir(subfolder_path):\n                    continue\n                # Get all .wav files in this subfolder\n                files = glob(os.path.join(subfolder_path, \"*.wav\"))\n                for f in files:\n                    self.file_list.append(f)\n                    self.speaker_list.append(speaker)\n        # Create mapping from speaker ID (string) to a numeric label\n        self.speaker_set = sorted(list(set(self.speaker_list)))\n        self.speaker_to_label = {spk: idx for idx, spk in enumerate(self.speaker_set)}\n        \n    def __len__(self) -> int:\n        return len(self.file_list)\n    \n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n        wav_path = self.file_list[idx]\n        waveform, sample_rate = torchaudio.load(wav_path)\n        # If multi-channel, convert to mono by averaging\n        if waveform.shape[0] > 1:\n            waveform = waveform.mean(dim=0, keepdim=True)\n        # Apply transform (e.g., MelSpectrogram) if provided\n        if self.transform:\n            features = self.transform(waveform)\n        else:\n            features = waveform\n        # features shape expected: (channel, n_mels, time)\n        # For further processing, squeeze channel dim and transpose to (time, n_mels)\n        if features.dim() == 3:\n            features = features.squeeze(0).transpose(0, 1)\n        else:\n            features = features.transpose(0, 1)\n        label = self.speaker_to_label[self.speaker_list[idx]]\n        return features, label\n\ndef collate_fn(batch: List[Tuple[torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pads variable-length feature sequences (time x n_mels) with zeros to form a batch.\n    \n    Returns:\n      - padded features: (batch, max_time, n_mels)\n      - labels: (batch,)\n    \"\"\"\n    features = [item[0] for item in batch]\n    labels = [item[1] for item in batch]\n    lengths = [feat.shape[0] for feat in features]\n    max_len = max(lengths)\n    padded = []\n    for feat in features:\n        pad = torch.zeros(max_len, feat.shape[1])\n        pad[:feat.shape[0], :] = feat\n        padded.append(pad)\n    padded = torch.stack(padded)  # Shape: (batch, max_time, n_mels)\n    labels = torch.tensor(labels, dtype=torch.long)\n    return padded, labels\n\n# =======================\n# ECAPA-TDNN Implementation\n# =======================\n\nclass SE_Res2Block(nn.Module):\n    \"\"\"\n    Squeeze-Excitation Res2Block used in ECAPA-TDNN.\n    Splits channels into several segments, processes them with convolutions and residual connections,\n    then applies a squeeze-excitation module.\n    \"\"\"\n    def __init__(self, channels: int, scale: int = 8, kernel_size: int = 3, dilation: int = 1):\n        super().__init__()\n        self.scale = scale\n        self.width = channels // scale\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1)\n        self.bn1 = nn.BatchNorm1d(channels)\n        self.relu = nn.ReLU()\n        self.convs = nn.ModuleList([\n            nn.Conv1d(self.width, self.width, kernel_size=kernel_size,\n                      padding=dilation, dilation=dilation)\n            for _ in range(scale - 1)\n        ])\n        self.bn2 = nn.BatchNorm1d(channels)\n        self.conv3 = nn.Conv1d(channels, channels, kernel_size=1)\n        self.bn3 = nn.BatchNorm1d(channels)\n        self.se = nn.Sequential(\n            nn.AdaptiveAvgPool1d(1),\n            nn.Conv1d(channels, channels // 8, kernel_size=1),\n            nn.ReLU(),\n            nn.Conv1d(channels // 8, channels, kernel_size=1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        residual = x\n        out = self.relu(self.bn1(self.conv1(x)))\n        splits = torch.split(out, self.width, dim=1)\n        out_splits = [splits[0]]\n        for i in range(1, self.scale):\n            if i == 1:\n                sp = self.convs[i-1](splits[i])\n            else:\n                sp = self.convs[i-1](splits[i] + out_splits[i-1])\n            out_splits.append(sp)\n        out = torch.cat(out_splits, dim=1)\n        out = self.relu(self.bn2(out))\n        out = self.conv3(out)\n        out = self.bn3(out)\n        w = self.se(out)\n        out = out * w\n        return out + residual\n\nclass AttentiveStatsPooling(nn.Module):\n    \"\"\"\n    Attentive Statistics Pooling layer computes weighted mean and standard deviation over time.\n    \"\"\"\n    def __init__(self, in_channels: int, hidden_channels: int):\n        super().__init__()\n        self.tanh = nn.Tanh()\n        self.linear = nn.Conv1d(in_channels, hidden_channels, kernel_size=1)\n        self.attention = nn.Conv1d(hidden_channels, in_channels, kernel_size=1)\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x shape: (batch, channels, time)\n        alpha = self.tanh(self.linear(x))\n        alpha = self.attention(alpha)\n        alpha = torch.softmax(alpha, dim=2)\n        mean = torch.sum(x * alpha, dim=2)\n        std = torch.sqrt(torch.sum((x ** 2) * alpha, dim=2) - mean ** 2 + 1e-9)\n        return torch.cat([mean, std], dim=1)\n\nclass ECAPA_TDNN(nn.Module):\n    \"\"\"\n    ECAPA-TDNN model for speaker recognition.\n    Expects input features with shape (batch, time, n_mels).\n    \"\"\"\n    def __init__(self, input_dim: int = 80, channels: int = 512, emb_dim: int = 192, num_classes: int = 1000):\n        super().__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv1d(input_dim, channels, kernel_size=5, padding=2),\n            nn.BatchNorm1d(channels),\n            nn.ReLU()\n        )\n        self.layer2 = SE_Res2Block(channels, scale=8, kernel_size=3, dilation=2)\n        self.layer3 = SE_Res2Block(channels, scale=8, kernel_size=3, dilation=3)\n        self.layer4 = SE_Res2Block(channels, scale=8, kernel_size=3, dilation=4)\n        self.pooling = AttentiveStatsPooling(channels, channels)\n        self.fc = nn.Linear(channels * 2, emb_dim)\n        self.classifier = nn.Linear(emb_dim, num_classes)\n    \n    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        # x shape: (batch, time, feature)\n        x = x.transpose(1, 2)  # -> (batch, feature, time)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.pooling(x)  # -> (batch, channels*2)\n        emb = self.fc(x)\n        logits = self.classifier(emb)\n        return emb, logits\n\n# =======================\n# Loss and Training Functions\n# =======================\nclass SoftmaxLoss(nn.Module):\n    \"\"\"\n    A simple wrapper around CrossEntropyLoss.\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.loss_fn = nn.CrossEntropyLoss()\n    \n    def forward(self, logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n        return self.loss_fn(logits, labels)\n\ndef train_model(model: nn.Module, train_loader: data.DataLoader, criterion: nn.Module,\n                optimizer: optim.Optimizer, epochs: int = 10) -> None:\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0.0\n        for features, labels in train_loader:\n            features, labels = features.to(torch.float32), labels.to(torch.long)\n            optimizer.zero_grad()\n            emb, logits = model(features)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n\ndef test_model(model: nn.Module, test_loader: data.DataLoader) -> None:\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for features, labels in test_loader:\n            features, labels = features.to(torch.float32), labels.to(torch.long)\n            emb, logits = model(features)\n            _, predicted = torch.max(logits, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n\n# =======================\n# Main Execution\n# =======================\nif __name__ == \"__main__\":\n    # Define a transform to extract mel-spectrogram features\n    # Adjust the sample_rate if needed; here, we assume 16kHz audio.\n    transform = T.MelSpectrogram(sample_rate=16000, n_mels=80)\n    \n    # Define dataset roots (update these paths according to your Kaggle dataset structure)\n    train_root = \"/kaggle/input/audiodataset10percent/VoxCeleb/vox1_dev_wav\"\n    test_root = \"/kaggle/input/audiodataset10percent/VoxCeleb/vox1_test_wav\"\n    \n    # Initialize the training and testing datasets\n    train_dataset = VoxCelebDataset(root=train_root, transform=transform)\n    test_dataset = VoxCelebDataset(root=test_root, transform=transform)\n    \n    # Create DataLoaders with the custom collate function\n    train_loader = data.DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n    test_loader = data.DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n    \n    # Determine the number of speakers from the training dataset\n    num_classes = len(train_dataset.speaker_set)\n    print(f\"Number of speakers (classes): {num_classes}\")\n    \n    # Initialize model, loss, and optimizer\n    model = ECAPA_TDNN(input_dim=80, channels=512, emb_dim=192, num_classes=num_classes)\n    criterion = SoftmaxLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    print(\"Starting training...\")\n    train_model(model, train_loader, criterion, optimizer, epochs=10)\n    \n    print(\"Evaluating on test set...\")\n    test_model(model, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T07:44:26.696887Z","iopub.execute_input":"2025-02-06T07:44:26.697273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}