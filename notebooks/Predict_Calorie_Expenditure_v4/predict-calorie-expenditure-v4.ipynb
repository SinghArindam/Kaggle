{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":9112.245256,"end_time":"2025-05-27T15:43:53.860187","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-27T13:12:01.614931","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V","metadata":{"_cell_guid":"fb94bd38-d79e-4595-8de1-9ac99df56ab3","_uuid":"e892d7cb-b179-42f7-8fd6-1e757053626f","collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:14:21.916409Z","iopub.execute_input":"2025-05-28T08:14:21.916792Z","iopub.status.idle":"2025-05-28T08:14:22.056821Z","shell.execute_reply.started":"2025-05-28T08:14:21.916768Z","shell.execute_reply":"2025-05-28T08:14:22.055458Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.133166,"end_time":"2025-05-27T13:12:06.439825","exception":false,"start_time":"2025-05-27T13:12:06.306659","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import lib and Check Input and read","metadata":{"_cell_guid":"b351f33d-1a12-409c-b635-f408a8621abd","_uuid":"70804f5e-b23d-49eb-8b88-58a36883c12f","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.004161,"end_time":"2025-05-27T13:12:06.448592","exception":false,"start_time":"2025-05-27T13:12:06.444431","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport time\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\nimport optuna\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_path = \"/kaggle/input/playground-series-s5e5/train.csv\"\ntest_path = \"/kaggle/input/playground-series-s5e5/test.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\ntest_ids = test_df['id']","metadata":{"_cell_guid":"06bb2244-8b54-40fa-b656-95d4f5023852","_uuid":"6f4dac58-3cbf-4371-a25d-22b3df7289ba","collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:14:23.519776Z","iopub.execute_input":"2025-05-28T08:14:23.52049Z","iopub.status.idle":"2025-05-28T08:14:24.224088Z","shell.execute_reply.started":"2025-05-28T08:14:23.520455Z","shell.execute_reply":"2025-05-28T08:14:24.223387Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":16.183173,"end_time":"2025-05-27T13:12:22.635913","exception":false,"start_time":"2025-05-27T13:12:06.45274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip show xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T08:14:25.534218Z","iopub.execute_input":"2025-05-28T08:14:25.534595Z","iopub.status.idle":"2025-05-28T08:14:25.539067Z","shell.execute_reply.started":"2025-05-28T08:14:25.534572Z","shell.execute_reply":"2025-05-28T08:14:25.537953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(dir(xgb))\n# print(help(xgb))\n# print(dir(xgb.XGBRegressor))\n# print(help(xgb.XGBRegressor))\n# print(dir(xgb.XGBRFRegressor))\n# print(help(xgb.XGBRFRegressor))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T08:14:25.733968Z","iopub.execute_input":"2025-05-28T08:14:25.734242Z","iopub.status.idle":"2025-05-28T08:14:25.738277Z","shell.execute_reply.started":"2025-05-28T08:14:25.734225Z","shell.execute_reply":"2025-05-28T08:14:25.737345Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{"_cell_guid":"6ee4426f-d021-4f6b-a8a3-2ec7d2a8bb35","_uuid":"7b99a93c-2a7e-48ba-96da-3c93e703902d","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.004021,"end_time":"2025-05-27T13:12:22.644498","exception":false,"start_time":"2025-05-27T13:12:22.640477","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df['Sex_Reversed'] = train_df['Sex'].map({'male': 1, 'female': 0})\ntest_df['Sex_Reversed'] = test_df['Sex'].map({'male': 1, 'female': 0})\n\ntrain_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n\ntrain_df['Heart_Rate_pct'] = train_df['Heart_Rate'] / (220 - train_df['Age'])\ntest_df['Heart_Rate_pct'] = test_df['Heart_Rate'] / (220 - test_df['Age'])\n\ntrain_df['BMI'] = train_df['Weight'] / (train_df['Height']/100)**2\ntest_df['BMI'] = test_df['Weight'] / (test_df['Height']/100)**2\n\ntrain_df['BMR'] = np.where(\n    train_df['Sex'] == 'female',\n    10 * train_df['Weight'] + 6.25 * train_df['Height'] - 5 * train_df['Age'] - 161,\n    10 * train_df['Weight'] + 6.25 * train_df['Height'] - 5 * train_df['Age'] + 5\n)\ntest_df['BMR'] = np.where(\n    test_df['Sex'] == 'female',\n    10 * test_df['Weight'] + 6.25 * test_df['Height'] - 5 * test_df['Age'] - 161,\n    10 * test_df['Weight'] + 6.25 * test_df['Height'] - 5 * test_df['Age'] + 5\n)\n\ntrain_df['TSI'] = 5 * ((train_df['Body_Temp'] - 36.5) / (41.5 - 36.5)) + 5 * ((train_df['Heart_Rate'] - 60) / ((220 - train_df['Age']) - 60))\ntrain_df['RPE'] = train_df['Heart_Rate_pct'] + 0.1 * (train_df['Body_Temp'] - 37)\ntrain_df['FI'] = (train_df['Heart_Rate_pct'] ** 2) / train_df['Duration']\ntrain_df['CLI'] = (train_df['Heart_Rate'] * train_df['Duration']) / train_df['Weight']\ntrain_df['TLI'] = ((train_df['Body_Temp'] - 36.6) ** 2) * train_df['Duration']\ntrain_df['AMI'] = (train_df['BMR'] * train_df['Heart_Rate_pct']) / train_df['Duration']\ntrain_df['AWI'] = (train_df['Duration'] * train_df['Heart_Rate_pct']) / train_df['Age']\ntrain_df['WLI'] = train_df['Heart_Rate'] * train_df['Duration'] * train_df['Weight']\ntrain_df['VO2_Proxy'] = np.where(\n    train_df['Sex'] == 'female',\n    (0.85 * train_df['Duration']) / (train_df['Heart_Rate_pct'] * train_df['Age']),\n    (1.00 * train_df['Duration']) / (train_df['Heart_Rate_pct'] * train_df['Age']),\n)\ntest_df['TSI'] = 5 * ((test_df['Body_Temp'] - 36.5) / (41.5 - 36.5)) + 5 * ((test_df['Heart_Rate'] - 60) / ((220 - test_df['Age']) - 60))\ntest_df['RPE'] = test_df['Heart_Rate_pct'] + 0.1 * (test_df['Body_Temp'] - 37)\ntest_df['FI'] = (test_df['Heart_Rate_pct'] ** 2) / test_df['Duration']\ntest_df['CLI'] = (test_df['Heart_Rate'] * test_df['Duration']) / test_df['Weight']\ntest_df['TLI'] = ((test_df['Body_Temp'] - 36.6) ** 2) * test_df['Duration']\ntest_df['AMI'] = (test_df['BMR'] * test_df['Heart_Rate_pct']) / test_df['Duration']\ntest_df['AWI'] = (test_df['Duration'] * test_df['Heart_Rate_pct']) / test_df['Age']\ntest_df['WLI'] = test_df['Heart_Rate'] * test_df['Duration'] * test_df['Weight']\ntest_df['VO2_Proxy'] = np.where(\n    test_df['Sex'] == 'female',\n    (0.85 * test_df['Duration']) / (test_df['Heart_Rate_pct'] * test_df['Age']),\n    (1.00 * test_df['Duration']) / (test_df['Heart_Rate_pct'] * test_df['Age']),\n)\n\ntrain_df['Duration_HR'] = train_df['Duration'] * train_df['Heart_Rate']\ntest_df['Duration_HR'] = test_df['Duration'] * test_df['Heart_Rate']\n\ntrain_df['Duration2_HR'] = (train_df['Duration'])**2 * train_df['Heart_Rate']\ntest_df['Duration2_HR'] = (test_df['Duration'])**2 * test_df['Heart_Rate']\n\ntrain_df['Intensity'] = train_df['Heart_Rate'] / train_df['Duration']\ntest_df['Intensity'] = test_df['Heart_Rate'] / test_df['Duration']\n\nfor f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n        for f2 in ['Sex', 'Sex_Reversed']:\n            train_df[f'{f1}_x_{f2}'] = train_df[f1] * train_df[f2]\nfor f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n        for f2 in ['Sex', 'Sex_Reversed']:\n            test_df[f'{f1}_x_{f2}'] = test_df[f1] * test_df[f2]\n\ntrain_df['Body_Temp'] = train_df['Body_Temp'] - 37.0\ntest_df['Body_Temp'] = test_df['Body_Temp'] - 37.0\n\n# for col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n#         for agg in ['min', 'max']:\n#             agg_val = train_df.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n#             train_df = train_df.merge(agg_val, on='Sex', how='left')\n# for col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n#         for agg in ['min', 'max']:\n#             agg_val = test_df.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n#             test_df = test_df.merge(agg_val, on='Sex', how='left')\n\n# Calculate 'Heart_Rate_Ratio' for the training data\ntrain_df['Heart_Rate_Ratio'] = train_df['Heart_Rate'] / train_df['Age']\n# Calculate 'Heart_Rate_Ratio' for the testing data\ntest_df['Heart_Rate_Ratio'] = test_df['Heart_Rate'] / test_df['Age']\n\n# Calculate 'Weight_x_Duration' for the training data\ntrain_df['Weight_x_Duration'] = train_df['Weight'] * train_df['Duration']\n# Calculate 'Weight_x_Duration' for the testing data\ntest_df['Weight_x_Duration'] = test_df['Weight'] * test_df['Duration']\n\n# Calculate 'Height_x_Duration' for the training data\ntrain_df['Height_x_Duration'] = train_df['Height'] * train_df['Duration']\n# Calculate 'Height_x_Duration' for the testing data\ntest_df['Height_x_Duration'] = test_df['Height'] * test_df['Duration']\n\n# Calculate 'Weight_x_Height' for the training data\ntrain_df['Weight_x_Height'] = train_df['Weight'] * train_df['Height']\n# Calculate 'Weight_x_Height' for the testing data\ntest_df['Weight_x_Height'] = test_df['Weight'] * test_df['Height']\n\n# Calculate 'Weight_x_Intensity' for the training data\ntrain_df['Weight_x_Intensity'] = train_df['Weight'] * train_df['Intensity']\n# Calculate 'Weight_x_Intensity' for the testing data\ntest_df['Weight_x_Intensity'] = test_df['Weight'] * test_df['Intensity']\n\n# Calculate 'Height_x_Intensity' for the training data\ntrain_df['Height_x_Intensity'] = train_df['Height'] * train_df['Intensity']\n# Calculate 'Height_x_Intensity' for the testing data\ntest_df['Height_x_Intensity'] = test_df['Height'] * test_df['Intensity']\n\ntrain_df.drop(columns=['Sex_Reversed'], inplace=True)\ntest_df.drop(columns=['Sex_Reversed'], inplace=True)\n\ntrain_df.drop(columns=['id'], inplace=True)\ntest_df.drop(columns=['id'], inplace=True)","metadata":{"_cell_guid":"5ef17f18-54ca-44b6-b9de-764da5b0355d","_uuid":"bc82cfea-218a-4604-a6b7-27319197abd7","collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:14:26.719307Z","iopub.execute_input":"2025-05-28T08:14:26.719655Z","iopub.status.idle":"2025-05-28T08:14:27.311065Z","shell.execute_reply.started":"2025-05-28T08:14:26.719633Z","shell.execute_reply":"2025-05-28T08:14:27.310065Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":2.329869,"end_time":"2025-05-27T13:12:24.978548","exception":false,"start_time":"2025-05-27T13:12:22.648679","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling Numeric Features","metadata":{"_cell_guid":"b124b505-6d4b-417e-b3b8-ca82460fe740","_uuid":"1bbb0f62-0b1d-4d4f-8357-5b0c41781d60","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.003919,"end_time":"2025-05-27T13:12:24.987073","exception":false,"start_time":"2025-05-27T13:12:24.983154","status":"completed"},"tags":[]}},{"cell_type":"code","source":"features = train_df.columns.tolist()\nfeatures.remove('Calories')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:14:31.001903Z","iopub.execute_input":"2025-05-28T08:14:31.00221Z","iopub.status.idle":"2025-05-28T08:14:31.007538Z","shell.execute_reply.started":"2025-05-28T08:14:31.002188Z","shell.execute_reply":"2025-05-28T08:14:31.006384Z"},"papermill":{"duration":0.012081,"end_time":"2025-05-27T13:12:25.003696","exception":false,"start_time":"2025-05-27T13:12:24.991615","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ntrain_df[features] = scaler.fit_transform(train_df[features])\ntest_df[features] = scaler.transform(test_df[features])","metadata":{"_cell_guid":"706c6d45-0f72-4538-8f1f-ce4ec0ec6bfc","_uuid":"8f51e5c8-81b8-4fd7-b757-c425ec86b0c1","collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:14:33.010483Z","iopub.execute_input":"2025-05-28T08:14:33.010788Z","iopub.status.idle":"2025-05-28T08:14:33.834467Z","shell.execute_reply.started":"2025-05-28T08:14:33.010767Z","shell.execute_reply":"2025-05-28T08:14:33.833597Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.690359,"end_time":"2025-05-27T13:12:25.698614","exception":false,"start_time":"2025-05-27T13:12:25.008255","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.head())\nprint(train_df.tail())\n\nprint(test_df.head())\nprint(test_df.tail())","metadata":{"_cell_guid":"ff08f9cb-51b9-42ef-8486-9689f8570baa","_uuid":"8e9e1a45-c43c-4cbc-9e4e-6064c6fb022e","collapsed":false,"execution":{"iopub.status.busy":"2025-05-28T08:14:33.835691Z","iopub.execute_input":"2025-05-28T08:14:33.83593Z","iopub.status.idle":"2025-05-28T08:14:33.875679Z","shell.execute_reply.started":"2025-05-28T08:14:33.835912Z","shell.execute_reply":"2025-05-28T08:14:33.874752Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.042118,"end_time":"2025-05-27T13:12:25.745764","exception":false,"start_time":"2025-05-27T13:12:25.703646","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = train_df[features]\ny_train = train_df['Calories']\n\nX_test = test_df[features]\n\nX_train = X_train.fillna(0) # Fill NaNs in training features\nX_test = X_test.fillna(0) # Fill NaNs in test features","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:14:39.010664Z","iopub.execute_input":"2025-05-28T08:14:39.010948Z","iopub.status.idle":"2025-05-28T08:14:39.331142Z","shell.execute_reply.started":"2025-05-28T08:14:39.01093Z","shell.execute_reply":"2025-05-28T08:14:39.330337Z"},"papermill":{"duration":0.342998,"end_time":"2025-05-27T13:12:26.200283","exception":false,"start_time":"2025-05-27T13:12:25.857285","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Functions","metadata":{"papermill":{"duration":0.006417,"end_time":"2025-05-27T13:12:26.213228","exception":false,"start_time":"2025-05-27T13:12:26.206811","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## RMSLE Scorer","metadata":{"papermill":{"duration":0.005922,"end_time":"2025-05-27T13:12:26.224891","exception":false,"start_time":"2025-05-27T13:12:26.218969","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def rmsle_scorer(y_true, y_pred):\n    y_pred_positive = np.maximum(y_pred, 0.001) \n    return np.sqrt(mean_squared_log_error(y_true, y_pred_positive))","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:14:43.101632Z","iopub.execute_input":"2025-05-28T08:14:43.101948Z","iopub.status.idle":"2025-05-28T08:14:43.106633Z","shell.execute_reply.started":"2025-05-28T08:14:43.101925Z","shell.execute_reply":"2025-05-28T08:14:43.105732Z"},"papermill":{"duration":0.012205,"end_time":"2025-05-27T13:12:26.243479","exception":false,"start_time":"2025-05-27T13:12:26.231274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## KFold CV","metadata":{"papermill":{"duration":0.005403,"end_time":"2025-05-27T13:12:26.25472","exception":false,"start_time":"2025-05-27T13:12:26.249317","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def run_kfold_cv(X, y, model, model_name, n_splits, random_state=42):\n    print(f\"\\n--- Starting {n_splits}-Fold Cross-Validation for {model_name} ---\")\n    start_cv_time = time.time() # Start timing for the entire CV process\n\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    \n    fold_rmsle_scores = []\n    oof_predictions = np.zeros(X.shape[0]) \n    \n    fold_times = [] \n\n    # Iterate through each fold\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n        fold_start_time = time.time() # Start timing for the current fold\n\n        # Split data for the current fold\n        X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n        X_val_fold, y_val_fold = X.iloc[val_idx], y.iloc[val_idx]\n        \n        model_fold = model.__class__(**model.get_params()) \n        model_fold.fit(X_train_fold, y_train_fold) # Train the model on the training fold\n        \n        val_preds = model_fold.predict(X_val_fold) # Make predictions on the validation fold\n        \n        val_preds[val_preds < 0] = 0.001 \n        \n        # Store out-of-fold predictions\n        oof_predictions[val_idx] = val_preds\n\n        # Evaluate the model's performance on the validation set for this fold using RMSLE\n        try:\n            fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n            fold_rmsle_scores.append(fold_rmsle)\n        except ValueError as e:\n            print(f\"  Warning: Error calculating RMSLE for Fold {fold + 1} ({model_name}): {e}. Setting RMSLE to NaN.\")\n            fold_rmsle_scores.append(np.nan)\n\n        fold_end_time = time.time() # End timing for the current fold\n        fold_duration = fold_end_time - fold_start_time\n        fold_times.append(fold_duration)\n\n    end_cv_time = time.time() # End timing for the entire CV process\n    total_cv_time = end_cv_time - start_cv_time\n\n    # Summarize results\n    valid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\n    \n    mean_cv_rmsle = np.nan\n    std_cv_rmsle = np.nan\n    overall_oof_rmsle = np.nan\n\n    if valid_fold_rmsle_scores:\n        mean_cv_rmsle = np.mean(valid_fold_rmsle_scores)\n        std_cv_rmsle = np.std(valid_fold_rmsle_scores)\n        print(f\"\\n--- {n_splits}-Fold CV Summary for {model_name} ---\")\n        print(f\"Average RMSLE: {mean_cv_rmsle:.4f} +/- {std_cv_rmsle:.4f}\")\n    else:\n        print(f\"\\n--- {n_splits}-Fold CV Summary for {model_name} ---\")\n        print(f\"RMSLE calculation failed for all folds.\")\n\n    # Calculate overall OOF RMSLE if possible\n    if y.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n        try:\n            overall_oof_rmsle = np.sqrt(mean_squared_log_error(y, oof_predictions))\n            print(f\"Overall OOF RMSLE: {overall_oof_rmsle:.4f}\")\n        except ValueError as e:\n            print(f\"Error calculating Overall OOF RMSLE for {model_name}: {e}. Ensure target and predictions are non-negative.\")\n    \n    return {\n        'Model': model_name,\n        'N_Splits': n_splits,\n        'Average RMSLE': mean_cv_rmsle,\n        'Std RMSLE': std_cv_rmsle,\n        'Overall OOF RMSLE': overall_oof_rmsle,\n        'Total CV Time (s)': total_cv_time,\n        'Avg Fold Time (s)': np.mean(fold_times) if fold_times else np.nan\n    }","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:14:45.034847Z","iopub.execute_input":"2025-05-28T08:14:45.035168Z","iopub.status.idle":"2025-05-28T08:14:45.04653Z","shell.execute_reply.started":"2025-05-28T08:14:45.03515Z","shell.execute_reply":"2025-05-28T08:14:45.045623Z"},"papermill":{"duration":0.018776,"end_time":"2025-05-27T13:12:26.279239","exception":false,"start_time":"2025-05-27T13:12:26.260463","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{"papermill":{"duration":0.005495,"end_time":"2025-05-27T13:12:26.290712","exception":false,"start_time":"2025-05-27T13:12:26.285217","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n_splits_list = [5, 10, 15, 30, 50]\n\nRANDOM_STATE = 42","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:14:49.03916Z","iopub.execute_input":"2025-05-28T08:14:49.039517Z","iopub.status.idle":"2025-05-28T08:14:49.043887Z","shell.execute_reply.started":"2025-05-28T08:14:49.039493Z","shell.execute_reply":"2025-05-28T08:14:49.043014Z"},"papermill":{"duration":0.011489,"end_time":"2025-05-27T13:12:26.307875","exception":false,"start_time":"2025-05-27T13:12:26.296386","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Optuna","metadata":{}},{"cell_type":"code","source":"# --- General Optuna Objective Function ---\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\ndef general_objective(trial, model_class, model_name_prefix):\n    \"\"\"\n    General objective function for Optuna to optimize various booster models.\n    Minimizes the average RMSLE from 5-fold cross-validation.\n    \"\"\"\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'random_state': RANDOM_STATE,\n        'n_jobs': -1,\n    }\n\n    if model_class == lgb.LGBMRegressor:\n        params['objective'] = 'regression_l1'\n        params['metric'] = 'rmsle'\n        params['num_leaves'] = trial.suggest_int('num_leaves', 20, 100)\n        params['min_child_samples'] = trial.suggest_int('min_child_samples', 5, 50)\n        params['colsample_bytree'] = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n        params['reg_alpha'] = trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True)\n        params['reg_lambda'] = trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True)\n        # params['device'] = 'gpu'\n        params['verbose'] = -1\n\n    elif model_class == xgb.XGBRegressor:\n        params['objective'] = 'reg:squarederror'\n        params['eval_metric'] = 'rmse'\n        params['min_child_weight'] = trial.suggest_int('min_child_weight', 1, 10)\n        params['colsample_bytree'] = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n        params['gamma'] = trial.suggest_float('gamma', 1e-8, 1.0, log=True)\n        params['lambda'] = trial.suggest_float('lambda', 1e-8, 1.0, log=True) # reg_lambda\n        params['alpha'] = trial.suggest_float('alpha', 1e-8, 1.0, log=True)   # reg_alpha\n        # params['tree_method'] = 'gpu_hist'\n        # params['predictor'] = 'gpu_predictor'\n\n    # elif model_class == CatBoostRegressor:\n    #     params['iterations'] = params.pop('n_estimators') # CatBoost uses 'iterations'\n    #     params['loss_function'] = 'RMSE'\n    #     params['eval_metric'] = 'RMSE'\n    #     params['depth'] = params.pop('max_depth') # CatBoost uses 'depth'\n    #     params['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True)\n    #     params['colsample_bylevel'] = trial.suggest_float('colsample_bylevel', 0.6, 1.0)\n    #     params['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 1, 30)\n    #     params['random_seed'] = RANDOM_STATE # CatBoost uses random_seed\n    #     params.pop('n_jobs') # CatBoost uses thread_count\n    #     params['thread_count'] = -1\n    #     params['task_type'] = 'GPU'\n    #     params['verbose'] = 0 # Suppress verbose output\n        \n        # # Ensure bootstrap_type for subsampling\n        # if params['subsample'] < 1.0:\n        #     params['bootstrap_type'] = 'Bernoulli'\n        # else:\n        #     params['bootstrap_type'] = 'MVS' # Or 'Bayesian', 'No'\n\n    model = model_class(**params)\n    \n    # cv_results = run_kfold_cv(X_train, y_train, model, model_name_prefix, n_splits=1, random_state=RANDOM_STATE)\n    # Perform train-validation split\n    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n    \n    # Train the model\n    model.fit(X_tr, y_tr)\n    \n    # Predict on validation set\n    y_pred = model.predict(X_val)\n    \n    # Ensure non-negative predictions for RMSLE\n    y_pred = np.clip(y_pred, 0, None)\n    \n    # Calculate RMSLE\n    rmsle = np.sqrt(mean_squared_log_error(y_val, y_pred))\n    \n    return rmsle #cv_results['Average RMSLE']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T08:17:04.702245Z","iopub.execute_input":"2025-05-28T08:17:04.702613Z","iopub.status.idle":"2025-05-28T08:17:04.713356Z","shell.execute_reply.started":"2025-05-28T08:17:04.702594Z","shell.execute_reply":"2025-05-28T08:17:04.712485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Optuna Optimization for LightGBM ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"Starting Optuna Hyperparameter Optimization for LightGBM\")\nprint(\"=\"*80)\n\nstudy_lgbm = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\nstudy_lgbm.optimize(lambda trial: general_objective(trial, lgb.LGBMRegressor, \"LightGBM_Optuna\"), n_trials=100, show_progress_bar=True)\n\nprint(\"\\nOptuna LightGBM optimization finished.\")\nprint(\"Number of finished trials: \", len(study_lgbm.trials))\nprint(\"Best trial (LightGBM):\")\ntrial_lgbm = study_lgbm.best_trial\n\nprint(\"  Value (Avg RMSLE): \", trial_lgbm.value)\nprint(\"  Params: \")\nfor key, value in trial_lgbm.params.items():\n    print(f\"    {key}: {value}\")\n\nbest_lgbm_params = trial_lgbm.params\nbest_lgbm_params['objective'] = 'regression_l1'\nbest_lgbm_params['metric'] = 'rmse'\nbest_lgbm_params['random_state'] = RANDOM_STATE\nbest_lgbm_params['n_jobs'] = -1\n# best_lgbm_params['device'] = 'gpu'\nbest_lgbm_params['verbose'] = -1\n\n\n# --- Optuna Optimization for XGBoost ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"Starting Optuna Hyperparameter Optimization for XGBoost\")\nprint(\"=\"*80)\n\nstudy_xgb = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE + 1))\nstudy_xgb.optimize(lambda trial: general_objective(trial, xgb.XGBRegressor, \"XGBoost_Optuna\"), n_trials=100, show_progress_bar=True)\n\nprint(\"\\nOptuna XGBoost optimization finished.\")\nprint(\"Number of finished trials: \", len(study_xgb.trials))\nprint(\"Best trial (XGBoost):\")\ntrial_xgb = study_xgb.best_trial\n\nprint(\"  Value (Avg RMSLE): \", trial_xgb.value)\nprint(\"  Params: \")\nfor key, value in trial_xgb.params.items():\n    print(f\"    {key}: {value}\")\n\nbest_xgb_params = trial_xgb.params\nbest_xgb_params['objective'] = 'reg:squarederror'\nbest_xgb_params['eval_metric'] = 'rmse'\nbest_xgb_params['random_state'] = RANDOM_STATE\n# best_xgb_params['tree_method'] = 'gpu_hist' # Ensure GPU is set for the final model if available\n# best_xgb_params['predictor'] = 'gpu_predictor' # Ensure GPU is set for the final model if available\nbest_xgb_params['n_jobs'] = -1\n\n\n# # --- Optuna Optimization for CatBoost ---\n# print(\"\\n\" + \"=\"*80)\n# print(\"Starting Optuna Hyperparameter Optimization for CatBoost\")\n# print(\"=\"*80)\n\n# study_cat = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE + 2))\n# study_cat.optimize(lambda trial: general_objective(trial, CatBoostRegressor, \"CatBoost_Optuna\"), n_trials=50, show_progress_bar=True)\n\n# print(\"\\nOptuna CatBoost optimization finished.\")\n# print(\"Number of finished trials: \", len(study_cat.trials))\n# print(\"Best trial (CatBoost):\")\n# trial_cat = study_cat.best_trial\n\n# print(\"  Value (Avg RMSLE): \", trial_cat.value)\n# print(\"  Params: \")\n# for key, value in trial_cat.params.items():\n#     print(f\"    {key}: {value}\")\n\n# best_cat_params = trial_cat.params\n# best_cat_params['random_seed'] = RANDOM_STATE\n# best_cat_params['verbose'] = 0\n# best_cat_params['thread_count'] = -1\n# best_cat_params['eval_metric'] = 'RMSE'\n# best_cat_params['eval_metric'] = 'RMSE' \n# best_cat_params['task_type'] = 'GPU' # Ensure GPU is set for the final model if available\n# best_cat_params['loss_function'] = 'RMSE'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T08:17:19.201367Z","iopub.execute_input":"2025-05-28T08:17:19.201708Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Models\n","metadata":{"papermill":{"duration":0.005511,"end_time":"2025-05-27T13:12:26.319357","exception":false,"start_time":"2025-05-27T13:12:26.313846","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# models = {\n#     # \"Linear Regression\": LinearRegression(),\n#     # \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=RANDOM_STATE),\n#     # \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),\n#     # \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE),\n#     \"XGBoost Regressor\": xgb.XGBRegressor(\n#     n_estimators=1000,  # Start with a large number and use early stopping during training\n#     learning_rate=0.05,  # Start with a value in the suggested range (0.01 to 0.05)\n#     max_depth=6,         # Start in the suggested range (4 to 10)\n#     colsample_bytree=0.8, # Start in the suggested range (0.6 to 1.0). Lower if many features.\n#     subsample=0.8,       # Start in the suggested range (0.6 to 1.0)\n#     reg_alpha=0,         # You might want to tune this (e.g., 0 to 5)\n#     reg_lambda=1,        # You might want to tune this (e.g., 0 to 5)\n#     random_state=RANDOM_STATE,\n#     n_jobs=-1\n# ),\n#     \"LightGBM Regressor\": lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=RANDOM_STATE, n_jobs=-1),\n#     \"CatBoost Regressor\": CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=3, random_state=RANDOM_STATE, verbose=0, thread_count=-1)\n# }\n\nmodels = {\n    \"XGBoost Regressor\": xgb.XGBRegressor(**study_xgb.best_params),\n    \"LightGBM Regressor\": lgb.LGBMRegressor(**study_lgbm.best_params),\n    # \"CatBoost Regressor\": CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=3, random_state=RANDOM_STATE, verbose=0, thread_count=-1)\n}","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:16:38.059331Z","iopub.status.idle":"2025-05-28T08:16:38.059602Z","shell.execute_reply.started":"2025-05-28T08:16:38.059473Z","shell.execute_reply":"2025-05-28T08:16:38.05949Z"},"papermill":{"duration":0.015086,"end_time":"2025-05-27T13:12:26.3402","exception":false,"start_time":"2025-05-27T13:12:26.325114","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KFold and Train and Save CSV","metadata":{"papermill":{"duration":0.005969,"end_time":"2025-05-27T13:12:26.352206","exception":false,"start_time":"2025-05-27T13:12:26.346237","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# List to store all CV results for comparison table\nall_cv_results = []\n\n# --- Run K-Fold CV for Each Model ---\nfor model_name, model_instance in models.items():\n    print(f\"\\n{'='*80}\\nRunning K-Fold Cross-Validation for: {model_name}\\n{'='*80}\")\n    for n_splits_val in n_splits_list:\n        results = run_kfold_cv(X_train, y_train, model_instance, model_name, n_splits_val, RANDOM_STATE)\n        all_cv_results.append(results)\n    \n    # --- Train on Full X_train and Predict on X_test (after CV for this model) ---\n    print(f\"\\n--- Training {model_name} on full X_train and predicting on X_test ---\")\n    final_model = model_instance.__class__(**model_instance.get_params()) # Create a fresh instance for final training\n    \n    start_time_full_train = time.time()\n    final_model.fit(X_train, y_train)\n    end_time_full_train = time.time()\n    print(f\"Full training complete in {(end_time_full_train - start_time_full_train):.4f} seconds.\")\n\n    start_time_predict = time.time()\n    predictions_test = final_model.predict(X_test)\n    end_time_predict = time.time()\n    print(f\"Predictions made in {(end_time_predict - start_time_predict):.4f} seconds.\")\n\n    # Handle negative predictions for submission file\n    predictions_test[predictions_test < 0] = 0.001 #np.abs(predictions_test)\n    print(predictions_test)\n\n    # Save predictions to CSV\n    submission_df = pd.DataFrame({'id': test_ids, 'Predictions': predictions_test})\n    csv_filename = f'{model_name.replace(\" \", \"_\")}_predictions.csv'\n    submission_df.to_csv(csv_filename, index=False)\n    print(f\"Submission file '{csv_filename}' created successfully.\")\n\n    # Print feature importances if available (for tree-based models)\n    if hasattr(final_model, 'feature_importances_'):\n        print(f\"Feature Importances for {model_name}:\")\n        # Map feature importances to original feature names\n        feature_importances_df = pd.DataFrame({\n            'Feature': X_train.columns,\n            'Importance': final_model.feature_importances_\n        }).sort_values(by='Importance', ascending=False)\n        print(feature_importances_df.to_string(index=False))\n    print(f\"{'-'*80}\") # Separator after each model's full training/prediction","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:16:38.060424Z","iopub.status.idle":"2025-05-28T08:16:38.060789Z","shell.execute_reply.started":"2025-05-28T08:16:38.060608Z","shell.execute_reply":"2025-05-28T08:16:38.060625Z"},"papermill":{"duration":9085.265923,"end_time":"2025-05-27T15:43:51.624138","exception":false,"start_time":"2025-05-27T13:12:26.358215","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Comparison Table","metadata":{"papermill":{"duration":0.1815,"end_time":"2025-05-27T15:43:51.987911","exception":false,"start_time":"2025-05-27T15:43:51.806411","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Final Comparison Table\nprint(\"\\n\" + \"=\"*120) # Adjusted width for new columns and more models\nprint(\"                                Cross-Validation Summary Across Different Models and Folds                                \")\nprint(\"=\"*120)\n\n# Create a DataFrame from the results for a nice tabular output\nresults_df = pd.DataFrame(all_cv_results)\n\n# Sort for better comparison: by Model, then by N_Splits\nresults_df = results_df.sort_values(by=['Model', 'N_Splits']).reset_index(drop=True)\n\n# Format the numerical columns for better readability\nresults_df['Average RMSLE'] = results_df['Average RMSLE'].map('{:.4f}'.format)\nresults_df['Std RMSLE'] = results_df['Std RMSLE'].map('{:.4f}'.format)\nresults_df['Overall OOF RMSLE'] = results_df['Overall OOF RMSLE'].map('{:.4f}'.format)\nresults_df['Total CV Time (s)'] = results_df['Total CV Time (s)'].map('{:.4f}'.format)\nresults_df['Avg Fold Time (s)'] = results_df['Avg Fold Time (s)'].map('{:.4f}'.format)\n\n# Print the DataFrame\nprint(results_df.to_string(index=False))\nprint(\"=\"*120)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-28T08:16:38.705826Z","iopub.execute_input":"2025-05-28T08:16:38.706148Z","iopub.status.idle":"2025-05-28T08:16:38.723937Z","shell.execute_reply.started":"2025-05-28T08:16:38.706123Z","shell.execute_reply":"2025-05-28T08:16:38.722837Z"},"papermill":{"duration":0.198158,"end_time":"2025-05-27T15:43:52.447521","exception":false,"start_time":"2025-05-27T15:43:52.249363","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}