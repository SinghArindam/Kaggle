{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -V","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T10:43:30.113725Z","iopub.execute_input":"2025-05-25T10:43:30.113979Z","iopub.status.idle":"2025-05-25T10:43:30.242782Z","shell.execute_reply.started":"2025-05-25T10:43:30.113961Z","shell.execute_reply":"2025-05-25T10:43:30.241973Z"}},"outputs":[{"name":"stdout","text":"Python 3.11.11\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import lib and Check Input and read","metadata":{"_uuid":"70804f5e-b23d-49eb-8b88-58a36883c12f","_cell_guid":"b351f33d-1a12-409c-b635-f408a8621abd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport time\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_path = \"/kaggle/input/playground-series-s5e5/train.csv\"\ntest_path = \"/kaggle/input/playground-series-s5e5/test.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\ntest_ids = test_df['id']","metadata":{"_uuid":"6f4dac58-3cbf-4371-a25d-22b3df7289ba","_cell_guid":"06bb2244-8b54-40fa-b656-95d4f5023852","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-05-25T10:43:04.518Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Pre-Processing","metadata":{"_uuid":"7b99a93c-2a7e-48ba-96da-3c93e703902d","_cell_guid":"6ee4426f-d021-4f6b-a8a3-2ec7d2a8bb35","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"train_df['Sex_Reversed'] = train_df['Sex'].map({'male': 1, 'female': 0})\ntest_df['Sex_Reversed'] = test_df['Sex'].map({'male': 1, 'female': 0})\n\ntrain_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n\ntrain_df['BMI'] = train_df['Weight'] / (train_df['Height']/100)**2\ntest_df['BMI'] = test_df['Weight'] / (test_df['Height']/100)**2\n\ntrain_df['Duration_HR'] = train_df['Duration'] * train_df['Heart_Rate']\ntest_df['Duration_HR'] = test_df['Duration'] * test_df['Heart_Rate']\n\ntrain_df['Duration2_HR'] = (train_df['Duration'])**2 * train_df['Heart_Rate']\ntest_df['Duration2_HR'] = (test_df['Duration'])**2 * test_df['Heart_Rate']\n\ntrain_df['Intensity'] = train_df['Heart_Rate'] / train_df['Duration']\ntest_df['Intensity'] = test_df['Heart_Rate'] / test_df['Duration']\n\nfor f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n        for f2 in ['Sex', 'Sex_Reversed']:\n            train_df[f'{f1}_x_{f2}'] = train_df[f1] * train_df[f2]\nfor f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n        for f2 in ['Sex', 'Sex_Reversed']:\n            test_df[f'{f1}_x_{f2}'] = test_df[f1] * test_df[f2]\n\ntrain_df['Body_Temp'] = train_df['Body_Temp'] - 37.0\ntest_df['Body_Temp'] = test_df['Body_Temp'] - 37.0\n\nfor col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n        for agg in ['min', 'max']:\n            agg_val = train_df.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n            train_df = train_df.merge(agg_val, on='Sex', how='left')\nfor col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n        for agg in ['min', 'max']:\n            agg_val = test_df.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n            test_df = test_df.merge(agg_val, on='Sex', how='left')\n\ntrain_df.drop(columns=['Sex_Reversed'], inplace=True)\ntest_df.drop(columns=['Sex_Reversed'], inplace=True)","metadata":{"_uuid":"bc82cfea-218a-4604-a6b7-27319197abd7","_cell_guid":"5ef17f18-54ca-44b6-b9de-764da5b0355d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"execution_failed":"2025-05-25T10:43:04.519Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling Numeric Features","metadata":{"_uuid":"1bbb0f62-0b1d-4d4f-8357-5b0c41781d60","_cell_guid":"b124b505-6d4b-417e-b3b8-ca82460fe740","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"features = train_df.columns.tolist()\nfeatures.remove('Calories')\nprint(features)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.52Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ntrain_df[features] = scaler.fit_transform(train_df[features])\ntest_df[features] = scaler.transform(test_df[features])","metadata":{"_uuid":"8f51e5c8-81b8-4fd7-b757-c425ec86b0c1","_cell_guid":"706c6d45-0f72-4538-8f1f-ce4ec0ec6bfc","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-05-25T10:43:04.521Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head()","metadata":{"_uuid":"8e9e1a45-c43c-4cbc-9e4e-6064c6fb022e","_cell_guid":"ff08f9cb-51b9-42ef-8486-9689f8570baa","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"execution_failed":"2025-05-25T10:43:04.522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.tail()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head()","metadata":{"_uuid":"05321894-c83c-423b-9681-ed7452b9e1f8","_cell_guid":"bf5afce0-4aec-4c21-8c95-d082e20d84b1","trusted":true,"collapsed":false,"execution":{"execution_failed":"2025-05-25T10:43:04.527Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.tail()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.53Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = train_df[features]\ny_train = train_df['Calories']\n\nX_test = test_df[features]\n\nX_train = X_train.fillna(0) # Fill NaNs in training features\nX_test = X_test.fillna(0) # Fill NaNs in test features","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.532Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"markdown","source":"## RMSLE Scorer","metadata":{}},{"cell_type":"code","source":"def rmsle_scorer(y_true, y_pred):\n    y_pred_positive = np.maximum(y_pred, 0.001) \n    return np.sqrt(mean_squared_log_error(y_true, y_pred_positive))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.533Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## KFold CV","metadata":{}},{"cell_type":"code","source":"def run_kfold_cv(X, y, model, model_name, n_splits, random_state=42):\n    print(f\"\\n--- Starting {n_splits}-Fold Cross-Validation for {model_name} ---\")\n    start_cv_time = time.time() # Start timing for the entire CV process\n\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    \n    fold_rmsle_scores = []\n    oof_predictions = np.zeros(X.shape[0]) \n    \n    fold_times = [] \n\n    # Iterate through each fold\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n        fold_start_time = time.time() # Start timing for the current fold\n\n        # Split data for the current fold\n        X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n        X_val_fold, y_val_fold = X.iloc[val_idx], y.iloc[val_idx]\n        \n        model_fold = model.__class__(**model.get_params()) \n        model_fold.fit(X_train_fold, y_train_fold) # Train the model on the training fold\n        \n        val_preds = model_fold.predict(X_val_fold) # Make predictions on the validation fold\n        \n        val_preds[val_preds < 0] = 0.001 \n        \n        # Store out-of-fold predictions\n        oof_predictions[val_idx] = val_preds\n\n        # Evaluate the model's performance on the validation set for this fold using RMSLE\n        try:\n            fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n            fold_rmsle_scores.append(fold_rmsle)\n        except ValueError as e:\n            print(f\"  Warning: Error calculating RMSLE for Fold {fold + 1} ({model_name}): {e}. Setting RMSLE to NaN.\")\n            fold_rmsle_scores.append(np.nan)\n\n        fold_end_time = time.time() # End timing for the current fold\n        fold_duration = fold_end_time - fold_start_time\n        fold_times.append(fold_duration)\n\n    end_cv_time = time.time() # End timing for the entire CV process\n    total_cv_time = end_cv_time - start_cv_time\n\n    # Summarize results\n    valid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\n    \n    mean_cv_rmsle = np.nan\n    std_cv_rmsle = np.nan\n    overall_oof_rmsle = np.nan\n\n    if valid_fold_rmsle_scores:\n        mean_cv_rmsle = np.mean(valid_fold_rmsle_scores)\n        std_cv_rmsle = np.std(valid_fold_rmsle_scores)\n        print(f\"\\n--- {n_splits}-Fold CV Summary for {model_name} ---\")\n        print(f\"Average RMSLE: {mean_cv_rmsle:.4f} +/- {std_cv_rmsle:.4f}\")\n    else:\n        print(f\"\\n--- {n_splits}-Fold CV Summary for {model_name} ---\")\n        print(f\"RMSLE calculation failed for all folds.\")\n\n    # Calculate overall OOF RMSLE if possible\n    if y.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n        try:\n            overall_oof_rmsle = np.sqrt(mean_squared_log_error(y, oof_predictions))\n            print(f\"Overall OOF RMSLE: {overall_oof_rmsle:.4f}\")\n        except ValueError as e:\n            print(f\"Error calculating Overall OOF RMSLE for {model_name}: {e}. Ensure target and predictions are non-negative.\")\n    \n    return {\n        'Model': model_name,\n        'N_Splits': n_splits,\n        'Average RMSLE': mean_cv_rmsle,\n        'Std RMSLE': std_cv_rmsle,\n        'Overall OOF RMSLE': overall_oof_rmsle,\n        'Total CV Time (s)': total_cv_time,\n        'Avg Fold Time (s)': np.mean(fold_times) if fold_times else np.nan\n    }","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"n_splits_list = [5, 10, 15]\n\nRANDOM_STATE = 42","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Models\n","metadata":{}},{"cell_type":"code","source":"# models = {\n#     \"Linear Regression\": LinearRegression(),\n#     \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=RANDOM_STATE),\n#     \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),\n#     \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE),\n#     \"XGBoost Regressor\": xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE, n_jobs=-1),\n#     \"LightGBM Regressor\": lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, num_leaves=31, random_state=RANDOM_STATE, n_jobs=-1),\n#     \"CatBoost Regressor\": CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, random_state=RANDOM_STATE, verbose=0, thread_count=-1)\n# }\n\n# Assuming cuml is installed and environment is set up for GPU\nfrom cuml.linear_model import LinearRegression as LinearRegression\nfrom cuml.ensemble import RandomForestRegressor as CRandomForestRegressor\nfrom cuml.tree import DecisionTreeRegressor as DecisionTreeRegressor\nfrom cuml.ensemble import GradientBoostingRegressor as GradientBoostingRegressor # Note: cuML's GradientBoosting is still evolving\n\nmodels = {\n    # \"Linear Regression\": CUML_LinearRegression(), # Example of how you would replace it\n    \"Linear Regression\": LinearRegression(), # Keep original if cuML not used\n    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=RANDOM_STATE), # Keep original if cuML not used\n    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1), # Keep original if cuML not used\n    \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE), # Keep original if cuML not used\n    \"XGBoost Regressor\": xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE, tree_method='hist', device='cuda', n_jobs=-1),\n    \"LightGBM Regressor\": lgb.LGBMRegressor(n_estimators=100, learning_rate=0.1, num_leaves=31, random_state=RANDOM_STATE, device='gpu', n_jobs=-1),\n    \"CatBoost Regressor\": CatBoostRegressor(iterations=100, learning_rate=0.1, depth=3, random_state=RANDOM_STATE, verbose=0, thread_count=-1, task_type='GPU')\n}","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.536Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KFold and Train and Save CSV","metadata":{}},{"cell_type":"code","source":"# List to store all CV results for comparison table\nall_cv_results = []\n\n# --- Run K-Fold CV for Each Model ---\nfor model_name, model_instance in models.items():\n    print(f\"\\n{'='*80}\\nRunning K-Fold Cross-Validation for: {model_name}\\n{'='*80}\")\n    for n_splits_val in n_splits_list:\n        results = run_kfold_cv(X_train, y_train, model_instance, model_name, n_splits_val, RANDOM_STATE)\n        all_cv_results.append(results)\n    \n    # --- Train on Full X_train and Predict on X_test (after CV for this model) ---\n    print(f\"\\n--- Training {model_name} on full X_train and predicting on X_test ---\")\n    final_model = model_instance.__class__(**model_instance.get_params()) # Create a fresh instance for final training\n    \n    start_time_full_train = time.time()\n    final_model.fit(X_train, y_train)\n    end_time_full_train = time.time()\n    print(f\"Full training complete in {(end_time_full_train - start_time_full_train):.4f} seconds.\")\n\n    start_time_predict = time.time()\n    predictions_test = final_model.predict(X_test)\n    end_time_predict = time.time()\n    print(f\"Predictions made in {(end_time_predict - start_time_predict):.4f} seconds.\")\n\n    # Handle negative predictions for submission file\n    predictions_test[predictions_test < 0] = 0.001 #np.abs(predictions_test)\n    print(predictions_test)\n\n    # Save predictions to CSV\n    submission_df = pd.DataFrame({'id': test_ids, 'Predictions': predictions_test})\n    csv_filename = f'{model_name.replace(\" \", \"_\")}_predictions.csv'\n    submission_df.to_csv(csv_filename, index=False)\n    print(f\"Submission file '{csv_filename}' created successfully.\")\n\n    # Print feature importances if available (for tree-based models)\n    if hasattr(final_model, 'feature_importances_'):\n        print(f\"Feature Importances for {model_name}:\")\n        # Map feature importances to original feature names\n        feature_importances_df = pd.DataFrame({\n            'Feature': X_train.columns,\n            'Importance': final_model.feature_importances_\n        }).sort_values(by='Importance', ascending=False)\n        print(feature_importances_df.to_string(index=False))\n    print(f\"{'-'*80}\") # Separator after each model's full training/prediction","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.537Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Comparison Table","metadata":{}},{"cell_type":"code","source":"# --- Print Final Comparison Table ---\nprint(\"\\n\" + \"=\"*120) # Adjusted width for new columns and more models\nprint(\"                                Cross-Validation Summary Across Different Models and Folds                                \")\nprint(\"=\"*120)\n\n# Create a DataFrame from the results for a nice tabular output\nresults_df = pd.DataFrame(all_cv_results)\n\n# Sort for better comparison: by Model, then by N_Splits\nresults_df = results_df.sort_values(by=['Model', 'N_Splits']).reset_index(drop=True)\n\n# Format the numerical columns for better readability\nresults_df['Average RMSLE'] = results_df['Average RMSLE'].map('{:.4f}'.format)\nresults_df['Std RMSLE'] = results_df['Std RMSLE'].map('{:.4f}'.format)\nresults_df['Overall OOF RMSLE'] = results_df['Overall OOF RMSLE'].map('{:.4f}'.format)\nresults_df['Total CV Time (s)'] = results_df['Total CV Time (s)'].map('{:.4f}'.format)\nresults_df['Avg Fold Time (s)'] = results_df['Avg Fold Time (s)'].map('{:.4f}'.format)\n\n# Print the DataFrame\nprint(results_df.to_string(index=False))\nprint(\"=\"*120)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-25T10:43:04.539Z"}},"outputs":[],"execution_count":null}]}