{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91716,"databundleVersionId":11893428,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":9112.245256,"end_time":"2025-05-27T15:43:53.860187","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-27T13:12:01.614931","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"id":"b202b272","cell_type":"code","source":"!python -V","metadata":{"_cell_guid":"fb94bd38-d79e-4595-8de1-9ac99df56ab3","_uuid":"e892d7cb-b179-42f7-8fd6-1e757053626f","collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T17:15:01.411242Z","iopub.execute_input":"2025-05-27T17:15:01.411426Z","iopub.status.idle":"2025-05-27T17:15:01.54162Z","shell.execute_reply.started":"2025-05-27T17:15:01.41141Z","shell.execute_reply":"2025-05-27T17:15:01.540163Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.133166,"end_time":"2025-05-27T13:12:06.439825","exception":false,"start_time":"2025-05-27T13:12:06.306659","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f533efaf","cell_type":"markdown","source":"# Import lib and Check Input and read","metadata":{"_cell_guid":"b351f33d-1a12-409c-b635-f408a8621abd","_uuid":"70804f5e-b23d-49eb-8b88-58a36883c12f","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.004161,"end_time":"2025-05-27T13:12:06.448592","exception":false,"start_time":"2025-05-27T13:12:06.444431","status":"completed"},"tags":[]}},{"id":"ecd8c903","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport time\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\nimport optuna\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_path = \"/kaggle/input/playground-series-s5e5/train.csv\"\ntest_path = \"/kaggle/input/playground-series-s5e5/test.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\n\ntest_ids = test_df['id']","metadata":{"_cell_guid":"06bb2244-8b54-40fa-b656-95d4f5023852","_uuid":"6f4dac58-3cbf-4371-a25d-22b3df7289ba","collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T17:15:01.544619Z","iopub.execute_input":"2025-05-27T17:15:01.546705Z","iopub.status.idle":"2025-05-27T17:15:09.1737Z","shell.execute_reply.started":"2025-05-27T17:15:01.546674Z","shell.execute_reply":"2025-05-27T17:15:09.1731Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":16.183173,"end_time":"2025-05-27T13:12:22.635913","exception":false,"start_time":"2025-05-27T13:12:06.45274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"9be458e2-1b0f-465e-a967-d1a027712d93","cell_type":"code","source":"!pip show xgboost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T17:15:09.174339Z","iopub.execute_input":"2025-05-27T17:15:09.174539Z","iopub.status.idle":"2025-05-27T17:15:11.159302Z","shell.execute_reply.started":"2025-05-27T17:15:09.174523Z","shell.execute_reply":"2025-05-27T17:15:11.158393Z"}},"outputs":[],"execution_count":null},{"id":"990ba57f-4376-4a9c-ab28-e8508d975753","cell_type":"code","source":"# print(dir(xgb))\n# print(help(xgb))\n# print(dir(xgb.XGBRegressor))\nprint(help(xgb.XGBRegressor))\n# print(dir(xgb.XGBRFRegressor))\nprint(help(xgb.XGBRFRegressor))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T17:15:11.161584Z","iopub.execute_input":"2025-05-27T17:15:11.161848Z","iopub.status.idle":"2025-05-27T17:15:11.176645Z","shell.execute_reply.started":"2025-05-27T17:15:11.161824Z","shell.execute_reply":"2025-05-27T17:15:11.175924Z"},"scrolled":true},"outputs":[],"execution_count":null},{"id":"7b3dba21","cell_type":"markdown","source":"# Data Pre-Processing","metadata":{"_cell_guid":"6ee4426f-d021-4f6b-a8a3-2ec7d2a8bb35","_uuid":"7b99a93c-2a7e-48ba-96da-3c93e703902d","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.004021,"end_time":"2025-05-27T13:12:22.644498","exception":false,"start_time":"2025-05-27T13:12:22.640477","status":"completed"},"tags":[]}},{"id":"5ce19b23","cell_type":"code","source":"train_df['Sex_Reversed'] = train_df['Sex'].map({'male': 1, 'female': 0})\ntest_df['Sex_Reversed'] = test_df['Sex'].map({'male': 1, 'female': 0})\n\ntrain_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\n\ntrain_df['BMI'] = train_df['Weight'] / (train_df['Height']/100)**2\ntest_df['BMI'] = test_df['Weight'] / (test_df['Height']/100)**2\n\ntrain_df['Duration_HR'] = train_df['Duration'] * train_df['Heart_Rate']\ntest_df['Duration_HR'] = test_df['Duration'] * test_df['Heart_Rate']\n\ntrain_df['Duration2_HR'] = (train_df['Duration'])**2 * train_df['Heart_Rate']\ntest_df['Duration2_HR'] = (test_df['Duration'])**2 * test_df['Heart_Rate']\n\ntrain_df['Intensity'] = train_df['Heart_Rate'] / train_df['Duration']\ntest_df['Intensity'] = test_df['Heart_Rate'] / test_df['Duration']\n\nfor f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n        for f2 in ['Sex', 'Sex_Reversed']:\n            train_df[f'{f1}_x_{f2}'] = train_df[f1] * train_df[f2]\nfor f1 in ['Duration', 'Heart_Rate', 'Body_Temp']:\n        for f2 in ['Sex', 'Sex_Reversed']:\n            test_df[f'{f1}_x_{f2}'] = test_df[f1] * test_df[f2]\n\ntrain_df['Body_Temp'] = train_df['Body_Temp'] - 37.0\ntest_df['Body_Temp'] = test_df['Body_Temp'] - 37.0\n\n# for col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n#         for agg in ['min', 'max']:\n#             agg_val = train_df.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n#             train_df = train_df.merge(agg_val, on='Sex', how='left')\n# for col in ['Height', 'Weight', 'Heart_Rate', 'Body_Temp']:\n#         for agg in ['min', 'max']:\n#             agg_val = test_df.groupby('Sex')[col].agg(agg).rename(f'Sex_{col}_{agg}')\n#             test_df = test_df.merge(agg_val, on='Sex', how='left')\n\ntrain_df.drop(columns=['Sex_Reversed'], inplace=True)\ntest_df.drop(columns=['Sex_Reversed'], inplace=True)\n\ntrain_df.drop(columns=['id'], inplace=True)\ntest_df.drop(columns=['id'], inplace=True)","metadata":{"_cell_guid":"5ef17f18-54ca-44b6-b9de-764da5b0355d","_uuid":"bc82cfea-218a-4604-a6b7-27319197abd7","collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T17:15:11.177321Z","iopub.execute_input":"2025-05-27T17:15:11.177553Z","iopub.status.idle":"2025-05-27T17:15:11.52612Z","shell.execute_reply.started":"2025-05-27T17:15:11.177522Z","shell.execute_reply":"2025-05-27T17:15:11.525175Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":2.329869,"end_time":"2025-05-27T13:12:24.978548","exception":false,"start_time":"2025-05-27T13:12:22.648679","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"515638aa","cell_type":"markdown","source":"## Scaling Numeric Features","metadata":{"_cell_guid":"b124b505-6d4b-417e-b3b8-ca82460fe740","_uuid":"1bbb0f62-0b1d-4d4f-8357-5b0c41781d60","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.003919,"end_time":"2025-05-27T13:12:24.987073","exception":false,"start_time":"2025-05-27T13:12:24.983154","status":"completed"},"tags":[]}},{"id":"9ebd1dab","cell_type":"code","source":"features = train_df.columns.tolist()\nfeatures.remove('Calories')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2025-05-27T17:15:11.526964Z","iopub.execute_input":"2025-05-27T17:15:11.527187Z","iopub.status.idle":"2025-05-27T17:15:11.531462Z","shell.execute_reply.started":"2025-05-27T17:15:11.527168Z","shell.execute_reply":"2025-05-27T17:15:11.53088Z"},"papermill":{"duration":0.012081,"end_time":"2025-05-27T13:12:25.003696","exception":false,"start_time":"2025-05-27T13:12:24.991615","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d5839909","cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\ntrain_df[features] = scaler.fit_transform(train_df[features])\ntest_df[features] = scaler.transform(test_df[features])","metadata":{"_cell_guid":"706c6d45-0f72-4538-8f1f-ce4ec0ec6bfc","_uuid":"8f51e5c8-81b8-4fd7-b757-c425ec86b0c1","collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T17:15:11.532232Z","iopub.execute_input":"2025-05-27T17:15:11.532451Z","iopub.status.idle":"2025-05-27T17:15:11.9694Z","shell.execute_reply.started":"2025-05-27T17:15:11.532427Z","shell.execute_reply":"2025-05-27T17:15:11.968506Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.690359,"end_time":"2025-05-27T13:12:25.698614","exception":false,"start_time":"2025-05-27T13:12:25.008255","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ef5b807f-247a-4fc1-b63c-d1d87b668689","cell_type":"code","source":"print(train_df.head())\nprint(train_df.tail())\n\nprint(test_df.head())\nprint(test_df.tail())","metadata":{"_cell_guid":"ff08f9cb-51b9-42ef-8486-9689f8570baa","_uuid":"8e9e1a45-c43c-4cbc-9e4e-6064c6fb022e","collapsed":false,"execution":{"iopub.status.busy":"2025-05-27T17:15:11.970269Z","iopub.execute_input":"2025-05-27T17:15:11.970572Z","iopub.status.idle":"2025-05-27T17:15:11.999746Z","shell.execute_reply.started":"2025-05-27T17:15:11.970543Z","shell.execute_reply":"2025-05-27T17:15:11.999192Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.042118,"end_time":"2025-05-27T13:12:25.745764","exception":false,"start_time":"2025-05-27T13:12:25.703646","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"8abd4a6a","cell_type":"code","source":"X_train = train_df[features]\ny_train = train_df['Calories']\n\nX_test = test_df[features]\n\nX_train = X_train.fillna(0) # Fill NaNs in training features\nX_test = X_test.fillna(0) # Fill NaNs in test features","metadata":{"execution":{"iopub.status.busy":"2025-05-27T17:15:12.000364Z","iopub.execute_input":"2025-05-27T17:15:12.000595Z","iopub.status.idle":"2025-05-27T17:15:12.206905Z","shell.execute_reply.started":"2025-05-27T17:15:12.000572Z","shell.execute_reply":"2025-05-27T17:15:12.206301Z"},"papermill":{"duration":0.342998,"end_time":"2025-05-27T13:12:26.200283","exception":false,"start_time":"2025-05-27T13:12:25.857285","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c39a6349","cell_type":"markdown","source":"# Functions","metadata":{"papermill":{"duration":0.006417,"end_time":"2025-05-27T13:12:26.213228","exception":false,"start_time":"2025-05-27T13:12:26.206811","status":"completed"},"tags":[]}},{"id":"6f00c09b","cell_type":"markdown","source":"## RMSLE Scorer","metadata":{"papermill":{"duration":0.005922,"end_time":"2025-05-27T13:12:26.224891","exception":false,"start_time":"2025-05-27T13:12:26.218969","status":"completed"},"tags":[]}},{"id":"5b2a7262","cell_type":"code","source":"def rmsle_scorer(y_true, y_pred):\n    y_pred_positive = np.maximum(y_pred, 0.001) \n    return np.sqrt(mean_squared_log_error(y_true, y_pred_positive))","metadata":{"execution":{"iopub.status.busy":"2025-05-27T17:15:12.209345Z","iopub.execute_input":"2025-05-27T17:15:12.209573Z","iopub.status.idle":"2025-05-27T17:15:12.213441Z","shell.execute_reply.started":"2025-05-27T17:15:12.209556Z","shell.execute_reply":"2025-05-27T17:15:12.212754Z"},"papermill":{"duration":0.012205,"end_time":"2025-05-27T13:12:26.243479","exception":false,"start_time":"2025-05-27T13:12:26.231274","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"53911aa5","cell_type":"markdown","source":"## KFold CV","metadata":{"papermill":{"duration":0.005403,"end_time":"2025-05-27T13:12:26.25472","exception":false,"start_time":"2025-05-27T13:12:26.249317","status":"completed"},"tags":[]}},{"id":"86aef4f2","cell_type":"code","source":"def run_kfold_cv(X, y, model, model_name, n_splits, random_state=42):\n    print(f\"\\n--- Starting {n_splits}-Fold Cross-Validation for {model_name} ---\")\n    start_cv_time = time.time() # Start timing for the entire CV process\n\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    \n    fold_rmsle_scores = []\n    oof_predictions = np.zeros(X.shape[0]) \n    \n    fold_times = [] \n\n    # Iterate through each fold\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n        fold_start_time = time.time() # Start timing for the current fold\n\n        # Split data for the current fold\n        X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n        X_val_fold, y_val_fold = X.iloc[val_idx], y.iloc[val_idx]\n        \n        model_fold = model.__class__(**model.get_params()) \n        model_fold.fit(X_train_fold, y_train_fold) # Train the model on the training fold\n        \n        val_preds = model_fold.predict(X_val_fold) # Make predictions on the validation fold\n        \n        val_preds[val_preds < 0] = 0.001 \n        \n        # Store out-of-fold predictions\n        oof_predictions[val_idx] = val_preds\n\n        # Evaluate the model's performance on the validation set for this fold using RMSLE\n        try:\n            fold_rmsle = np.sqrt(mean_squared_log_error(y_val_fold, val_preds))\n            fold_rmsle_scores.append(fold_rmsle)\n        except ValueError as e:\n            print(f\"  Warning: Error calculating RMSLE for Fold {fold + 1} ({model_name}): {e}. Setting RMSLE to NaN.\")\n            fold_rmsle_scores.append(np.nan)\n\n        fold_end_time = time.time() # End timing for the current fold\n        fold_duration = fold_end_time - fold_start_time\n        fold_times.append(fold_duration)\n\n    end_cv_time = time.time() # End timing for the entire CV process\n    total_cv_time = end_cv_time - start_cv_time\n\n    # Summarize results\n    valid_fold_rmsle_scores = [s for s in fold_rmsle_scores if not np.isnan(s)]\n    \n    mean_cv_rmsle = np.nan\n    std_cv_rmsle = np.nan\n    overall_oof_rmsle = np.nan\n\n    if valid_fold_rmsle_scores:\n        mean_cv_rmsle = np.mean(valid_fold_rmsle_scores)\n        std_cv_rmsle = np.std(valid_fold_rmsle_scores)\n        print(f\"\\n--- {n_splits}-Fold CV Summary for {model_name} ---\")\n        print(f\"Average RMSLE: {mean_cv_rmsle:.4f} +/- {std_cv_rmsle:.4f}\")\n    else:\n        print(f\"\\n--- {n_splits}-Fold CV Summary for {model_name} ---\")\n        print(f\"RMSLE calculation failed for all folds.\")\n\n    # Calculate overall OOF RMSLE if possible\n    if y.min() >= 0 and oof_predictions.min() >= 0 and valid_fold_rmsle_scores:\n        try:\n            overall_oof_rmsle = np.sqrt(mean_squared_log_error(y, oof_predictions))\n            print(f\"Overall OOF RMSLE: {overall_oof_rmsle:.4f}\")\n        except ValueError as e:\n            print(f\"Error calculating Overall OOF RMSLE for {model_name}: {e}. Ensure target and predictions are non-negative.\")\n    \n    return {\n        'Model': model_name,\n        'N_Splits': n_splits,\n        'Average RMSLE': mean_cv_rmsle,\n        'Std RMSLE': std_cv_rmsle,\n        'Overall OOF RMSLE': overall_oof_rmsle,\n        'Total CV Time (s)': total_cv_time,\n        'Avg Fold Time (s)': np.mean(fold_times) if fold_times else np.nan\n    }","metadata":{"execution":{"iopub.status.busy":"2025-05-27T17:15:12.21417Z","iopub.execute_input":"2025-05-27T17:15:12.214392Z","iopub.status.idle":"2025-05-27T17:15:12.230081Z","shell.execute_reply.started":"2025-05-27T17:15:12.214377Z","shell.execute_reply":"2025-05-27T17:15:12.229324Z"},"papermill":{"duration":0.018776,"end_time":"2025-05-27T13:12:26.279239","exception":false,"start_time":"2025-05-27T13:12:26.260463","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"257faa9c","cell_type":"markdown","source":"# Hyperparameters","metadata":{"papermill":{"duration":0.005495,"end_time":"2025-05-27T13:12:26.290712","exception":false,"start_time":"2025-05-27T13:12:26.285217","status":"completed"},"tags":[]}},{"id":"d80a54f3","cell_type":"code","source":"n_splits_list = [5, 10, 15]\n\nRANDOM_STATE = 42","metadata":{"execution":{"iopub.status.busy":"2025-05-27T17:15:12.230688Z","iopub.execute_input":"2025-05-27T17:15:12.230846Z","iopub.status.idle":"2025-05-27T17:15:12.247149Z","shell.execute_reply.started":"2025-05-27T17:15:12.230834Z","shell.execute_reply":"2025-05-27T17:15:12.246398Z"},"papermill":{"duration":0.011489,"end_time":"2025-05-27T13:12:26.307875","exception":false,"start_time":"2025-05-27T13:12:26.296386","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"3aca88f5-6d21-44d0-b4e7-197b88a4f0dc","cell_type":"code","source":"# --- General Optuna Objective Function ---\ndef general_objective(trial, model_class, model_name_prefix):\n    \"\"\"\n    General objective function for Optuna to optimize various booster models.\n    Minimizes the average RMSLE from 5-fold cross-validation.\n    \"\"\"\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n        'random_state': RANDOM_STATE,\n        'n_jobs': -1,\n    }\n\n    if model_class == lgb.LGBMRegressor:\n        params['objective'] = 'regression_l1'\n        params['metric'] = 'rmse'\n        params['num_leaves'] = trial.suggest_int('num_leaves', 20, 100)\n        params['min_child_samples'] = trial.suggest_int('min_child_samples', 5, 50)\n        params['colsample_bytree'] = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n        params['reg_alpha'] = trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True)\n        params['reg_lambda'] = trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True)\n        params['device'] = 'gpu'\n        params['verbose'] = -1\n\n    elif model_class == xgb.XGBRegressor:\n        params['objective'] = 'reg:squarederror'\n        params['eval_metric'] = 'rmse'\n        params['min_child_weight'] = trial.suggest_int('min_child_weight', 1, 10)\n        params['colsample_bytree'] = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n        params['gamma'] = trial.suggest_float('gamma', 1e-8, 1.0, log=True)\n        params['lambda'] = trial.suggest_float('lambda', 1e-8, 1.0, log=True) # reg_lambda\n        params['alpha'] = trial.suggest_float('alpha', 1e-8, 1.0, log=True)   # reg_alpha\n        params['tree_method'] = 'gpu_hist'\n        params['predictor'] = 'gpu_predictor'\n\n    elif model_class == CatBoostRegressor:\n        params['iterations'] = params.pop('n_estimators') # CatBoost uses 'iterations'\n        params['loss_function'] = 'RMSE'\n        params['eval_metric'] = 'RMSE'\n        params['depth'] = params.pop('max_depth') # CatBoost uses 'depth'\n        params['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 1e-8, 10.0, log=True)\n        params['colsample_bylevel'] = trial.suggest_float('colsample_bylevel', 0.6, 1.0)\n        params['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 1, 30)\n        params['random_seed'] = RANDOM_STATE # CatBoost uses random_seed\n        params.pop('n_jobs') # CatBoost uses thread_count\n        params['thread_count'] = -1\n        params['task_type'] = 'GPU'\n        params['verbose'] = 0 # Suppress verbose output\n        \n        # Ensure bootstrap_type for subsampling\n        if params['subsample'] < 1.0:\n            params['bootstrap_type'] = 'Bernoulli'\n        else:\n            params['bootstrap_type'] = 'MVS' # Or 'Bayesian', 'No'\n\n    model = model_class(**params)\n    \n    cv_results = run_kfold_cv(X_train, y_train, model, model_name_prefix, n_splits=5, random_state=RANDOM_STATE)\n    \n    return cv_results['Average RMSLE']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T17:15:12.247875Z","iopub.execute_input":"2025-05-27T17:15:12.248473Z","iopub.status.idle":"2025-05-27T17:15:12.268885Z","shell.execute_reply.started":"2025-05-27T17:15:12.248457Z","shell.execute_reply":"2025-05-27T17:15:12.268309Z"}},"outputs":[],"execution_count":null},{"id":"5be30589-5a2d-416b-90c0-810541991033","cell_type":"code","source":"# --- Optuna Optimization for LightGBM ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"Starting Optuna Hyperparameter Optimization for LightGBM\")\nprint(\"=\"*80)\n\nstudy_lgbm = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE))\nstudy_lgbm.optimize(lambda trial: general_objective(trial, lgb.LGBMRegressor, \"LightGBM_Optuna\"), n_trials=50, show_progress_bar=True)\n\nprint(\"\\nOptuna LightGBM optimization finished.\")\nprint(\"Number of finished trials: \", len(study_lgbm.trials))\nprint(\"Best trial (LightGBM):\")\ntrial_lgbm = study_lgbm.best_trial\n\nprint(\"  Value (Avg RMSLE): \", trial_lgbm.value)\nprint(\"  Params: \")\nfor key, value in trial_lgbm.params.items():\n    print(f\"    {key}: {value}\")\n\nbest_lgbm_params = trial_lgbm.params\nbest_lgbm_params['objective'] = 'regression_l1'\nbest_lgbm_params['metric'] = 'rmse'\nbest_lgbm_params['random_state'] = RANDOM_STATE\nbest_lgbm_params['n_jobs'] = -1\nbest_lgbm_params['device'] = 'gpu'\nbest_lgbm_params['verbose'] = -1\n\n\n# --- Optuna Optimization for XGBoost ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"Starting Optuna Hyperparameter Optimization for XGBoost\")\nprint(\"=\"*80)\n\nstudy_xgb = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE + 1))\nstudy_xgb.optimize(lambda trial: general_objective(trial, xgb.XGBRegressor, \"XGBoost_Optuna\"), n_trials=50, show_progress_bar=True)\n\nprint(\"\\nOptuna XGBoost optimization finished.\")\nprint(\"Number of finished trials: \", len(study_xgb.trials))\nprint(\"Best trial (XGBoost):\")\ntrial_xgb = study_xgb.best_trial\n\nprint(\"  Value (Avg RMSLE): \", trial_xgb.value)\nprint(\"  Params: \")\nfor key, value in trial_xgb.params.items():\n    print(f\"    {key}: {value}\")\n\nbest_xgb_params = trial_xgb.params\nbest_xgb_params['objective'] = 'reg:squarederror'\nbest_xgb_params['eval_metric'] = 'rmse'\nbest_xgb_params['random_state'] = RANDOM_STATE\nbest_xgb_params['tree_method'] = 'gpu_hist' # Ensure GPU is set for the final model if available\nbest_xgb_params['predictor'] = 'gpu_predictor' # Ensure GPU is set for the final model if available\nbest_xgb_params['n_jobs'] = -1\n\n\n# --- Optuna Optimization for CatBoost ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"Starting Optuna Hyperparameter Optimization for CatBoost\")\nprint(\"=\"*80)\n\nstudy_cat = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE + 2))\nstudy_cat.optimize(lambda trial: general_objective(trial, CatBoostRegressor, \"CatBoost_Optuna\"), n_trials=50, show_progress_bar=True)\n\nprint(\"\\nOptuna CatBoost optimization finished.\")\nprint(\"Number of finished trials: \", len(study_cat.trials))\nprint(\"Best trial (CatBoost):\")\ntrial_cat = study_cat.best_trial\n\nprint(\"  Value (Avg RMSLE): \", trial_cat.value)\nprint(\"  Params: \")\nfor key, value in trial_cat.params.items():\n    print(f\"    {key}: {value}\")\n\nbest_cat_params = trial_cat.params\nbest_cat_params['random_seed'] = RANDOM_STATE\nbest_cat_params['verbose'] = 0\nbest_cat_params['thread_count'] = -1\nbest_cat_params['eval_metric'] = 'RMSE'\nbest_cat_params['eval_metric'] = 'RMSE' \nbest_cat_params['task_type'] = 'GPU' # Ensure GPU is set for the final model if available\nbest_cat_params['loss_function'] = 'RMSE'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T17:15:12.2697Z","iopub.execute_input":"2025-05-27T17:15:12.269879Z","execution_failed":"2025-05-27T17:20:34.275Z"}},"outputs":[],"execution_count":null},{"id":"1766faa4","cell_type":"markdown","source":"# Models\n","metadata":{"papermill":{"duration":0.005511,"end_time":"2025-05-27T13:12:26.319357","exception":false,"start_time":"2025-05-27T13:12:26.313846","status":"completed"},"tags":[]}},{"id":"d5140dd4","cell_type":"code","source":"# models = {\n#     # \"Linear Regression\": LinearRegression(),\n#     # \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=RANDOM_STATE),\n#     # \"Random Forest Regressor\": RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),\n#     # \"Gradient Boosting Regressor\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=RANDOM_STATE),\n#     \"XGBoost Regressor\": xgb.XGBRegressor(\n#     n_estimators=1000,  # Start with a large number and use early stopping during training\n#     learning_rate=0.05,  # Start with a value in the suggested range (0.01 to 0.05)\n#     max_depth=6,         # Start in the suggested range (4 to 10)\n#     colsample_bytree=0.8, # Start in the suggested range (0.6 to 1.0). Lower if many features.\n#     subsample=0.8,       # Start in the suggested range (0.6 to 1.0)\n#     reg_alpha=0,         # You might want to tune this (e.g., 0 to 5)\n#     reg_lambda=1,        # You might want to tune this (e.g., 0 to 5)\n#     random_state=RANDOM_STATE,\n#     n_jobs=-1\n# ),\n#     \"LightGBM Regressor\": lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=31, random_state=RANDOM_STATE, n_jobs=-1),\n#     \"CatBoost Regressor\": CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=3, random_state=RANDOM_STATE, verbose=0, thread_count=-1)\n# }","metadata":{"execution":{"execution_failed":"2025-05-27T17:20:34.28Z"},"papermill":{"duration":0.015086,"end_time":"2025-05-27T13:12:26.3402","exception":false,"start_time":"2025-05-27T13:12:26.325114","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"2a39e403","cell_type":"markdown","source":"# KFold and Train and Save CSV","metadata":{"papermill":{"duration":0.005969,"end_time":"2025-05-27T13:12:26.352206","exception":false,"start_time":"2025-05-27T13:12:26.346237","status":"completed"},"tags":[]}},{"id":"599ade31","cell_type":"code","source":"# List to store all CV results for comparison table\nall_cv_results = []\n\n# --- Run K-Fold CV for Each Model ---\nfor model_name, model_instance in models.items():\n    print(f\"\\n{'='*80}\\nRunning K-Fold Cross-Validation for: {model_name}\\n{'='*80}\")\n    for n_splits_val in n_splits_list:\n        results = run_kfold_cv(X_train, y_train, model_instance, model_name, n_splits_val, RANDOM_STATE)\n        all_cv_results.append(results)\n    \n    # --- Train on Full X_train and Predict on X_test (after CV for this model) ---\n    print(f\"\\n--- Training {model_name} on full X_train and predicting on X_test ---\")\n    final_model = model_instance.__class__(**model_instance.get_params()) # Create a fresh instance for final training\n    \n    start_time_full_train = time.time()\n    final_model.fit(X_train, y_train)\n    end_time_full_train = time.time()\n    print(f\"Full training complete in {(end_time_full_train - start_time_full_train):.4f} seconds.\")\n\n    start_time_predict = time.time()\n    predictions_test = final_model.predict(X_test)\n    end_time_predict = time.time()\n    print(f\"Predictions made in {(end_time_predict - start_time_predict):.4f} seconds.\")\n\n    # Handle negative predictions for submission file\n    predictions_test[predictions_test < 0] = 0.001 #np.abs(predictions_test)\n    print(predictions_test)\n\n    # Save predictions to CSV\n    submission_df = pd.DataFrame({'id': test_ids, 'Predictions': predictions_test})\n    csv_filename = f'{model_name.replace(\" \", \"_\")}_predictions.csv'\n    submission_df.to_csv(csv_filename, index=False)\n    print(f\"Submission file '{csv_filename}' created successfully.\")\n\n    # Print feature importances if available (for tree-based models)\n    if hasattr(final_model, 'feature_importances_'):\n        print(f\"Feature Importances for {model_name}:\")\n        # Map feature importances to original feature names\n        feature_importances_df = pd.DataFrame({\n            'Feature': X_train.columns,\n            'Importance': final_model.feature_importances_\n        }).sort_values(by='Importance', ascending=False)\n        print(feature_importances_df.to_string(index=False))\n    print(f\"{'-'*80}\") # Separator after each model's full training/prediction","metadata":{"execution":{"execution_failed":"2025-05-27T17:20:34.281Z"},"papermill":{"duration":9085.265923,"end_time":"2025-05-27T15:43:51.624138","exception":false,"start_time":"2025-05-27T13:12:26.358215","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"23e635cc","cell_type":"markdown","source":"# Final Comparison Table","metadata":{"papermill":{"duration":0.1815,"end_time":"2025-05-27T15:43:51.987911","exception":false,"start_time":"2025-05-27T15:43:51.806411","status":"completed"},"tags":[]}},{"id":"2547b03b","cell_type":"code","source":"# Final Comparison Table\nprint(\"\\n\" + \"=\"*120) # Adjusted width for new columns and more models\nprint(\"                                Cross-Validation Summary Across Different Models and Folds                                \")\nprint(\"=\"*120)\n\n# Create a DataFrame from the results for a nice tabular output\nresults_df = pd.DataFrame(all_cv_results)\n\n# Sort for better comparison: by Model, then by N_Splits\nresults_df = results_df.sort_values(by=['Model', 'N_Splits']).reset_index(drop=True)\n\n# Format the numerical columns for better readability\nresults_df['Average RMSLE'] = results_df['Average RMSLE'].map('{:.4f}'.format)\nresults_df['Std RMSLE'] = results_df['Std RMSLE'].map('{:.4f}'.format)\nresults_df['Overall OOF RMSLE'] = results_df['Overall OOF RMSLE'].map('{:.4f}'.format)\nresults_df['Total CV Time (s)'] = results_df['Total CV Time (s)'].map('{:.4f}'.format)\nresults_df['Avg Fold Time (s)'] = results_df['Avg Fold Time (s)'].map('{:.4f}'.format)\n\n# Print the DataFrame\nprint(results_df.to_string(index=False))\nprint(\"=\"*120)\n","metadata":{"execution":{"execution_failed":"2025-05-27T17:20:34.281Z"},"papermill":{"duration":0.198158,"end_time":"2025-05-27T15:43:52.447521","exception":false,"start_time":"2025-05-27T15:43:52.249363","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"23bd8ea7-7b83-42b5-a5c2-943b2a7c0ec3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}