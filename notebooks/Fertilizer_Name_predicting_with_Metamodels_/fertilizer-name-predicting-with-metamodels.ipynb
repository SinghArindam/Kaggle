{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"},{"sourceId":12029694,"sourceType":"datasetVersion","datasetId":7568902},{"sourceId":12072271,"sourceType":"datasetVersion","datasetId":7599197}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:40.430876Z","iopub.execute_input":"2025-06-05T23:27:40.431022Z","iopub.status.idle":"2025-06-05T23:27:40.934829Z","shell.execute_reply.started":"2025-06-05T23:27:40.431008Z","shell.execute_reply":"2025-06-05T23:27:40.934089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nimport optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:40.935523Z","iopub.execute_input":"2025-06-05T23:27:40.935916Z","iopub.status.idle":"2025-06-05T23:27:47.37589Z","shell.execute_reply.started":"2025-06-05T23:27:40.935896Z","shell.execute_reply":"2025-06-05T23:27:47.375252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(r\"/kaggle/input/playground-series-s5e6/train.csv\")\ntest_data = pd.read_csv(r\"/kaggle/input/playground-series-s5e6/test.csv\")\noriginal_data = pd.read_csv(r\"/kaggle/input/fertilizer-data/Fertilizer Prediction.csv\")\ndata = pd.read_csv(r\"/kaggle/input/playground-series-s5e6/sample_submission.csv\")\n\nprint(\"train_data shape :\",train_data.shape)\nprint(\"test_data shape :\",test_data.shape)\nprint(\"original_data shape :\",original_data.shape)\nprint(\"data shape :\",data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:47.377697Z","iopub.execute_input":"2025-06-05T23:27:47.378167Z","iopub.status.idle":"2025-06-05T23:27:48.685798Z","shell.execute_reply.started":"2025-06-05T23:27:47.378152Z","shell.execute_reply":"2025-06-05T23:27:48.685186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:48.688378Z","iopub.execute_input":"2025-06-05T23:27:48.688565Z","iopub.status.idle":"2025-06-05T23:27:48.71003Z","shell.execute_reply.started":"2025-06-05T23:27:48.688551Z","shell.execute_reply":"2025-06-05T23:27:48.709105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.isna().sum().sort_values(ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:48.710689Z","iopub.execute_input":"2025-06-05T23:27:48.710909Z","iopub.status.idle":"2025-06-05T23:27:48.798149Z","shell.execute_reply.started":"2025-06-05T23:27:48.71089Z","shell.execute_reply":"2025-06-05T23:27:48.797457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:48.798787Z","iopub.execute_input":"2025-06-05T23:27:48.798969Z","iopub.status.idle":"2025-06-05T23:27:48.814209Z","shell.execute_reply.started":"2025-06-05T23:27:48.798954Z","shell.execute_reply":"2025-06-05T23:27:48.813603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data.isna().sum().sort_values(ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:48.814886Z","iopub.execute_input":"2025-06-05T23:27:48.815143Z","iopub.status.idle":"2025-06-05T23:27:48.852545Z","shell.execute_reply.started":"2025-06-05T23:27:48.815124Z","shell.execute_reply":"2025-06-05T23:27:48.851924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:48.854078Z","iopub.execute_input":"2025-06-05T23:27:48.854251Z","iopub.status.idle":"2025-06-05T23:27:48.871649Z","shell.execute_reply.started":"2025-06-05T23:27:48.854238Z","shell.execute_reply":"2025-06-05T23:27:48.871036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = train_data.drop(\"id\", axis=1)\ntest_data = test_data.drop(\"id\", axis=1)\ntrain_data = pd.concat([train_data, original_data], ignore_index=True)\ntrain_data = train_data.drop_duplicates()\nprint(\"shape of the data :\",train_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:48.872222Z","iopub.execute_input":"2025-06-05T23:27:48.872389Z","iopub.status.idle":"2025-06-05T23:27:49.208603Z","shell.execute_reply.started":"2025-06-05T23:27:48.872376Z","shell.execute_reply":"2025-06-05T23:27:49.207946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"params = {'booster': 'gbtree', 'lambda': 0.4852532041827346, 'alpha': 5.681002524055748, 'colsample_bytree': 0.40465381192194894, 'subsample': 0.9318477513237314, 'learning_rate': 0.2978528279037068, 'max_depth': 10, 'min_child_weight': 6}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:49.209228Z","iopub.execute_input":"2025-06-05T23:27:49.209448Z","iopub.status.idle":"2025-06-05T23:27:49.213268Z","shell.execute_reply.started":"2025-06-05T23:27:49.209407Z","shell.execute_reply":"2025-06-05T23:27:49.21264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_data.drop(columns=\"Fertilizer Name\")\ny = train_data[\"Fertilizer Name\"]\ntest = test_data.copy()\n# Encode target\ntarget_le = LabelEncoder()\ny_encoded = target_le.fit_transform(y)\nnum_classes = len(np.unique(y_encoded))\n\n# Identify column types\nnum_cols = X.select_dtypes(include='number').columns.tolist()\ncat_cols = X.select_dtypes(include='object').columns.tolist()\n\n# Preprocessor\npreprocessor = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols),\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n])\n\n# MAP@3 metric\ndef map3_score(y_true, y_proba, k=3):\n    top_k = np.argsort(y_proba, axis=1)[:, -k:][:, ::-1]\n    score = 0.0\n    for i in range(len(y_true)):\n        if y_true[i] in top_k[i]:\n            rank = np.where(top_k[i] == y_true[i])[0][0]\n            score += 1 / (rank + 1)\n    return score / len(y_true)\n\n# Optuna hyperparameter tuning for XGB example\ndef optuna_xgb(trial):\n    params = {\n        'objective': 'multi:softprob',\n        'num_class': num_classes,\n        'eval_metric': 'mlogloss',\n        'use_label_encoder': False,\n        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n        'max_depth': trial.suggest_int(\"max_depth\", 3, 10),\n        'subsample': trial.suggest_float(\"subsample\", 0.5, 1.0),\n        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n        'gamma': trial.suggest_float(\"gamma\", 0, 5),\n    }\n    map3_scores = []\n    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n    for train_idx, val_idx in skf.split(X, y_encoded):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n        \n        preprocessor.fit(X_train)\n        X_train_scaled = preprocessor.transform(X_train)\n        X_val_scaled = preprocessor.transform(X_val)\n\n        model = XGBClassifier(**params)\n        model.fit(X_train_scaled, y_train)\n        proba = model.predict_proba(X_val_scaled)\n        map3_scores.append(map3_score(y_val, proba))\n\n    return np.mean(map3_scores)\n\n# Run Optuna study\n#study = optuna.create_study(direction=\"maximize\")\n#study.optimize(optuna_xgb, n_trials=20)\n#print(\"Best MAP@3:\", study.best_value)\n#print(\"Best params:\", study.best_params)\n\n# Use best XGB params in stacking with test predictions\nFOLDS = 5\nkf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\n# Base models with best XGB\nbase_models = {\n    \"xgb\": XGBClassifier(**params, use_label_encoder=False, eval_metric='mlogloss', num_class=num_classes, random_state=42),\n    \"lgb\": LGBMClassifier(objective='multiclass', num_class=num_classes, random_state=42, verbosity=-1),\n    \"rf\": RandomForestClassifier(n_estimators=100, random_state=42),\n    \"gb\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n    \"hgb\": HistGradientBoostingClassifier(random_state=42),\n    \"cat\": CatBoostClassifier(iterations=100, verbose=0, random_seed=42)\n}\n\nmeta_features = np.zeros((len(X), len(base_models) * num_classes))\ntest_preds = np.zeros((len(test), len(base_models) * num_classes))\n\nfor i, (name, model) in enumerate(base_models.items()):\n    print(f\"\\n Training base model: {name}\")\n    oof = np.zeros((len(X), num_classes))\n    test_fold_preds = np.zeros((len(test), num_classes))\n\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y_encoded), 1):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n\n        preprocessor.fit(X_train)\n        X_train_scaled = preprocessor.transform(X_train)\n        X_val_scaled = preprocessor.transform(X_val)\n        test_scaled = preprocessor.transform(test)\n\n        model.fit(X_train_scaled, y_train)\n        oof[val_idx] = model.predict_proba(X_val_scaled)\n        test_fold_preds += model.predict_proba(test_scaled) / FOLDS\n\n    meta_features[:, i * num_classes:(i + 1) * num_classes] = oof\n    test_preds[:, i * num_classes:(i + 1) * num_classes] = test_fold_preds\n\n# Train meta model:\nmeta_model = LogisticRegression(multi_class='multinomial', max_iter=1000)\nmeta_model.fit(meta_features, y_encoded)\n\n# Predict on test\nfinal_test_preds = meta_model.predict_proba(test_preds)\ntop3 = np.argsort(final_test_preds, axis=1)[:, -3:][:, ::-1]\ntop3_labels = target_le.inverse_transform(top3.ravel()).reshape(-1, 3)\n\nsubmission = pd.read_csv(r\"/kaggle/input/playground-series-s5e6-data/sample_submission.csv\")\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission = pd.DataFrame({\n    \"id\": data.id,\n    \"Fertilizer Name\": [\" \".join(row) for row in top3_labels.astype(str)]\n})\n\nsubmission.to_csv(\"stacked_meta_submission.csv\", index=False)\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T23:27:49.213834Z","iopub.execute_input":"2025-06-05T23:27:49.213983Z"}},"outputs":[],"execution_count":null}]}