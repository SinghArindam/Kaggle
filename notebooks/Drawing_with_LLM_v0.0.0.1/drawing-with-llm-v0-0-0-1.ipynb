{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":89659,"databundleVersionId":11522106,"sourceType":"competition"},{"sourceId":10864822,"sourceType":"datasetVersion","datasetId":6749698},{"sourceId":269504,"sourceType":"modelInstanceVersion","modelInstanceId":230133,"modelId":251879},{"sourceId":268942,"sourceType":"modelInstanceVersion","modelInstanceId":230141,"modelId":251887}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/input/kcomfyui/KComfyUI/custom_nodes/GGUF\n!pip install -r requirements.txt\n%cd /kaggle/input/kcomfyui/KComfyUI/custom_nodes/ToSVG\n!pip install -r requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/input/kcomfyui/KComfyUI\n!pip install -r requirements.txt\n!pip install cairosvg","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom nodes import CheckpointLoaderSimple, CLIPTextEncode, KSampler, VAEDecode, SaveImage, EmptyLatentImage, DualCLIPLoader, VAELoader\nfrom custom_nodes.GGUF.nodes import UnetLoaderGGUF\nfrom custom_nodes.ToSVG.svgnode import ConvertRasterToVectorColor\n\nimport cairosvg\nfrom IPython.display import Image ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_loader = UnetLoaderGGUF()\nmodel = checkpoint_loader.load_unet(unet_name='/kaggle/input/flux1-dev-q2_k/pytorch/default/2/flux1-dev-Q2_K.gguf')\n\nclip_loader = DualCLIPLoader()\nclip = clip_loader.load_clip(clip_name1='/kaggle/input/flux1-dev-q2_k/pytorch/default/2/t5xxl_fp8_e4m3fn.safetensors', clip_name2='/kaggle/input/flux1-dev-q2_k/pytorch/default/2/clip_l.safetensors', type='flux')\n\nvae_loader =VAELoader()\nvae = vae_loader.load_vae(vae_name='/kaggle/input/flux1-dev-q2_k/pytorch/default/2/ae.safetensors')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ntrain = pd.read_csv('/kaggle/input/drawing-with-llms/train.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prompt = 'A cute unicorn'\nprompt = train.iloc[12]['description']\nprint(prompt)\n\n# テキストのエンコード\nclip_text_encode = CLIPTextEncode()\npositive_conditioning = clip_text_encode.encode(\n    text=f\"flat vector design of {prompt}, monochromatic, minimal objects, black and white only, clean black background,with continuous single-line drawing as much as possible\",\n    clip=clip[0],\n)\nnegative_conditioning = clip_text_encode.encode(\n    text=\"lurry image, thin line, shadows, blurry edges, messy background\",\n    clip=clip[0],\n)\n\n# 潜在画像の生成\nlatent_encode = EmptyLatentImage()\nlatent_image = latent_encode.generate(width=256, height=256, batch_size=1)\n\n# サンプリング\nk_sampler = KSampler()\nsampled_image = k_sampler.sample(\n    model=model[0],\n    seed=143091209577701,\n    positive=positive_conditioning[0],\n    negative=negative_conditioning[0],\n    latent_image=latent_image[0],\n    steps=6,\n    cfg=1.0,\n    sampler_name=\"euler\",\n    scheduler=\"simple\",\n    denoise=1.0,\n)\n\n# 画像のデコード\nvae_decode = VAEDecode()\ndecoded_image = vae_decode.decode(samples=sampled_image[0], vae=vae[0])\n\n# SVGコンバーター\nsvg_conv = ConvertRasterToVectorColor()\nsvg_output = svg_conv.convert_to_svg(\n    image=decoded_image[0].detach(),\n    hierarchical=\"cutout\",\n    mode=\"polygon\",\n    filter_speckle=4,\n    color_precision=6,\n    layer_difference=16,\n    corner_threshold=60,\n    length_threshold=4,\n    max_iterations=10,\n    splice_threshold=45,\n    path_precision=3,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svg_start = svg_output[0][0].find('<svg')\nsvg = svg_output[0][0][svg_start:]\n\npng_fromstring = cairosvg.svg2png(bytestring=svg)\n\n\nmax_svg_size: int = 10000\nprint(len(svg.encode('utf-8')))\n\nif len(svg.encode('utf-8')) > max_svg_size:\n    print(\"[NG] SVG is too large!\")\nelse:\n    print(\"[OK] SVG is within the limit.\")\n\nImage(png_fromstring)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del model,clip, vae","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModel\nmodel = AutoModel.from_pretrained(\"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\")\nprocessor = AutoProcessor.from_pretrained(\"/kaggle/input/google-siglip-so400m-patch14-384/transformers/default/1\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\ndef svgMetric(prompt, svg):\n    cairosvg.svg2png(svg, write_to=\"/kaggle/working/temp.png\")\n    image = Image.open('/kaggle/working/temp.png').convert(\"RGB\")\n    texts = [\"SVG illustration of \" + prompt]\n    inputs = processor(text=texts, images=image, padding=\"max_length\", return_tensors=\"pt\")\n    with torch.no_grad():\n        outputs = model(**inputs)\n    logits_per_image = outputs.logits_per_image\n    probs = torch.sigmoid(logits_per_image)\n    return probs[0][0].item()\n\n\nprint(prompt)\nprint(\"SCORE: {:.4f}\".format(svgMetric(prompt, svg)))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}