{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10545331,"sourceType":"datasetVersion","datasetId":6524657}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nctr=0\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    if ctr!=0:\n        break\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        ctr+=1\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T06:18:42.574824Z","iopub.execute_input":"2025-01-22T06:18:42.575087Z","iopub.status.idle":"2025-01-22T06:18:42.978459Z","shell.execute_reply.started":"2025-01-22T06:18:42.575064Z","shell.execute_reply":"2025-01-22T06:18:42.977586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Install dependencies","metadata":{}},{"cell_type":"code","source":"!pip install speechbrain matplotlib pandas seaborn pytorch_lightning torchmetrics resampy python_speech_features scikit-learn tensorboard","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T06:18:42.979637Z","iopub.execute_input":"2025-01-22T06:18:42.979969Z","iopub.status.idle":"2025-01-22T06:18:50.915627Z","shell.execute_reply.started":"2025-01-22T06:18:42.979947Z","shell.execute_reply":"2025-01-22T06:18:50.914818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Code","metadata":{}},{"cell_type":"code","source":"import os\n\n# Datasets imports\nimport glob\nimport random\nimport resampy\nfrom scipy.io import wavfile\nfrom scipy.signal import fftconvolve\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import Dataset\nfrom python_speech_features import mfcc\n\n# Plda_classifier imports\nimport pickle\nfrom speechbrain.processing.PLDA_LDA import *\n\n# Plda_score_stat imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nfrom sklearn.manifold import TSNE\nfrom speechbrain.utils.metric_stats import EER, minDCF\n\n# Main imports\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.tensorboard\nimport torchmetrics\nfrom pytorch_lightning import loggers as pl_loggers\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom torch.utils.data import DataLoader\n\n# global variables\nglobal num_worker, log_dir, bse_dir, data_final_path, n_epochs_total, n_batch_size\nbse_dir = \"/kaggle/working/\"\nlog_dir = bse_dir+\"testlogs\"\nnum_worker = 4\ndata_final_path = \"/kaggle/input/audiodataset10percent/\"\nn_epochs_total = 2\nn_batch_size = 512\n\n# Tdnn_layer\nclass TdnnLayer(nn.Module):\n    def __init__(self, input_size=24, output_size=512, context=[0], batch_norm=True, dropout_p=0.0):\n        super(TdnnLayer, self).__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.context = context\n        self.batch_norm = batch_norm\n        self.dropout_p = dropout_p\n        self.linear = nn.Linear(input_size*len(context), output_size)\n        self.relu = nn.ReLU()\n        if(self.batch_norm):\n            self.norm = nn.BatchNorm1d(output_size)\n        if(self.dropout_p):\n            self.drop = nn.Dropout(p=self.dropout_p)\n    def forward(self, x):\n        x_context = get_time_context(x, self.context)\n        x = torch.cat(x_context, 2)\n        x = self.linear(x)\n        x = self.relu(x)\n        if(self.dropout_p):\n            x = self.drop(x)\n        if(self.batch_norm):\n            x = x.transpose(1,2)\n            x = self.norm(x)\n            x = x.transpose(1,2)\n        return x\ndef get_time_context(x, c=[0]):\n    l = len(c) - 1\n    xc =   [x[:, c[l]+cc:c[0]+cc, :]\n            if cc!=c[l] else\n            x[:, c[l]+cc:, :]\n            for cc in c]\n    return xc\n# Plda_classifier\ndef get_train_x_vec(train_xv, train_label, x_id_train):\n    N = train_xv.shape[0]\n    print('N train utt:', N)\n    md = ['id'+str(train_label[i]) for i in range(N)]\n    modelset = np.array(md, dtype=\"|O\")\n    sg = [str(x_id_train[i]) for i in range(N)]\n    segset = np.array(sg, dtype=\"|O\")\n    s = np.array([None] * N)\n    stat0 = np.array([[1.0]]* N)\n    xvectors_stat = StatObject_SB(modelset=modelset, segset=segset, start=s, stop=s, stat0=stat0, stat1=train_xv)\n    return xvectors_stat\ndef setup_plda(mean=None, F=None, Sigma=None, rank_f=150, nb_iter=10, scaling_factor=1):\n    plda = PLDA(mean=mean, F=F, Sigma=Sigma, rank_f=rank_f, nb_iter=nb_iter, scaling_factor=scaling_factor)\n    return plda\ndef train_plda(plda, xvectors_stat):\n    plda.plda(xvectors_stat)\n    return plda\ndef get_x_vec_stat(xv, id):\n    N = xv.shape[0]\n    sgs = [str(id[i]) for i in range(N)]\n    sets = np.array(sgs, dtype=\"|O\")\n    s = np.array([None] * N)\n    stat0 = np.array([[1.0]]* N)\n    xv_stat = StatObject_SB(modelset=sets, segset=sets, start=s, stop=s, stat0=stat0, stat1=xv)\n    return xv_stat\ndef plda_scores(plda, en_stat, te_stat):\n    ndx = Ndx(models=en_stat.modelset, testsegs=te_stat.modelset)\n    fast_plda_scores = fast_PLDA_scoring(en_stat, te_stat, ndx, plda.mean, plda.F, plda.Sigma, p_known=0.0)\n    return fast_plda_scores\ndef save_plda(plda, file_name):\n    try:\n        with open(bse_dir+'plda/'+file_name+'.pickle', 'wb') as f:\n            pickle.dump(plda, f, protocol=pickle.HIGHEST_PROTOCOL)\n    except Exception as ex:\n        print('Error during pickling plda: ', ex)\ndef load_plda(file_path_name):\n    try:\n        with open(file_path_name, 'rb') as f:\n            return pickle.load(f)\n    except Exception as ex:\n        print('Error during pickling plda: ', ex)\ndef lda(x_vec_stat, reduced_dim=2):\n    lda = LDA()\n    new_train_obj = lda.do_lda(x_vec_stat, reduced_dim=reduced_dim)\n    return new_train_obj\n# Plda_score_stat\nclass plda_score_stat_object():\n    def __init__(self, x_vectors_test):\n        self.x_vectors_test = x_vectors_test\n        self.x_id_test = np.array(self.x_vectors_test.iloc[:, 1])\n        self.x_vec_test = np.array([np.array(x_vec[1:-1].split(), dtype=np.float64) for x_vec in self.x_vectors_test.iloc[:, 3]])\n        self.en_stat = get_x_vec_stat(self.x_vec_test, self.x_id_test)\n        self.te_stat = get_x_vec_stat(self.x_vec_test, self.x_id_test)\n        self.plda_scores = 0\n        self.positive_scores = []\n        self.negative_scores = []\n        self.positive_scores_mask = []\n        self.negative_scores_mask = []\n        self.eer = 0\n        self.eer_th = 0\n        self.min_dcf = 0\n        self.min_dcf_th = 0\n        self.checked_xvec = []\n        self.checked_label = []\n    def test_plda(self, plda, veri_test_file_path):\n        self.plda_scores = plda_scores(plda, self.en_stat, self.te_stat)\n        self.positive_scores_mask = np.zeros_like(self.plda_scores.scoremat)\n        self.negative_scores_mask = np.zeros_like(self.plda_scores.scoremat)\n        checked_list = []\n        for pair in open(veri_test_file_path):\n            is_match = bool(int(pair.split(\" \")[0].rstrip().split(\".\")[0].strip()))\n            enrol_id = pair.split(\" \")[1].strip()\n            test_id = pair.split(\" \")[2].strip()\n            i = int(np.where(self.plda_scores.modelset == enrol_id)[0][0])\n            if(not enrol_id in checked_list):\n                checked_list.append(enrol_id)\n                self.checked_xvec.append(np.array(self.x_vectors_test.loc[self.x_vectors_test['id'] == enrol_id, 'xvector'].item()[1:-1].split(), dtype=np.float64))\n                self.checked_label.append(int(enrol_id.split(\".\")[0].split(\"/\")[0][2:]))\n            j = int(np.where(self.plda_scores.segset == test_id)[0][0])\n            if(not test_id in checked_list):\n                checked_list.append(test_id)\n                self.checked_xvec.append(np.array(self.x_vectors_test.loc[self.x_vectors_test['id'] == test_id, 'xvector'].item()[1:-1].split(), dtype=np.float64))\n                self.checked_label.append(int(test_id.split(\".\")[0].split(\"/\")[0][2:]))\n            current_score = float(self.plda_scores.scoremat[i,j])\n            if(is_match):\n                self.positive_scores.append(current_score)\n                self.positive_scores_mask[i,j] = 1\n            else:\n                self.negative_scores.append(current_score)\n                self.negative_scores_mask[i,j] = 1\n        self.checked_xvec = np.array(self.checked_xvec)\n        self.checked_label = np.array(self.checked_label)\n    def calc_eer_mindcf(self):\n        self.eer, self.eer_th = EER(torch.tensor(self.positive_scores), torch.tensor(self.negative_scores))\n        self.min_dcf, self.min_dcf_th = minDCF(torch.tensor(self.positive_scores), torch.tensor(self.negative_scores), p_target=0.5)\n    def plot_images(self, writer):\n        split_xvec = []\n        split_label = []\n        group_kfold = sklearn.model_selection.GroupKFold(n_splits=2)\n        groups1234 = np.where(self.checked_label<10290, 0, 1)\n        for g12, g34 in group_kfold.split(self.checked_xvec, self.checked_label, groups1234):\n            x12, x34 = self.checked_xvec[g12], self.checked_xvec[g34]\n            y12, y34 = self.checked_label[g12], self.checked_label[g34]\n            groups12 = np.where(y12<10280, 0, 1)\n            groups34 = np.where(y34<10300, 0, 1)\n            for g1, g2 in group_kfold.split(x12, y12, groups12):\n                split_xvec.append(x12[g1])\n                split_xvec.append(x12[g2])\n                split_label.append(y12[g1])\n                split_label.append(y12[g2])\n                break\n            for g3, g4 in group_kfold.split(x34, y34, groups34):\n                split_xvec.append(x34[g3])\n                split_xvec.append(x34[g4])\n                split_label.append(y34[g3])\n                split_label.append(y34[g4])\n                break\n            break\n        split_xvec = np.array(split_xvec)\n        split_label = np.array(split_label)\n        print('generating images for tensorboard')\n        scoremat_norm = np.array(self.plda_scores.scoremat)\n        scoremat_norm -= np.min(scoremat_norm)\n        scoremat_norm /= np.max(scoremat_norm)\n        print('score_matrix')\n        img = np.zeros((3, scoremat_norm.shape[0], scoremat_norm.shape[1]))\n        img[0] = np.array([scoremat_norm])\n        img[1] = np.array([scoremat_norm])\n        img[2] = np.array([scoremat_norm])\n        writer.add_image('score_matrix', img, 0)\n        print('ground_truth')\n        img = np.zeros((3, scoremat_norm.shape[0], scoremat_norm.shape[1]))\n        img[1] = np.array([self.positive_scores_mask])\n        img[0] = np.array([self.negative_scores_mask])\n        writer.add_image('ground_truth', img, 0)\n        print('ground_truth_scores')\n        img = np.zeros((3, scoremat_norm.shape[0], scoremat_norm.shape[1]))\n        img[1] = np.array([scoremat_norm*self.positive_scores_mask])\n        img[0] = np.array([scoremat_norm*self.negative_scores_mask])\n        writer.add_image('ground_truth_scores', img, 0)\n        checked_values_map = self.positive_scores_mask + self.negative_scores_mask\n        checked_values = checked_values_map * self.plda_scores.scoremat\n        eer_prediction_positive = np.where(checked_values >= self.eer_th, 1, 0) * checked_values_map\n        eer_prediction_negative = np.where(checked_values < self.eer_th, 1, 0) * checked_values_map\n        min_dcf_prediction_positive = np.where(checked_values >= self.min_dcf_th, 1, 0) * checked_values_map\n        min_dcf_prediction_negative = np.where(checked_values < self.min_dcf_th, 1, 0) * checked_values_map\n        print('prediction_eer_min_dcf')\n        img = np.ones((3, scoremat_norm.shape[0], scoremat_norm.shape[1]*2+5))\n        img[1,:,:checked_values.shape[1]] = eer_prediction_positive\n        img[0,:,:checked_values.shape[1]] = eer_prediction_negative\n        img[1,:,-checked_values.shape[1]:] = min_dcf_prediction_positive\n        img[0,:,-checked_values.shape[1]:] = min_dcf_prediction_negative\n        img[2,:,:checked_values.shape[1]] = 0\n        img[2,:,-checked_values.shape[1]:] = 0\n        writer.add_image('prediction_eer_min_dcf', img, 0)\n        print('correct_prediction_eer_min_dcf')\n        img = np.ones((3, scoremat_norm.shape[0], scoremat_norm.shape[1]*2+5))\n        img[1,:,:checked_values.shape[1]] = eer_prediction_positive * self.positive_scores_mask\n        img[0,:,:checked_values.shape[1]] = eer_prediction_negative * self.negative_scores_mask\n        img[1,:,-checked_values.shape[1]:] = min_dcf_prediction_positive * self.positive_scores_mask\n        img[0,:,-checked_values.shape[1]:] = min_dcf_prediction_negative * self.negative_scores_mask\n        img[2,:,:checked_values.shape[1]] = 0\n        img[2,:,-checked_values.shape[1]:] = 0\n        writer.add_image('correct_prediction_eer_min_dcf', img, 0)\n        print('false_prediction_eer_min_dcf')\n        img = np.ones((3, scoremat_norm.shape[0], scoremat_norm.shape[1]*2+5))\n        img[1,:,:checked_values.shape[1]] = eer_prediction_positive * self.negative_scores_mask\n        img[0,:,:checked_values.shape[1]] = eer_prediction_negative * self.positive_scores_mask\n        img[1,:,-checked_values.shape[1]:] = min_dcf_prediction_positive * self.negative_scores_mask\n        img[0,:,-checked_values.shape[1]:] = min_dcf_prediction_negative * self.positive_scores_mask\n        img[2,:,:checked_values.shape[1]] = 0\n        img[2,:,-checked_values.shape[1]:] = 0\n        writer.add_image('false_prediction_eer_min_dcf', img, 0)\n        def generate_scatter_plot(x, y, label, plot_name):\n            df = pd.DataFrame({'x': x, 'y': y, 'label': label})\n            fig, ax = plt.subplots(1)\n            fig.set_size_inches(16, 12)\n            sns.scatterplot(x='x', y='y', hue='label', palette='bright', data=df, ax=ax, s=80) #use sns.color_palette(\"hls\", 40) for 40 speakers\n            limx = (x.min()-5, x.max()+5)\n            limy = (y.min()-5, y.max()+5)\n            ax.set_xlim(limx)\n            ax.set_ylim(limy)\n            ax.set_aspect(1.0/ax.get_data_ratio(), adjustable='box')\n            ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\n            ax.title.set_text(plot_name)\n        for i, (checked_xvec, checked_label) in enumerate(zip(split_xvec, split_label)):\n            print('scatter_plot_LDA'+str(i+1))\n            new_stat = get_x_vec_stat(checked_xvec, checked_label)\n            new_stat = lda(new_stat)\n            generate_scatter_plot(new_stat.stat1[:, 0], new_stat.stat1[:, 1], checked_label, 'scatter_plot_LDA'+str(i+1))\n            writer.add_figure('scatter_plot_LDA'+str(i+1), plt.gcf())\n            print('scatter_plot_PCA'+str(i+1))\n            pca = sklearn.decomposition.PCA(n_components=2)\n            pca_result = pca.fit_transform(sklearn.preprocessing.StandardScaler().fit_transform(checked_xvec))\n            generate_scatter_plot(pca_result[:,0], pca_result[:,1], checked_label, 'scatter_plot_PCA'+str(i+1))\n            writer.add_figure('scatter_plot_PCA'+str(i+1), plt.gcf())\n            print('scatter_plot_TSNE'+str(i+1))\n            tsne = TSNE(2)\n            tsne_result = tsne.fit_transform(checked_xvec)\n            generate_scatter_plot(tsne_result[:,0], tsne_result[:,1], checked_label, 'scatter_plot_TSNE'+str(i+1))\n            writer.add_figure('scatter_plot_TSNE'+str(i+1), plt.gcf())\n# Dataset\nEPS = 1e-20\nclass Dataset(Dataset):\n    def __init__(self,\n                sampling_rate=16000,\n                mfcc_numcep=24,\n                mfcc_nfilt=26,\n                mfcc_nfft=512,\n                data_folder_path='data',\n                augmentations_per_sample=2):\n        self.samples = []\n        self.labels = []\n        self.n_samples = 0\n        self.unique_labels = []\n        self.train_samples = []\n        self.train_labels = []\n        self.val_samples = []\n        self.val_labels = []\n        self.test_samples = []\n        self.test_labels = []\n        self.data_folder_path = data_folder_path\n        self.sampling_rate = sampling_rate\n        self.augmentations_per_sample = augmentations_per_sample\n        self.mfcc_numcep = mfcc_numcep\n        self.mfcc_nfilt = mfcc_nfilt\n        self.mfcc_nfft = mfcc_nfft\n\n    def init_samples_and_labels(self):\n        vox_train_path = self.data_folder_path + '/VoxCeleb/vox1_dev_wav/*/*/*.wav'\n        vox_test_path = self.data_folder_path + '/VoxCeleb/vox1_test_wav/*/*/*.wav'\n        globs = glob.glob(vox_train_path)\n        print('collectiong training and validation samples')\n        samples = [(sample, 'none') for sample in globs]\n        labels = [os.path.basename(os.path.dirname(os.path.dirname(f))) for f in globs]\n        for i in range(self.augmentations_per_sample):\n            samples = samples + [(sample, random.choice(['music', 'speech', 'noise', 'rir'])) for sample in globs]\n            labels = labels + [os.path.basename(os.path.dirname(os.path.dirname(f))) for f in globs]\n        unique_labels = np.unique(labels)\n        print('found:')\n        print(len(unique_labels), ' unique speakers')\n        print(int(len(samples)/(self.augmentations_per_sample+1)), ' voice samples')\n        print(len(samples), ' total voice samples including augmentations')\n        print('splitting into 90% training and 10% validation')\n        skf = StratifiedKFold(n_splits=10, shuffle=True)\n        train_index, val_index = [], []\n        for traini, vali in skf.split(samples, labels):\n            if(len(vali) == int(round(len(samples)/10))):\n                train_index = traini\n                val_index = vali\n        if(len(train_index) <= 1):\n            print('StratifiedKFold Failed')\n        self.train_samples = list(np.array(samples)[train_index])\n        self.train_labels = list(np.array(labels)[train_index])\n        self.val_samples = list(np.array(samples)[val_index])\n        self.val_labels = list(np.array(labels)[val_index])\n        globs = glob.glob(vox_test_path)\n        print('collectiong test samples')\n        test_samples = [(sample, 'none') for sample in globs]\n        test_labels = [os.path.basename(os.path.dirname(os.path.dirname(f))) for f in globs]\n        unique_labels = np.unique(test_labels)\n        print('found:')\n        print(len(unique_labels), ' unique speakers')\n        print(len(test_samples), ' voice samples')\n        print('DONE collectiong samples')\n        self.test_samples = list(np.array(test_samples))\n        self.test_labels = list(np.array(test_labels))\n    def __getitem__(self, index):\n        sample_path, augmentation = self.samples[index]\n        rate, sample = wavfile.read(sample_path, np.dtype)\n        sample = resampy.resample(sample, rate, self.sampling_rate)\n        augmented_sample = self.augment_data(sample, augmentation)\n        augmented_sample = mfcc(augmented_sample, self.sampling_rate, numcep=self.mfcc_numcep, nfilt=self.mfcc_nfilt, nfft=self.mfcc_nfft)\n        label = self.unique_labels.index(self.labels[index])\n        id = '/'.join(sample_path.rsplit('/')[-3:])\n        return torch.from_numpy(augmented_sample), label, id\n    def __len__(self):\n        return self.n_samples\n    def load_data(self, train=False, val=False, test=False):\n        self.samples = []\n        self.labels = []\n        self.n_samples = 0\n        self.unique_labels = []\n        if(train):\n            self.samples = self.samples + self.train_samples\n            self.labels = self.labels + self.train_labels\n        if(val):\n            self.samples = self.samples + self.val_samples\n            self.labels = self.labels + self.val_labels\n        if(test):\n            self.samples = self.samples + self.test_samples\n            self.labels = self.labels + self.test_labels\n        self.n_samples = len(self.samples)\n        self.unique_labels = list(np.unique(self.labels))\n    def augment_data(self, sample, augmentation):\n        sample = self.cut_to_sec(sample, 3)\n        if(augmentation == 'music'):\n            aug_sample = self.augment_musan_music(sample)\n        elif(augmentation == 'speech'):\n            aug_sample = self.augment_musan_speech(sample)\n        elif(augmentation == 'noise'):\n            aug_sample = self.augment_musan_noise(sample)\n        elif(augmentation == 'rir'):\n            aug_sample = self.augment_rir(sample)\n        else:\n            aug_sample = sample\n        aug_sample = aug_sample.astype(np.float64)\n        aug_sample -= np.min(aug_sample)\n        aug_sample /= np.max(aug_sample)\n        return aug_sample\n    def cut_to_sec(self, sample, length):\n        if(len(sample) < self.sampling_rate*length):\n            new_sample = np.pad(sample, (0, self.sampling_rate*length-len(sample)), 'constant', constant_values=(0, 0))\n        else:\n            start_point = random.randint(0, len(sample) - self.sampling_rate*length)\n            new_sample = sample[start_point:start_point + self.sampling_rate*length]\n        return new_sample\n    def add_with_certain_snr(self, sample, noise, min_snr_db=5, max_snr_db=20):\n        sample = sample.astype('int64')\n        noise = noise.astype('int64')\n        sample_rms = np.sqrt(np.mean(sample**2))\n        noise_rms = np.sqrt(np.mean(noise**2))\n        wanted_snr = random.randint(min_snr_db, max_snr_db)\n        wanted_noise_rms = np.sqrt(sample_rms**2 / 10**(wanted_snr/10))\n        new_noise = noise * wanted_noise_rms/(noise_rms+EPS)\n        noisy_sample = sample + new_noise\n        return noisy_sample\n    def augment_musan_music(self, sample):\n        musan_music_path = self.data_folder_path + '/musan/music/*/*.wav'\n        song_path = random.choice(glob.glob(musan_music_path))\n        rate, song = wavfile.read(song_path, np.dtype)\n        song = resampy.resample(song, rate, self.sampling_rate)\n        song = self.cut_to_sec(song, 3)\n        aug_sample = self.add_with_certain_snr(sample, song, min_snr_db=5, max_snr_db=15)\n        return aug_sample\n    def augment_musan_speech(self, sample):\n        musan_speech_path = self.data_folder_path + '/musan/speech/*/*.wav'\n        speaker_path = random.choice(glob.glob(musan_speech_path))\n        rate, speakers = wavfile.read(speaker_path, np.dtype)\n        speakers = resampy.resample(speakers, rate, self.sampling_rate)\n        speakers = self.cut_to_sec(speakers, 3)\n        for i in range(random.randint(2, 6)):\n            speaker_path = random.choice(glob.glob(musan_speech_path))\n            rate, speaker = wavfile.read(speaker_path, np.dtype)\n            speaker = resampy.resample(speaker, rate, self.sampling_rate)\n            speaker = self.cut_to_sec(speaker, 3)\n            speakers = speakers + speaker\n        aug_sample = self.add_with_certain_snr(sample, speakers, min_snr_db=13, max_snr_db=20)\n        return aug_sample\n    def augment_musan_noise(self, sample):\n        musan_noise_path = self.data_folder_path + '/musan/noise/*/*.wav'\n        for i in range(3):\n            noise_path = random.choice(glob.glob(musan_noise_path))\n            rate, noise = wavfile.read(noise_path, np.dtype)\n            noise = resampy.resample(noise, rate, self.sampling_rate)\n            noise = self.cut_to_sec(noise, 1)\n            sample[i:i+self.sampling_rate] = self.add_with_certain_snr(sample[i:i+self.sampling_rate], noise, min_snr_db=0, max_snr_db=15)\n        return sample\n    def augment_rir(self, sample):\n        rir_noise_path = self.data_folder_path + '/RIRS_NOISES/simulated_rirs/*/*/*.wav'\n        rir_path = random.choice(glob.glob(rir_noise_path))\n        _, rir = wavfile.read(rir_path, np.dtype)\n        aug_sample = fftconvolve(sample, rir)\n        aug_sample = aug_sample / abs(aug_sample).max()\n        sample_max = abs(sample).max()\n        aug_max = abs(aug_sample).max()\n        aug_sample = aug_sample * (sample_max/aug_max)\n        aug_sample = sample + aug_sample[:len(sample)]\n        return aug_sample\nclass Config:\n    def __init__(self,\n                batch_size=n_batch_size,\n                input_size=24,\n                hidden_size=512,\n                num_classes=1211,\n                x_vector_size=512,\n                x_vec_extract_layer=6,\n                learning_rate=0.001,\n                num_epochs=n_epochs_total,\n                batch_norm=True,\n                dropout_p=0.0,\n                augmentations_per_sample=2,\n                plda_rank_f=50,\n                checkpoint_path='none',\n                data_folder_path='data',\n                train_x_vector_model=True,\n                extract_x_vectors=True,\n                train_plda=True,\n                test_plda=True):\n        self.batch_size = batch_size\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_classes = num_classes\n        self.x_vector_size = x_vector_size\n        self.x_vec_extract_layer = x_vec_extract_layer\n        self.learning_rate = learning_rate\n        self.num_epochs = num_epochs\n        self.batch_norm = batch_norm\n        self.dropout_p = dropout_p\n        self.augmentations_per_sample = augmentations_per_sample\n        self.plda_rank_f = plda_rank_f\n        self.checkpoint_path = checkpoint_path\n        self.data_folder_path = data_folder_path\n        self.train_x_vector_model = train_x_vector_model\n        self.extract_x_vectors = extract_x_vectors\n        self.train_plda = train_plda\n        self.test_plda = test_plda\nclass XVectorModel(pl.LightningModule):\n    def __init__(self, input_size=24,\n                hidden_size=512,\n                num_classes=1211,\n                x_vector_size=512,\n                x_vec_extract_layer=6,\n                batch_size=512,\n                learning_rate=0.001,\n                batch_norm=True,\n                dropout_p=0.0,\n                augmentations_per_sample=2,\n                data_folder_path='data'):\n        super().__init__()\n        self.time_context_layers = nn.Sequential(\n            TdnnLayer(input_size=input_size, output_size=hidden_size, context=[-2, -1, 0, 1, 2], batch_norm=batch_norm, dropout_p=dropout_p),\n            TdnnLayer(input_size=hidden_size, output_size=hidden_size, context=[-2, 0, 2], batch_norm=batch_norm, dropout_p=dropout_p),\n            TdnnLayer(input_size=hidden_size, output_size=hidden_size, context=[-3, 0, 3], batch_norm=batch_norm, dropout_p=dropout_p),\n            TdnnLayer(input_size=hidden_size, output_size=hidden_size, batch_norm=batch_norm, dropout_p=dropout_p),\n            TdnnLayer(input_size=hidden_size, output_size=1500, batch_norm=batch_norm, dropout_p=dropout_p)\n        )\n        self.segment_layer6 = nn.Linear(3000, x_vector_size)\n        self.segment_layer7 = nn.Linear(x_vector_size, x_vector_size)\n        self.output = nn.Linear(x_vector_size, num_classes)\n        self.x_vec_extract_layer = x_vec_extract_layer\n        self.batch_size = batch_size\n        self.learning_rate = learning_rate\n        self.dataset = Dataset(data_folder_path=data_folder_path, augmentations_per_sample=augmentations_per_sample)\n        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        self.save_hyperparameters()\n    def stat_pool(self, x):\n        mean = torch.mean(x, 1)\n        stand_dev = torch.std(x, 1)\n        out = torch.cat((mean, stand_dev), 1)\n        return out\n    def forward(self, x):\n        out = self.time_context_layers(x)\n        out = self.stat_pool(out)\n        out = F.relu(self.segment_layer6(out))\n        out = F.relu(self.segment_layer7(out))\n        out = self.output(out)\n        return out\n    def extract_x_vec(self, x):\n        out = self.time_context_layers.forward(x)\n        out = self.stat_pool(out)\n        if(self.x_vec_extract_layer == 6):\n            x_vec = self.segment_layer6.forward(out)\n        elif(self.x_vec_extract_layer == 7):\n            out = F.relu(self.segment_layer6.forward(out))\n            x_vec = self.segment_layer7.forward(out)\n        else:\n            x_vec = self.segment_layer6.forward(out)\n        return x_vec\n    def training_step(self, batch, batch_index):\n        samples, labels, id = batch\n        outputs = self(samples.float())\n        loss = F.cross_entropy(outputs, labels)\n        return {'loss': loss, 'train_preds': outputs, 'train_labels': labels, 'train_id': id}\n    def training_step_end(self, outputs):\n        self.log('train_step_loss', outputs['loss'])\n        accuracy = self.accuracy(outputs['train_preds'], outputs['train_labels'])\n        self.log('train_step_acc', self.accuracy)\n        return {'loss': outputs['loss'], 'acc': accuracy}\n    def on_fit_start(self):\n        sample_input = torch.rand((1, 299, 24)).to(self.device)\n        self.logger.experiment.add_graph(self, sample_input)\n    def on_train_epoch_end(self):\n        print(f\"Epoch {self.current_epoch} ended. Skipping add_graph to avoid Trainer attachment issues.\")\n    def validation_step(self, batch, batch_index):\n      samples, labels, _ = batch\n      outputs = self(samples.float())\n      loss = F.cross_entropy(outputs, labels)\n      self.log(\"val_step_loss\", loss, prog_bar=True)  # Log the metric for early stopping\n      return {\"val_loss\": loss}\n    def validation_step_end(self, outputs):\n      accuracy = self.accuracy(outputs[\"val_preds\"], outputs[\"val_labels\"])\n      self.log(\"val_step_acc\", accuracy, prog_bar=True)\n    def test_step(self, batch, batch_index):\n        samples, labels, id = batch\n        x_vecs = self.extract_x_vec(samples.float())\n        return [(x_vecs, labels, id)]\n    def test_epoch_end(self, test_step_outputs):\n        for batch_output in test_step_outputs:\n            for x_vec, label, id in batch_output:\n                for x, l, i in zip(x_vec, label, id):\n                    x_vector.append((i, int(l.cpu().numpy()), np.array(x.cpu().numpy(), dtype=np.float64)))\n        return test_step_outputs\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n    def train_dataloader(self):\n        self.dataset.load_data(train=True)\n        train_data_loader = DataLoader(dataset=self.dataset, batch_size=self.batch_size, num_workers=num_worker, shuffle=True)\n        return train_data_loader\n    def val_dataloader(self):\n        self.dataset.load_data(val=True)\n        val_data_loader = DataLoader(dataset=self.dataset, batch_size=self.batch_size, num_workers=num_worker, shuffle=False)\n        return val_data_loader\n    def test_dataloader(self):\n        if(extract_mode == 'train'):\n            self.dataset.load_data(train=True, val=True)\n            test_data_loader = DataLoader(dataset=self.dataset, batch_size=self.batch_size, num_workers=num_worker, shuffle=False)\n        if(extract_mode == 'test'):\n            self.dataset.load_data(test=True)\n            test_data_loader = DataLoader(dataset=self.dataset, batch_size=self.batch_size, num_workers=num_worker, shuffle=False)\n        return test_data_loader\n\n\n# Main execution\nif __name__ == \"__main__\":\n    print('setting up model and trainer parameters')\n    ppth = f'{log_dir}/lightning_logs/version_7/checkpoints/last.ckpt'\n    ckpt_path = ppth if os.path.exists(f'{log_dir}/lightning_logs/version_7/checkpoints/last.ckpt') else 'none'\n    sep1=\"::::::::\\\\::::::::\"\n    print(sep1,ckpt_path,sep1)\n    config = Config(data_folder_path=data_final_path,\n                    checkpoint_path='none',#ppth,\n                    train_x_vector_model = True,\n                    extract_x_vectors = False,\n                    train_plda = False,\n                    test_plda = False,\n                    x_vec_extract_layer=6,\n                    plda_rank_f=25)#TODO delete most of this\n    # Define model and trainer\n    tb_logger = pl_loggers.TensorBoardLogger(save_dir=log_dir)\n    early_stopping_callback = EarlyStopping(monitor=\"val_step_loss\", mode=\"min\")\n    checkpoint_callback = ModelCheckpoint(monitor='val_step_loss', save_top_k=10, save_last=True, verbose=True)\n    if(config.checkpoint_path == 'none'):\n        model = XVectorModel(input_size=config.input_size,\n                            hidden_size=config.hidden_size,\n                            num_classes=config.num_classes,\n                            x_vector_size=config.x_vector_size,\n                            x_vec_extract_layer=config.x_vec_extract_layer,\n                            batch_size=config.batch_size,\n                            learning_rate=config.learning_rate,\n                            batch_norm=config.batch_norm,\n                            dropout_p=config.dropout_p,\n                            augmentations_per_sample=config.augmentations_per_sample,\n                            data_folder_path=config.data_folder_path)\n    else:\n        model = XVectorModel.load_from_checkpoint(config.checkpoint_path)\n    model.dataset.init_samples_and_labels()\n    trainer = pl.Trainer(callbacks=[early_stopping_callback, checkpoint_callback],\n                        logger=tb_logger,\n                        log_every_n_steps=1,\n                        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n                        max_epochs=config.num_epochs)\n    # Train the x-vector model\n    if(config.train_x_vector_model):\n        print('training x-vector model')\n        if(config.checkpoint_path == 'none'):\n            trainer.fit(model)\n        else:\n            trainer.fit(model, ckpt_path=config.checkpoint_path)\n    # Extract the x-vectors\n    if(config.extract_x_vectors):\n        print('extracting x-vectors')\n        if not os.path.exists('x_vectors'):\n            os.makedirs('x_vectors')\n        # Extract the x-vectors for trainng the PLDA classifier and save to csv\n        x_vector = []\n        extract_mode = 'train'\n        if(config.train_x_vector_model):\n            trainer.test(model)\n            x_vector = pd.DataFrame(x_vector)\n            x_vector.to_csv('x_vectors/x_vector_train_v1_5_l7relu.csv')#TODO set to default name\n        elif(config.checkpoint_path != 'none'):\n            trainer.test(model, ckpt_path=config.checkpoint_path)\n            x_vector = pd.DataFrame(x_vector)\n            x_vector.to_csv('x_vectors/x_vector_train_v1_5_l7relu.csv')#TODO set to default name\n        else:\n            print('could not extract train x-vectors')\n        # Extract the x-vectors for testing the PLDA classifier and save to csv\n        x_vector = []\n        extract_mode = 'test'\n        if(config.train_x_vector_model):\n            trainer.test(model)\n            x_vector = pd.DataFrame(x_vector)\n            x_vector.to_csv(bse_dir+'x_vectors/x_vector_test_v1_5_l7relu.csv')#TODO set to default name\n        elif(config.checkpoint_path != 'none'):\n            trainer.test(model, ckpt_path=config.checkpoint_path)\n            x_vector = pd.DataFrame(x_vector)\n            x_vector.to_csv(bse_dir+'x_vectors/x_vector_test_v1_5_l7relu.csv')#TODO set to default name\n        else:\n            print('could not extract test x-vectors')\n    if(config.train_plda):\n        print('loading x_vector data')\n        if not os.path.exists('plda'):\n            os.makedirs('plda')\n        # Extract the x-vectors, labels and id from the csv\n        x_vectors_train = pd.read_csv(bse_dir+'x_vectors/i_vector_train_v2.csv')#TODO set to default name\n        x_id_train = np.array(x_vectors_train.iloc[:, 1])\n        x_label_train = np.array(x_vectors_train.iloc[:, 2], dtype=int)\n        x_vec_train = np.array([np.array(x_vec[1:-1].split(), dtype=np.float64) for x_vec in x_vectors_train.iloc[:, 3]])\n        # Generate x_vec stat objects\n        print('generating x_vec stat objects')\n        tr_stat = get_train_x_vec(x_vec_train, x_label_train, x_id_train)\n        # Train plda\n        print('training plda')\n        plda = setup_plda(rank_f=50, nb_iter=10)\n        plda = train_plda(plda, tr_stat)\n        save_plda(plda, 'plda_ivec_v2_d50')\n        # Train plda\n        print('training plda')\n        plda = setup_plda(rank_f=100, nb_iter=10)\n        plda = train_plda(plda, tr_stat)\n        save_plda(plda, 'plda_ivec_v2_d100')\n        # Train plda\n        print('training plda')\n        plda = setup_plda(rank_f=150, nb_iter=10)\n        plda = train_plda(plda, tr_stat)\n        save_plda(plda, 'plda_ivec_v2_d150')\n        # Train plda\n        print('training plda')\n        plda = setup_plda(rank_f=200, nb_iter=10)\n        plda = train_plda(plda, tr_stat)\n        save_plda(plda, 'plda_ivec_v2_d200')\n    if(config.test_plda):\n        # Extract the x-vectors, labels and id from the csv\n        print('loading x_vector data')\n        x_vectors_test = pd.read_csv(bse_dir+'x_vectors/i_vector_test_v2.csv')#TODO set to default name\n        x_vectors_test.columns = ['index', 'id', 'label', 'xvector']\n        score = plda_score_stat_object(x_vectors_test)\n        # Test plda\n        print('testing plda')\n        if(not config.train_plda):\n            plda = load_plda(bse_dir+'plda/plda_ivec_v2_d200.pickle')#TODO set to default name\n        score.test_plda(plda, config.data_folder_path + '/VoxCeleb/veri_test2.txt')\n        # Calculate EER and minDCF\n        print('calculating EER and minDCF')\n        score.calc_eer_mindcf()\n        print('EER: ', score.eer, '   threshold: ', score.eer_th)\n        print('minDCF: ', score.min_dcf, '   threshold: ', score.min_dcf_th)\n        # Generate images for tensorboard\n        score.plot_images(tb_logger.experiment)\n        save_plda(score, 'plda_score_ivec_v2_d200')#TODO set to default name\n    print('DONE')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T06:18:50.917804Z","iopub.execute_input":"2025-01-22T06:18:50.918057Z","iopub.status.idle":"2025-01-22T06:23:24.981417Z","shell.execute_reply.started":"2025-01-22T06:18:50.918035Z","shell.execute_reply":"2025-01-22T06:23:24.979324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# End","metadata":{}}]}