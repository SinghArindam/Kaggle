{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"},{"sourceId":6749586,"sourceType":"datasetVersion","datasetId":3886057}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install efficientnet_pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T07:26:21.477814Z","iopub.execute_input":"2025-04-24T07:26:21.478496Z","iopub.status.idle":"2025-04-24T07:26:21.482265Z","shell.execute_reply.started":"2025-04-24T07:26:21.478468Z","shell.execute_reply":"2025-04-24T07:26:21.481355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import librosa\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import EfficientNet\nfrom torch.utils.data import Dataset, DataLoader\nfrom audiomentations import Compose, AddBackgroundNoise, TimeMask, FrequencyMask\nfrom multiprocessing import Pool\nimport os\n\n# Constants\nSR = 32000\nN_MELS = 128\nHOP_LENGTH = 512\nNUM_CLASSES = 182  # Adjust based on BirdCLEF 2025 species count\nBATCH_SIZE = 32\nEPOCHS = 10\n\n# Data Preprocessing\ndef audio_to_mel_spectrogram(audio_path, sr=SR, n_mels=N_MELS, hop_length=HOP_LENGTH):\n    y, _ = librosa.load(audio_path, sr=sr)\n    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n    S_dB = librosa.power_to_db(S, ref=np.max)\n    return S_dB\n\nNOISE_PATH = \"/kaggle/input/audio-noise-dataset\"\n\n# Data Augmentation\naugment = Compose([\n    AddBackgroundNoise(sounds_path=NOISE_PATH, min_snr=0.0, max_snr=2.0, p=0.5),\n    TimeMask(min_band_part=0.0, max_band_part=0.2, p=0.5),\n    FrequencyMask(min_frequency_band=0.0, max_frequency_band=0.2, p=0.5),\n])\n\n# Custom Dataset\nclass BirdCLEFDataset(Dataset):\n    def __init__(self, audio_paths, labels=None, augment=None):\n        self.audio_paths = audio_paths\n        self.labels = labels\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.audio_paths)\n\n    def __getitem__(self, idx):\n        spec = audio_to_mel_spectrogram(self.audio_paths[idx])\n        if self.augment and self.labels is not None:\n            spec = self.augment(samples=spec, sample_rate=SR)\n        spec = torch.tensor(spec, dtype=torch.float32).unsqueeze(0)  # Add channel dim\n        if self.labels is not None:\n            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n            return spec, label\n        return spec\n\n# Weighted Loss Function\nclass WeightedBCELoss(nn.Module):\n    def __init__(self, weight):\n        super(WeightedBCELoss, self).__init__()\n        self.weight = weight\n\n    def forward(self, input, target):\n        return nn.functional.binary_cross_entropy_with_logits(input, target, pos_weight=self.weight)\n\n# Model Setup\ndef get_model(num_classes=NUM_CLASSES):\n    model = EfficientNet.from_pretrained('efficientnet-b0')\n    model._fc = nn.Linear(model._fc.in_features, num_classes)\n    return model\n\n# Training Loop\ndef train_model(model, train_loader, device, optimizer, criterion, epochs=EPOCHS):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n\n# Inference\ndef predict(model, test_loader, device):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for inputs in test_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            preds = torch.sigmoid(outputs).cpu().numpy()\n            predictions.extend(preds)\n    return np.array(predictions)\n\n# Parallel Spectrogram Computation\ndef compute_spectrogram(audio_path):\n    return audio_to_mel_spectrogram(audio_path)\n\ndef preprocess_in_parallel(audio_paths, num_workers=4):\n    with Pool(processes=num_workers) as pool:\n        spectrograms = pool.map(compute_spectrogram, audio_paths)\n    return spectrograms\n\n# Main Execution\ndef main():\n    # Example paths and labels (replace with actual data)\n    train_audio_paths = [\"path/to/train/audio1.wav\", \"path/to/train/audio2.wav\"]\n    train_labels = np.random.randint(0, 2, (len(train_audio_paths), NUM_CLASSES))  # Dummy labels\n    test_audio_paths = [\"path/to/test/audio1.wav\", \"path/to/test/audio2.wav\"]\n\n    # Datasets and Loaders\n    train_dataset = BirdCLEFDataset(train_audio_paths, train_labels, augment=augment)\n    test_dataset = BirdCLEFDataset(test_audio_paths)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    # Model, Optimizer, Loss\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = get_model().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    class_weights = torch.tensor([1.0] * NUM_CLASSES).to(device)  # Adjust weights as needed\n    criterion = WeightedBCELoss(weight=class_weights)\n\n    # Train\n    train_model(model, train_loader, device, optimizer, criterion)\n\n    # Predict\n    predictions = predict(model, test_loader, device)\n    print(\"Predictions:\", predictions)\n\n    # Save model to ONNX (optional)\n    dummy_input = torch.randn(1, 1, N_MELS, 313).to(device)  # Adjust shape as needed\n    torch.onnx.export(model, dummy_input, \"birdclef_model.onnx\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T07:26:21.489628Z","iopub.execute_input":"2025-04-24T07:26:21.489975Z","iopub.status.idle":"2025-04-24T07:26:21.516177Z","shell.execute_reply.started":"2025-04-24T07:26:21.489952Z","shell.execute_reply":"2025-04-24T07:26:21.514944Z"}},"outputs":[],"execution_count":null}]}