{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":34877,"sourceType":"datasetVersion","datasetId":27352}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:41.745422Z","iopub.execute_input":"2025-03-20T04:13:41.745677Z","iopub.status.idle":"2025-03-20T04:13:42.658325Z","shell.execute_reply.started":"2025-03-20T04:13:41.745647Z","shell.execute_reply":"2025-03-20T04:13:42.65744Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Initial Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:42.659578Z","iopub.execute_input":"2025-03-20T04:13:42.659955Z","iopub.status.idle":"2025-03-20T04:13:42.6642Z","shell.execute_reply.started":"2025-03-20T04:13:42.659932Z","shell.execute_reply":"2025-03-20T04:13:42.663246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for imaage and data split\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nimport math\nimport copy\nimport time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:42.666007Z","iopub.execute_input":"2025-03-20T04:13:42.666295Z","iopub.status.idle":"2025-03-20T04:13:43.864565Z","shell.execute_reply.started":"2025-03-20T04:13:42.666267Z","shell.execute_reply":"2025-03-20T04:13:43.863636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision.utils import make_grid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:43.867584Z","iopub.execute_input":"2025-03-20T04:13:43.868029Z","iopub.status.idle":"2025-03-20T04:13:49.914817Z","shell.execute_reply.started":"2025-03-20T04:13:43.868003Z","shell.execute_reply":"2025-03-20T04:13:49.914092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#neural net imports\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:49.915552Z","iopub.execute_input":"2025-03-20T04:13:49.915925Z","iopub.status.idle":"2025-03-20T04:13:49.919777Z","shell.execute_reply.started":"2025-03-20T04:13:49.915903Z","shell.execute_reply":"2025-03-20T04:13:49.918955Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## pytorch Version","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:49.92073Z","iopub.execute_input":"2025-03-20T04:13:49.920946Z","iopub.status.idle":"2025-03-20T04:13:49.938995Z","shell.execute_reply.started":"2025-03-20T04:13:49.920928Z","shell.execute_reply":"2025-03-20T04:13:49.938168Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"# # Load the data\n# train_df = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_train.csv\")\n# test_df = pd.read_csv(\"/kaggle/input/mnist-in-csv/mnist_test.csv\")\n\n# y = train_df[\"label\"]\n# x = train_df.drop(\"label\", axis = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:49.939661Z","iopub.execute_input":"2025-03-20T04:13:49.939912Z","iopub.status.idle":"2025-03-20T04:13:54.649265Z","shell.execute_reply.started":"2025-03-20T04:13:49.939892Z","shell.execute_reply":"2025-03-20T04:13:54.648253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the data\ntrain_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n\ny = train_df[\"label\"]\nx = train_df.drop(\"label\", axis = 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Dataset head","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:54.651661Z","iopub.execute_input":"2025-03-20T04:13:54.651925Z","iopub.status.idle":"2025-03-20T04:13:54.677056Z","shell.execute_reply.started":"2025-03-20T04:13:54.651906Z","shell.execute_reply":"2025-03-20T04:13:54.67637Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Split - Train Val Test","metadata":{}},{"cell_type":"code","source":"#Split training data into Train and validation set\nX_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:54.678112Z","iopub.execute_input":"2025-03-20T04:13:54.678368Z","iopub.status.idle":"2025-03-20T04:13:54.970597Z","shell.execute_reply.started":"2025-03-20T04:13:54.678349Z","shell.execute_reply":"2025-03-20T04:13:54.969684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\nrandom_seed = 42\ntorch.backends.cudnn.enabled = False\ntorch.manual_seed(random_seed)\n\nnum_epoch = 25\nbatch_size_train = 32\nbatch_size_test = 32\nlearning_rate = 0.002\nmomentum = 0.9\nlog_interval = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:54.971553Z","iopub.execute_input":"2025-03-20T04:13:54.971896Z","iopub.status.idle":"2025-03-20T04:13:54.980508Z","shell.execute_reply.started":"2025-03-20T04:13:54.971873Z","shell.execute_reply":"2025-03-20T04:13:54.97977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset Processing","metadata":{}},{"cell_type":"code","source":"#CustomDatasetFromDF\nclass MNISTDataset(Dataset):\n    def __init__(self,  data, target, train=True, transform=None):\n        \"\"\"\n        Args:\n            csv_path (string): path to csv file\n            transform: pytorch transforms for transforms and tensor conversion\n        \"\"\"\n        self.train = train\n        if self.train :\n            self.data = data\n            self.labels = np.asarray(target.iloc[:])\n        else:\n            self.data = data\n            self.labels = None\n        self.height = 28 # Height of image\n        self.width = 28 # Width of image\n        self.transform = transform\n\n    def __getitem__(self, index):\n        # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28])\n        img_as_np = np.asarray(self.data.iloc[index][0:]).reshape(self.height, self.width).astype('uint8')\n        # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n        img_as_img = Image.fromarray(img_as_np)\n        img_as_img = img_as_img.convert('L')\n        img_as_tensor = img_as_img\n        \n        if self.train:\n            single_image_label = self.labels[index]\n        else:\n            single_image_label = None\n            \n        # Transform image to tensor\n        if self.transform is not None:\n            img_as_tensor = self.transform(img_as_img)\n        \n        if self.train:\n        # Return image and the label                \n            return (img_as_tensor, single_image_label)\n        else:\n            return img_as_tensor\n    \n    def __len__(self):\n        return len(self.data.index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:54.981323Z","iopub.execute_input":"2025-03-20T04:13:54.981618Z","iopub.status.idle":"2025-03-20T04:13:54.988782Z","shell.execute_reply.started":"2025-03-20T04:13:54.981586Z","shell.execute_reply":"2025-03-20T04:13:54.987964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_img_stats_full(dataset):\n    imgs_ = torch.stack([img for img,_ in dataset],dim=1)\n    imgs_ = imgs_.view(1,-1)\n    imgs_mean = imgs_.mean(dim=1)\n    imgs_std = imgs_.std(dim=1)\n    return imgs_mean,imgs_std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:54.989568Z","iopub.execute_input":"2025-03-20T04:13:54.989813Z","iopub.status.idle":"2025-03-20T04:13:55.000532Z","shell.execute_reply.started":"2025-03-20T04:13:54.989793Z","shell.execute_reply":"2025-03-20T04:13:54.999818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformations_org = transforms.Compose([transforms.ToTensor()])\ntrain_org = MNISTDataset(x, y, True, transformations_org)\n\ncalculate_img_stats_full(train_org)\n# (tensor([0.1310]), tensor([0.3085]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:13:55.001368Z","iopub.execute_input":"2025-03-20T04:13:55.001691Z","iopub.status.idle":"2025-03-20T04:14:12.805899Z","shell.execute_reply.started":"2025-03-20T04:13:55.001663Z","shell.execute_reply":"2025-03-20T04:14:12.804967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transformations_train = transforms.Compose([transforms.RandomRotation(15),                                       \n                                            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize(mean=[0.1310], std=[0.3085])\n                                           ])\n\n\ntransformations_valid = transforms.Compose([transforms.ToTensor(),\n                                            transforms.Normalize(mean=[0.1310], std=[0.3085])\n                                           ])\n\ntrain = MNISTDataset(X_train, y_train, True, transformations_train)\nvalid = MNISTDataset(X_valid, y_valid, True, transformations_valid)\ntest  = MNISTDataset(data=test_df, target=None, train=False, transform=transformations_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:14:12.80682Z","iopub.execute_input":"2025-03-20T04:14:12.807088Z","iopub.status.idle":"2025-03-20T04:14:12.812558Z","shell.execute_reply.started":"2025-03-20T04:14:12.807058Z","shell.execute_reply":"2025-03-20T04:14:12.811782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train, batch_size=batch_size_train,num_workers=2, shuffle=True)\nvalid_loader = DataLoader(valid, batch_size=batch_size_test, num_workers=2, shuffle=True)\ntest_loader  = DataLoader(test,  batch_size=batch_size_test, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:14:12.813466Z","iopub.execute_input":"2025-03-20T04:14:12.813694Z","iopub.status.idle":"2025-03-20T04:14:12.828318Z","shell.execute_reply.started":"2025-03-20T04:14:12.813675Z","shell.execute_reply":"2025-03-20T04:14:12.827644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2) \n        )\n        \n        self.linear_block = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(128*7*7, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(64, 10)\n        )\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear_block(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:14:12.828987Z","iopub.execute_input":"2025-03-20T04:14:12.829244Z","iopub.status.idle":"2025-03-20T04:14:12.844015Z","shell.execute_reply.started":"2025-03-20T04:14:12.829225Z","shell.execute_reply":"2025-03-20T04:14:12.843173Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"cnn_model = Net()    \ncriterion = nn.CrossEntropyLoss()\n\nif torch.cuda.is_available():\n    cnn_model.cuda()\n    criterion.cuda()                       \n\noptimizer = optim.Adam(params=cnn_model.parameters(), lr=learning_rate)    \n\nexp_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\ntrain_losses = []\ntrain_counter = []\ntest_losses = []\ntest_counter = [i*len(train_loader.dataset) for i in range(1, num_epoch + 1)]    \n\nbest_model_wts = copy.deepcopy(cnn_model.state_dict())\nbest_acc = 0.0\n\nsince = time.time()\n\nfor epoch in range(1, num_epoch + 1):\n    cnn_model.train()    \n    for i, (images, labels) in enumerate(train_loader):\n        images = Variable(images).cuda()\n        labels = Variable(labels).cuda()\n        # Clear gradients\n        optimizer.zero_grad()\n        # Forward pass\n        outputs = cnn_model(images)\n        # Calculate loss\n        loss = criterion(outputs, labels)\n        # Backward pass\n        loss.backward()\n        # Update weights\n        optimizer.step()\n        if (i + 1)% log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, (i + 1) * len(images), len(train_loader.dataset),\n                100. * (i + 1) / len(train_loader), loss.data))\n            train_losses.append(loss.item())\n            train_counter.append((i*64) + ((epoch-1)*len(train_loader.dataset)))\n    cnn_model.eval()    \n    loss = 0    \n    running_corrects = 0\n    with torch.no_grad():       \n        for i, (data, target) in enumerate(valid_loader):\n            data = Variable(data).cuda()\n            target = Variable(target).cuda()\n            output = cnn_model(data)\n            loss += F.cross_entropy(output, target, reduction='sum').item()            \n            _, preds = torch.max(output, 1)            \n            running_corrects += torch.sum(preds == target.data)\n    loss /= len(valid_loader.dataset)\n    test_losses.append(loss)\n    epoch_acc = 100. * running_corrects.double() / len(valid_loader.dataset)\n    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        loss, running_corrects, len(valid_loader.dataset), epoch_acc))\n    if epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model_wts = copy.deepcopy(cnn_model.state_dict())\n    exp_lr_scheduler.step(loss)\n             \ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\nprint('Best val Acc: {:4f}'.format(best_acc))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T04:14:12.844766Z","iopub.execute_input":"2025-03-20T04:14:12.844987Z","execution_failed":"2025-03-20T04:16:02.421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot","metadata":{}},{"cell_type":"code","source":"fig = plt.figure()\nplt.plot(train_counter, train_losses, color='blue')\nplt.scatter(test_counter, test_losses, color='red')\nplt.legend(['Train Loss', 'Test Loss'], loc='upper right')\nplt.xlabel('number of training examples seen')\nplt.ylabel('negative log likelihood loss')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T04:16:02.423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"cnn_model.eval()\ntest_preds = None\ntest_preds = torch.LongTensor()\n    \nfor i, data in enumerate(test_loader):\n    data = Variable(data).cuda()   \n    output = cnn_model(data)\n    preds = output.cpu().data.max(1, keepdim=True)[1]\n    test_preds = torch.cat((test_preds, preds), dim=0)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T04:16:02.424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save Output as CSV","metadata":{}},{"cell_type":"code","source":"out_df = pd.DataFrame({'ImageId':np.arange(1, len(test_loader.dataset)+1), 'Label':test_preds.numpy().squeeze()})\nout_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T04:16:02.425Z"}},"outputs":[],"execution_count":null}]}